<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>兔の博客</title>
  
  <subtitle>兔子的小窝</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-08-25T04:01:21.767Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Alexander Liu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Stanford Pratical Machine Learning-模型评估</title>
    <link href="http://example.com/2023/08/25/stanford-pratical-machine-learning-mo-xing-ping-gu/"/>
    <id>http://example.com/2023/08/25/stanford-pratical-machine-learning-mo-xing-ping-gu/</id>
    <published>2023-08-25T03:27:18.000Z</published>
    <updated>2023-08-25T04:01:21.767Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要介绍模型评估！！！&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-神经网络</title>
    <link href="http://example.com/2023/08/25/stanford-pratical-machine-learning-shen-jing-wang-luo/"/>
    <id>http://example.com/2023/08/25/stanford-pratical-machine-learning-shen-jing-wang-luo/</id>
    <published>2023-08-25T02:04:22.000Z</published>
    <updated>2023-08-25T02:58:34.741Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要介绍多层感知机&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-线性模型</title>
    <link href="http://example.com/2023/08/24/stanford-pratical-machine-learning-xian-xing-mo-xing/"/>
    <id>http://example.com/2023/08/24/stanford-pratical-machine-learning-xian-xing-mo-xing/</id>
    <published>2023-08-24T13:29:38.000Z</published>
    <updated>2023-08-25T02:03:59.876Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要介绍线性模型昂！&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-决策树</title>
    <link href="http://example.com/2023/08/24/stanford-pratical-machine-learning-jue-ce-shu/"/>
    <id>http://example.com/2023/08/24/stanford-pratical-machine-learning-jue-ce-shu/</id>
    <published>2023-08-24T13:01:09.000Z</published>
    <updated>2023-08-24T13:29:07.177Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要介绍决策树，Decision Trees用的很广泛啦！！！&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-机器学习简介</title>
    <link href="http://example.com/2023/08/24/stanford-pratical-machine-learning-ji-qi-xue-xi-jian-jie/"/>
    <id>http://example.com/2023/08/24/stanford-pratical-machine-learning-ji-qi-xue-xi-jian-jie/</id>
    <published>2023-08-24T09:09:21.000Z</published>
    <updated>2023-08-24T13:31:30.807Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要简单介绍一下机器学习，包括机器学习的类型之类的。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-数据科学家的日常</title>
    <link href="http://example.com/2023/08/24/stanford-pratical-machine-learning-shu-ju-ke-xue-jia-de-ri-chang/"/>
    <id>http://example.com/2023/08/24/stanford-pratical-machine-learning-shu-ju-ke-xue-jia-de-ri-chang/</id>
    <published>2023-08-24T08:41:09.000Z</published>
    <updated>2023-08-24T08:58:34.631Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要介绍数据科学家的日常，主要是一个总结篇，对于前几章的数据预处理做一个大大的总结。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-特征工程</title>
    <link href="http://example.com/2023/08/24/stanford-pratical-machine-learning-te-zheng-gong-cheng/"/>
    <id>http://example.com/2023/08/24/stanford-pratical-machine-learning-te-zheng-gong-cheng/</id>
    <published>2023-08-24T08:23:25.000Z</published>
    <updated>2023-08-24T08:40:28.998Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要介绍特征工程，上一章是如何将数据转换为我们需要的格式。这一章更进一步，从处理好的数据中，提取出模型用的特征。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-数据变换</title>
    <link href="http://example.com/2023/08/24/stanford-pratical-machine-learning-shu-ju-bian-huan/"/>
    <id>http://example.com/2023/08/24/stanford-pratical-machine-learning-shu-ju-bian-huan/</id>
    <published>2023-08-24T03:33:34.000Z</published>
    <updated>2023-08-24T04:02:10.400Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要介绍数据变换&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-数据清理</title>
    <link href="http://example.com/2023/08/24/stanford-pratical-machine-learning-shu-ju-qing-li/"/>
    <id>http://example.com/2023/08/24/stanford-pratical-machine-learning-shu-ju-qing-li/</id>
    <published>2023-08-24T02:50:08.000Z</published>
    <updated>2023-08-24T03:10:29.028Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要介绍数据清理&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-探索性数据分析</title>
    <link href="http://example.com/2023/08/24/stanford-pratical-machine-learning-tan-suo-xing-shu-ju-fen-xi/"/>
    <id>http://example.com/2023/08/24/stanford-pratical-machine-learning-tan-suo-xing-shu-ju-fen-xi/</id>
    <published>2023-08-24T02:00:43.000Z</published>
    <updated>2023-08-24T02:51:34.867Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要介绍探索性数据分析&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-数据标注</title>
    <link href="http://example.com/2023/08/23/stanford-pratical-machine-learning-shu-ju-biao-zhu/"/>
    <id>http://example.com/2023/08/23/stanford-pratical-machine-learning-shu-ju-biao-zhu/</id>
    <published>2023-08-23T13:37:00.000Z</published>
    <updated>2023-08-24T01:57:05.951Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要介绍数据标注&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-网页数据抓取</title>
    <link href="http://example.com/2023/08/23/stanford-pratical-machine-learning-wang-ye-shu-ju-zhua-qu/"/>
    <id>http://example.com/2023/08/23/stanford-pratical-machine-learning-wang-ye-shu-ju-zhua-qu/</id>
    <published>2023-08-23T13:05:12.000Z</published>
    <updated>2023-08-23T13:45:00.845Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一章主要介绍网页数据爬取&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Pratical Machine Learning-数据获取</title>
    <link href="http://example.com/2023/08/23/stanford-pratical-machine-learning-shu-ju-huo-qu/"/>
    <id>http://example.com/2023/08/23/stanford-pratical-machine-learning-shu-ju-huo-qu/</id>
    <published>2023-08-23T12:04:30.000Z</published>
    <updated>2023-08-23T12:59:54.206Z</updated>
    
    
    <summary type="html">&lt;p&gt;这一节主要介绍数据获取的内容&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Practical Machine Learning-课程介绍</title>
    <link href="http://example.com/2023/08/23/stanford-practical-machine-learning-ke-cheng-jie-shao/"/>
    <id>http://example.com/2023/08/23/stanford-practical-machine-learning-ke-cheng-jie-shao/</id>
    <published>2023-08-23T08:43:22.000Z</published>
    <updated>2023-08-23T12:03:31.712Z</updated>
    
    
    <summary type="html">&lt;p&gt;这门课程主要关于，机器学习在工业界的运用。教授一个数据科学家，将机器学习用到工业界的时候后，在不同的阶段所遇到了一些比较重要的技术细节。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>D2L-Paper Reading</title>
    <link href="http://example.com/2023/08/23/d2l-paper-reading/"/>
    <id>http://example.com/2023/08/23/d2l-paper-reading/</id>
    <published>2023-08-23T02:01:59.000Z</published>
    <updated>2023-08-23T03:13:23.187Z</updated>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1H44y1t75x/?spm_id_from=333.788&amp;amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd&quot;&gt;沐神教你读论文&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>D2L-Summary of D2L Lession</title>
    <link href="http://example.com/2023/08/20/d2l-summary-of-d2l-lession/"/>
    <id>http://example.com/2023/08/20/d2l-summary-of-d2l-lession/</id>
    <published>2023-08-20T12:12:18.000Z</published>
    <updated>2023-08-20T13:14:24.211Z</updated>
    
    
    <summary type="html">&lt;p&gt;D2L的课程结束啦，接下来是斯坦福的课程：&lt;a href=&quot;https://c.d2l.ai/stanford-cs329p/&quot;&gt;Stanford Lession&lt;/a&gt;，结尾课程链接在这里：&lt;a href=&quot;https://www.bilibili.com/video/BV1AL4y1Y7gu/?spm_id_from=333.999.0.0&amp;amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd&quot;&gt;D2L 课程总结和进阶学习&lt;/a&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>D2L-12-Optimization Algorithms</title>
    <link href="http://example.com/2023/08/18/d2l-12-optimization-algorithms/"/>
    <id>http://example.com/2023/08/18/d2l-12-optimization-algorithms/</id>
    <published>2023-08-18T12:53:14.000Z</published>
    <updated>2023-08-21T07:51:28.501Z</updated>
    
    
    <summary type="html">&lt;p&gt;对于深度学习问题，我们通常会先定义&lt;em&gt;损失函数&lt;/em&gt;。一旦我们有了损失函数，我们就可以使用优化算法来尝试最小化损失。在优化中，损失函数通常被称为优化问题的&lt;em&gt;目标函数&lt;/em&gt;。按照传统惯例，大多数优化算法都关注的是&lt;em&gt;最小化&lt;/em&gt;。如果我们需要最大化目标，那么有一个简单的解决方案：在目标函数前加负号即可。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>D2L-Kaggle-目标检测（牛仔穿戴）</title>
    <link href="http://example.com/2023/08/18/d2l-kaggle-mu-biao-jian-ce-niu-zi-chuan-dai/"/>
    <id>http://example.com/2023/08/18/d2l-kaggle-mu-biao-jian-ce-niu-zi-chuan-dai/</id>
    <published>2023-08-18T12:09:30.000Z</published>
    <updated>2023-08-18T12:50:15.397Z</updated>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;这个Competition中，我们遇到的主要问题，是数据的不平衡。数据不平衡使得某些类别的样本过少，我们需要处理这个问题。&lt;/p&gt;
&lt;h1 id=&quot;实战Kaggle比赛&quot;&gt;&lt;a href=&quot;#实战Kaggle比赛&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>D2L-11-Attention Mechanisms and Transformers</title>
    <link href="http://example.com/2023/08/16/d2l-11-attention-mechanisms-and-transformers/"/>
    <id>http://example.com/2023/08/16/d2l-11-attention-mechanisms-and-transformers/</id>
    <published>2023-08-16T09:06:57.000Z</published>
    <updated>2023-08-18T11:31:35.036Z</updated>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1v3411r78R?p=1&amp;amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd&quot;&gt;Self Attention &amp;amp; Transformer 李宏毅&lt;/a&gt;，&lt;a href=&quot;https://www.bilibili.com/video/BV1fL4y1z7Pi/?p=2&amp;amp;spm_id_from=pageDriver&amp;amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd&quot;&gt;Self-supervised Learing BERT GPT 李宏毅&lt;/a&gt;。先看这些！这个对于原理讲的非常清楚，了解了这个，再去学李沐的课程，就十分清晰了昂！！！&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>D2L-10-Modern Recurrent Neural Networks</title>
    <link href="http://example.com/2023/08/14/d2l-10-modern-recurrent-neural-networks/"/>
    <id>http://example.com/2023/08/14/d2l-10-modern-recurrent-neural-networks/</id>
    <published>2023-08-14T12:31:54.000Z</published>
    <updated>2023-08-15T13:57:49.432Z</updated>
    
    
    <summary type="html">&lt;p&gt;循环神经网络在实践中一个常见问题是数值不稳定性。 尽管我们已经应用了梯度裁剪等技巧来缓解这个问题， 但是仍需要通过设计更复杂的序列模型来进一步处理它。 具体来说，我们将引入两个广泛使用的网络， 即&lt;em&gt;门控循环单元&lt;/em&gt;（gated recurrent units，GRU）和 &lt;em&gt;长短期记忆网络&lt;/em&gt;（long short-term memory，LSTM）。 然后，我们将基于一个单向隐藏层来扩展循环神经网络架构。 我们将描述具有多个隐藏层的深层架构， 并讨论基于前向和后向循环计算的双向设计。 现代循环网络经常采用这种扩展。 在解释这些循环神经网络的变体时， 我们将继续考虑 &lt;a href=&quot;https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/index.html#chap-rnn&quot;&gt;8节&lt;/a&gt;中的语言建模问题。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    
    <category term="研0自学" scheme="http://example.com/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/"/>
    
  </entry>
  
</feed>
