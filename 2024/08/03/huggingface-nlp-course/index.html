

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/tuzi.png">
  <link rel="icon" href="/img/tuzi.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Alexander Liu">
  <meta name="keywords" content="åˆ†å¸ƒå¼ç³»ç»Ÿ,åç«¯ç ”å‘,æ•°æ®ååŒ">
  
    <meta name="description" content="æ–°å‘æ¥è‡ªäºè‡ªå·±çš„æµ…è–„ï¼Œåœ¨ä»æ´›é˜³å›åŒ—äº¬çš„åŠ¨è½¦ä¸Šï¼Œæè€å¸ˆç»™æˆ‘æ¨èäº†è¿™ä¸ªHuggingFaceæ•™ç¨‹ã€‚å°½é‡ä¸å¤§ç¯‡å¹…è®°å½•ï¼Œè®°å½•ç¬”è®°ï¼Œå¯¹æœ‰æ„Ÿè§¦å’Œè‡ªå·±è®¤ä¸ºæœ‰ä»·å€¼çš„åœ°æ–¹å¤šé©»è¶³ã€‚è¿™ä¸ªé¡¹ç›®ä»æˆ‘çš„è§†è§’æ¥çœ‹ï¼Œå’Œå®è·µç»“åˆä¼šæ›´åŠ ç´§å¯†ï¼Œå¯¹æˆ‘æ¥è¯´æœ‰å¾ˆå¤šä»·å€¼ï¼">
<meta property="og:type" content="article">
<meta property="og:title" content="HuggingFace-NLP-Course">
<meta property="og:url" content="https://alexanderliu-creator.github.io/2024/08/03/huggingface-nlp-course/index.html">
<meta property="og:site_name" content="å…”ã®åšå®¢">
<meta property="og:description" content="æ–°å‘æ¥è‡ªäºè‡ªå·±çš„æµ…è–„ï¼Œåœ¨ä»æ´›é˜³å›åŒ—äº¬çš„åŠ¨è½¦ä¸Šï¼Œæè€å¸ˆç»™æˆ‘æ¨èäº†è¿™ä¸ªHuggingFaceæ•™ç¨‹ã€‚å°½é‡ä¸å¤§ç¯‡å¹…è®°å½•ï¼Œè®°å½•ç¬”è®°ï¼Œå¯¹æœ‰æ„Ÿè§¦å’Œè‡ªå·±è®¤ä¸ºæœ‰ä»·å€¼çš„åœ°æ–¹å¤šé©»è¶³ã€‚è¿™ä¸ªé¡¹ç›®ä»æˆ‘çš„è§†è§’æ¥çœ‹ï¼Œå’Œå®è·µç»“åˆä¼šæ›´åŠ ç´§å¯†ï¼Œå¯¹æˆ‘æ¥è¯´æœ‰å¾ˆå¤šä»·å€¼ï¼">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202408032115104.svg">
<meta property="article:published_time" content="2024-08-03T13:13:03.000Z">
<meta property="article:modified_time" content="2024-08-26T09:25:20.321Z">
<meta property="article:author" content="Alexander Liu">
<meta property="article:tag" content="è‡ªå­¦">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202408032115104.svg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>HuggingFace-NLP-Course - å…”ã®åšå®¢</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"alexanderliu-creator.github.io","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":1},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="å…”ã®åšå®¢" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>å…”çš„åšå®¢</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                é¦–é¡µ
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                å½’æ¡£
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                åˆ†ç±»
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                æ ‡ç­¾
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                å…³äº
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                å‹é“¾
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/background_post.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="HuggingFace-NLP-Course"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Alexander Liu
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-08-03 21:13" pubdate>
          2024å¹´8æœˆ3æ—¥ æ™šä¸Š
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          49k å­—
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          406 åˆ†é’Ÿ
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> æ¬¡
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">HuggingFace-NLP-Course</h1>
            
              <p class="note note-info">
                
                  
                    æœ¬æ–‡æœ€åæ›´æ–°äºï¼š24 å¤©å‰
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <p>æ–°å‘æ¥è‡ªäºè‡ªå·±çš„æµ…è–„ï¼Œåœ¨ä»æ´›é˜³å›åŒ—äº¬çš„åŠ¨è½¦ä¸Šï¼Œæè€å¸ˆç»™æˆ‘æ¨èäº†è¿™ä¸ª<a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/zh-CN/chapter1/1">HuggingFaceæ•™ç¨‹</a>ã€‚å°½é‡ä¸å¤§ç¯‡å¹…è®°å½•ï¼Œè®°å½•ç¬”è®°ï¼Œå¯¹æœ‰æ„Ÿè§¦å’Œè‡ªå·±è®¤ä¸ºæœ‰ä»·å€¼çš„åœ°æ–¹å¤šé©»è¶³ã€‚è¿™ä¸ªé¡¹ç›®ä»æˆ‘çš„è§†è§’æ¥çœ‹ï¼Œå’Œå®è·µç»“åˆä¼šæ›´åŠ ç´§å¯†ï¼Œå¯¹æˆ‘æ¥è¯´æœ‰å¾ˆå¤šä»·å€¼ï¼</p>
<span id="more"></span>



<h1 id="Environment-Setup"><a href="#Environment-Setup" class="headerlink" title="Environment Setup"></a>Environment Setup</h1><ul>
<li>Anaconda</li>
<li>Conda createä¸€ä¸ªç¯å¢ƒï¼Œå¹¶ä¸”<code>pip install transformers</code>ã€‚</li>
</ul>
<h1 id="Transformer-Model"><a href="#Transformer-Model" class="headerlink" title="Transformer Model"></a>Transformer Model</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>ä¸»è¦å†…å®¹ï¼šTransformersã€Datasetsã€Tokenizers å’Œ Accelerateâ€”â€”ä»¥åŠ Hugging Face Hub æ•™ä½ è‡ªç„¶è¯­è¨€å¤„ç† (NLP)ã€‚</li>
<li>è¯¾ç¨‹è®¾ç½®ï¼š<ul>
<li>ç¬¬ 1 ç« åˆ°ç¬¬ 4 ç« ä»‹ç»äº† Transformers åº“çš„ä¸»è¦æ¦‚å¿µã€‚åœ¨æœ¬è¯¾ç¨‹çš„è¿™ä¸€éƒ¨åˆ†ç»“æŸæ—¶ï¼Œæ‚¨å°†ç†Ÿæ‚‰ Transformer æ¨¡å‹çš„å·¥ä½œåŸç†ï¼Œå¹¶å°†äº†è§£å¦‚ä½•ä½¿ç”¨ <a target="_blank" rel="noopener" href="https://huggingface.co/models">Hugging Face Hub</a> ä¸­çš„æ¨¡å‹ï¼Œåœ¨æ•°æ®é›†ä¸Šå¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œå¹¶åœ¨ Hub ä¸Šåˆ†äº«æ‚¨çš„ç»“æœã€‚</li>
<li>ç¬¬ 5 ç« åˆ°ç¬¬ 8 ç« åœ¨æ·±å…¥ç ”ç©¶ç»å…¸ NLP ä»»åŠ¡ä¹‹å‰ï¼Œæ•™æˆ Datasetså’Œ Tokenizersçš„åŸºç¡€çŸ¥è¯†ã€‚åœ¨æœ¬éƒ¨åˆ†ç»“æŸæ—¶ï¼Œæ‚¨å°†èƒ½å¤Ÿè‡ªå·±è§£å†³æœ€å¸¸è§çš„ NLP é—®é¢˜ã€‚</li>
<li>ç¬¬ 9 ç« åˆ°ç¬¬ 12 ç« æ›´åŠ æ·±å…¥ï¼Œæ¢è®¨äº†å¦‚ä½•ä½¿ç”¨ Transformer æ¨¡å‹å¤„ç†è¯­éŸ³å¤„ç†å’Œè®¡ç®—æœºè§†è§‰ä¸­çš„ä»»åŠ¡ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•æ„å»ºå’Œåˆ†äº«æ¨¡å‹ï¼Œå¹¶é’ˆå¯¹ç”Ÿäº§ç¯å¢ƒå¯¹å…¶è¿›è¡Œä¼˜åŒ–ã€‚åœ¨è¿™éƒ¨åˆ†ç»“æŸæ—¶ï¼Œæ‚¨å°†å‡†å¤‡å¥½å°† Transformers åº”ç”¨äºï¼ˆå‡ ä¹ï¼‰ä»»ä½•æœºå™¨å­¦ä¹ é—®é¢˜ï¼</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202408032208494.svg" srcset="/img/loading.gif" lazyload alt="Course Setting"></p>
<h2 id="Transformer-Usage"><a href="#Transformer-Usage" class="headerlink" title="Transformer Usage"></a>Transformer Usage</h2><ul>
<li><p>å¸¸è§NLPä»»åŠ¡ï¼šå¯¹æ•´ä¸ªå¥å­è¿›è¡Œåˆ†ç±»ï¼Œå¯¹å¥å­ä¸­çš„æ¯ä¸ªè¯è¿›è¡Œåˆ†ç±»ï¼Œç”Ÿæˆæ–‡æœ¬å†…å®¹ï¼Œä»æ–‡æœ¬ä¸­æå–ç­”æ¡ˆï¼Œä»è¾“å…¥æ–‡æœ¬ç”Ÿæˆæ–°å¥å­ã€‚NLP ä¸ä»…é™äºä¹¦é¢æ–‡æœ¬ã€‚å®ƒè¿˜è§£å†³äº†è¯­éŸ³è¯†åˆ«å’Œè®¡ç®—æœºè§†è§‰ä¸­çš„å¤æ‚æŒ‘æˆ˜ï¼Œä¾‹å¦‚ç”ŸæˆéŸ³é¢‘æ ·æœ¬çš„è½¬å½•æˆ–å›¾åƒæè¿°ã€‚Transformerå°±æ˜¯å¹¿æ³›ç”¨äºNLPé¢†åŸŸçš„ä¸€ä¸ªæ¨¡å‹ã€‚Some of the currently <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/main_classes/pipelines">available pipelines</a> are:</p>
</li>
<li><p>Transformers åº“ä¸­æœ€åŸºæœ¬çš„å¯¹è±¡æ˜¯ <strong>pipeline()</strong> å‡½æ•°ã€‚å®ƒå°†æ¨¡å‹ä¸å…¶å¿…è¦çš„é¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤è¿æ¥èµ·æ¥ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿé€šè¿‡ç›´æ¥è¾“å…¥ä»»ä½•æ–‡æœ¬å¹¶è·å¾—æœ€ç»ˆçš„ç­”æ¡ˆï¼š</p>
<ul>
<li><p>Single Sentence</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>classifier = pipeline(<span class="hljs-string">"sentiment-analysis"</span>)<br>classifier(<span class="hljs-string">"I've been waiting for a HuggingFace course my whole life."</span>)<br><br><span class="hljs-comment"># Result: [{'label': 'POSITIVE', 'score': 0.9598047137260437}]</span><br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>Multi Sentences</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">classifier(<br>    [<span class="hljs-string">"I've been waiting for a HuggingFace course my whole life."</span>, <span class="hljs-string">"I hate this so much!"</span>]<br>)<br><br><span class="hljs-comment"># Result: [{'label': 'POSITIVE', 'score': 0.9598047137260437},{'label': 'NEGATIVE', 'score': 0.9994558095932007}]</span><br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>é»˜è®¤æƒ…å†µä¸‹ï¼Œæ­¤pipelineé€‰æ‹©ä¸€ä¸ªç‰¹å®šçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å·²é’ˆå¯¹è‹±è¯­æƒ…æ„Ÿåˆ†æè¿›è¡Œäº†å¾®è°ƒã€‚åˆ›å»ºclassifierå¯¹è±¡æ—¶ï¼Œå°†ä¸‹è½½å¹¶ç¼“å­˜æ¨¡å‹ã€‚å¦‚æœæ‚¨é‡æ–°è¿è¡Œè¯¥å‘½ä»¤ï¼Œåˆ™å°†ä½¿ç”¨ç¼“å­˜çš„æ¨¡å‹ï¼Œæ— éœ€å†æ¬¡ä¸‹è½½æ¨¡å‹ã€‚</p>
</li>
</ul>
</li>
<li><p>å°†ä¸€äº›æ–‡æœ¬ä¼ é€’åˆ°pipelineæ—¶æ¶‰åŠä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼š</p>
<ol>
<li>æ–‡æœ¬è¢«é¢„å¤„ç†ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ ¼å¼ã€‚</li>
<li>é¢„å¤„ç†çš„è¾“å…¥è¢«ä¼ é€’ç»™æ¨¡å‹ã€‚</li>
<li>æ¨¡å‹å¤„ç†åè¾“å‡ºæœ€ç»ˆäººç±»å¯ä»¥ç†è§£çš„ç»“æœã€‚</li>
</ol>
</li>
<li><p>Some of the currently <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/main_classes/pipelines">available pipelines</a> are: </p>
<ul>
<li><code>feature-extraction</code> (get the vector representation of a text)</li>
<li><code>fill-mask</code></li>
<li><code>ner</code> (named entity recognition)</li>
<li><code>question-answering</code></li>
<li><code>sentiment-analysis</code></li>
<li><code>summarization</code></li>
<li><code>text-generation</code></li>
<li><code>translation</code></li>
<li><code>zero-shot-classification</code></li>
</ul>
</li>
<li><p>ä¸‹é¢æ˜¯ä¸€äº›Demo</p>
<ul>
<li><p>Zero-shot classification</p>
<p>æˆ‘ä»¬å°†é¦–å…ˆå¤„ç†ä¸€é¡¹éå¸¸å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œæˆ‘ä»¬éœ€è¦å¯¹å°šæœªæ ‡è®°çš„æ–‡æœ¬è¿›è¡Œåˆ†ç±»ã€‚zero-shot-classification pipelineéå¸¸å¼ºå¤§ï¼šå®ƒå…è®¸æ‚¨ç›´æ¥æŒ‡å®šç”¨äºåˆ†ç±»çš„æ ‡ç­¾ï¼Œå› æ­¤æ‚¨ä¸å¿…ä¾èµ–é¢„è®­ç»ƒæ¨¡å‹çš„æ ‡ç­¾ã€‚ä¸‹é¢çš„æ¨¡å‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨è¿™ä¸¤ä¸ªæ ‡ç­¾å°†å¥å­åˆ†ç±»ä¸ºæ­£é¢æˆ–è´Ÿé¢â€”â€”ä½†ä¹Ÿå¯ä»¥ä½¿ç”¨æ‚¨å–œæ¬¢çš„ä»»ä½•å…¶ä»–æ ‡ç­¾é›†å¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>classifier = pipeline(<span class="hljs-string">"zero-shot-classification"</span>)<br>classifier(<br>    <span class="hljs-string">"This is a course about the Transformers library"</span>,<br>    candidate_labels=[<span class="hljs-string">"education"</span>, <span class="hljs-string">"politics"</span>, <span class="hljs-string">"business"</span>],<br>)<br><br><span class="hljs-comment"># Result: {'sequence': 'This is a course about the Transformers library', 'labels': ['education', 'business', 'politics'], 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>æ­¤pipelineç§°ä¸ºzero-shotï¼Œå› ä¸ºæ‚¨ä¸éœ€è¦å¯¹æ•°æ®ä¸Šçš„æ¨¡å‹è¿›è¡Œå¾®è°ƒå³å¯ä½¿ç”¨å®ƒã€‚å®ƒå¯ä»¥ç›´æ¥è¿”å›æ‚¨æƒ³è¦çš„ä»»ä½•æ ‡ç­¾åˆ—è¡¨çš„æ¦‚ç‡åˆ†æ•°ï¼</p>
</blockquote>
</li>
<li><p>Text generation</p>
<p>ä¸»è¦ä½¿ç”¨æ–¹æ³•æ˜¯æ‚¨æä¾›ä¸€ä¸ªæç¤ºï¼Œæ¨¡å‹å°†é€šè¿‡ç”Ÿæˆå‰©ä½™çš„æ–‡æœ¬æ¥è‡ªåŠ¨å®Œæˆæ•´æ®µè¯ã€‚è¿™ç±»ä¼¼äºè®¸å¤šæ‰‹æœºä¸Šçš„é¢„æµ‹æ–‡æœ¬åŠŸèƒ½ã€‚æ–‡æœ¬ç”Ÿæˆæ¶‰åŠéšæœºæ€§ï¼Œå› æ­¤å¦‚æœæ‚¨æ²¡æœ‰å¾—åˆ°ç›¸åŒçš„å¦‚ä¸‹æ‰€ç¤ºçš„ç»“æœï¼Œè¿™æ˜¯æ­£å¸¸çš„ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>generator = pipeline(<span class="hljs-string">"text-generation"</span>)<br>generator(<span class="hljs-string">"In this course, we will teach you how to"</span>)<br><br><span class="hljs-comment"># Result: [{'generated_text': 'In this course, we will teach you how to understand and use data flow and data interchange when handling user data. We will be working with one or more of the most commonly used data flows â€” data flows of various types, as seen by the HTTP}]</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>æ‚¨å¯ä»¥ä½¿ç”¨å‚æ•° <strong>num_return_sequences</strong> æ§åˆ¶ç”Ÿæˆå¤šå°‘ä¸ªä¸åŒçš„åºåˆ—ï¼Œå¹¶ä½¿ç”¨å‚æ•° <strong>max_length</strong> æ§åˆ¶è¾“å‡ºæ–‡æœ¬çš„æ€»é•¿åº¦ã€‚</p>
</blockquote>
</li>
<li><p>Mask filling</p>
<p>æ­¤ä»»åŠ¡çš„æƒ³æ³•æ˜¯å¡«å……ç»™å®šæ–‡æœ¬ä¸­çš„ç©ºç™½ï¼Œ</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>unmasker = pipeline(<span class="hljs-string">"fill-mask"</span>)<br>unmasker(<span class="hljs-string">"This course will teach you all about &lt;mask&gt; models."</span>, top_k=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># Reuslt: [{'sequence': 'This course will teach you all about mathematical models.','score': 0.19619831442832947,'token': 30412,'token_str': ' mathematical'}, {'sequence': 'This course will teach you all about computational models.', 'score': 0.04052725434303284, 'token': 38163, 'token_str': ' computational'}]</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p><strong>top_k</strong> å‚æ•°æ§åˆ¶è¦æ˜¾ç¤ºçš„ç»“æœæœ‰å¤šå°‘ç§ã€‚è¯·æ³¨æ„ï¼Œè¿™é‡Œæ¨¡å‹å¡«å……äº†ç‰¹æ®Šçš„&lt; **mask** &gt;è¯ï¼Œå®ƒé€šå¸¸è¢«ç§°ä¸ºæ©ç æ ‡è®°ã€‚å…¶ä»–æ©ç å¡«å……æ¨¡å‹å¯èƒ½æœ‰ä¸åŒçš„æ©ç æ ‡è®°ï¼Œå› æ­¤åœ¨æ¢ç´¢å…¶ä»–æ¨¡å‹æ—¶è¦éªŒè¯æ­£ç¡®çš„æ©ç å­—æ˜¯ä»€ä¹ˆã€‚æ£€æŸ¥å®ƒçš„ä¸€ç§æ–¹æ³•æ˜¯æŸ¥çœ‹å°ç»„ä»¶ä¸­ä½¿ç”¨çš„æ©ç ã€‚</p>
</blockquote>
<img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202408032253866.png" srcset="/img/loading.gif" lazyload alt="image-20240803225327829" style="zoom:50%;">
</li>
<li><p>Named entity recognition</p>
<p>å‘½åå®ä½“è¯†åˆ« (NER) æ˜¯ä¸€é¡¹ä»»åŠ¡ï¼Œå…¶ä¸­æ¨¡å‹å¿…é¡»æ‰¾åˆ°è¾“å…¥æ–‡æœ¬çš„å“ªäº›éƒ¨åˆ†å¯¹åº”äºè¯¸å¦‚äººå‘˜ã€ä½ç½®æˆ–ç»„ç»‡ä¹‹ç±»çš„å®ä½“ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>ner = pipeline(<span class="hljs-string">"ner"</span>, grouped_entities=<span class="hljs-literal">True</span>)<br>ner(<span class="hljs-string">"My name is Sylvain and I work at Hugging Face in Brooklyn."</span>)<br><br><span class="hljs-comment"># result [{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18},{'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}]</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>pipelineåˆ›å»ºå‡½æ•°ä¸­ä¼ é€’é€‰é¡¹ <strong>grouped_entities=True</strong> ä»¥å‘Šè¯‰pipelineå°†å¯¹åº”äºåŒä¸€å®ä½“çš„å¥å­éƒ¨åˆ†é‡æ–°ç»„åˆåœ¨ä¸€èµ·ï¼šè¿™é‡Œæ¨¡å‹æ­£ç¡®åœ°å°†â€œHuggingâ€å’Œâ€œFaceâ€åˆ†ç»„ä¸ºä¸€ä¸ªç»„ç»‡ï¼Œå³ä½¿åç§°ç”±å¤šä¸ªè¯ç»„æˆã€‚äº‹å®ä¸Šï¼Œæ­£å¦‚æˆ‘ä»¬å³å°†åœ¨ä¸‹ä¸€ç« çœ‹åˆ°çš„ï¼Œé¢„å¤„ç†ç”šè‡³ä¼šå°†ä¸€äº›å•è¯åˆ†æˆæ›´å°çš„éƒ¨åˆ†ã€‚ä¾‹å¦‚ï¼Œ<strong>Sylvain</strong> åˆ†å‰²ä¸ºäº†å››éƒ¨åˆ†ï¼š<strong>Sã€##ylã€##va</strong> å’Œ <strong>##in</strong>ã€‚åœ¨åå¤„ç†æ­¥éª¤ä¸­ï¼ŒpipelineæˆåŠŸåœ°é‡æ–°ç»„åˆäº†è¿™äº›éƒ¨åˆ†ã€‚</p>
</blockquote>
</li>
<li><p>Question answering</p>
<p>é—®ç­”pipelineä½¿ç”¨æ¥è‡ªç»™å®šä¸Šä¸‹æ–‡çš„ä¿¡æ¯å›ç­”é—®é¢˜ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>question_answerer = pipeline(<span class="hljs-string">"question-answering"</span>)<br>question_answerer(<br>    question=<span class="hljs-string">"Where do I work?"</span>,<br>    context=<span class="hljs-string">"My name is Sylvain and I work at Hugging Face in Brooklyn"</span>,<br>)<br><br><span class="hljs-comment"># Result {'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>æ­¤pipelineé€šè¿‡ä»æä¾›çš„ä¸Šä¸‹æ–‡ä¸­æå–ä¿¡æ¯æ¥å·¥ä½œï¼›å®ƒä¸ä¼šå‡­ç©ºç”Ÿæˆç­”æ¡ˆã€‚</p>
</blockquote>
</li>
<li><p>Summarization</p>
<p>æ–‡æœ¬æ‘˜è¦æ˜¯å°†æ–‡æœ¬ç¼©å‡ä¸ºè¾ƒçŸ­æ–‡æœ¬çš„ä»»åŠ¡ï¼ŒåŒæ—¶ä¿ç•™æ–‡æœ¬ä¸­çš„ä¸»è¦ï¼ˆé‡è¦ï¼‰ä¿¡æ¯ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>summarizer = pipeline(<span class="hljs-string">"summarization"</span>)<br>summarizer(<br>    <span class="hljs-string">"""</span><br><span class="hljs-string">    America has changed dramatically during recent years. Not only has the number of </span><br><span class="hljs-string">    graduates in traditional engineering disciplines such as mechanical, civil, </span><br><span class="hljs-string">    electrical, chemical, and aeronautical engineering declined, but in most of </span><br><span class="hljs-string">    the premier American universities engineering curricula now concentrate on </span><br><span class="hljs-string">    and encourage largely the study of engineering science. As a result, there </span><br><span class="hljs-string">    are declining offerings in engineering subjects dealing with infrastructure, </span><br><span class="hljs-string">    the environment, and related issues, and greater concentration on high </span><br><span class="hljs-string">    technology subjects, largely supporting increasingly complex scientific </span><br><span class="hljs-string">    developments. While the latter is important, it should not be at the expense </span><br><span class="hljs-string">    of more traditional engineering.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Rapidly developing economies such as China and India, as well as other </span><br><span class="hljs-string">    industrial countries in Europe and Asia, continue to encourage and advance </span><br><span class="hljs-string">    the teaching of engineering. Both China and India, respectively, graduate </span><br><span class="hljs-string">    six and eight times as many traditional engineers as does the United States. </span><br><span class="hljs-string">    Other industrial countries at minimum maintain their output, while America </span><br><span class="hljs-string">    suffers an increasingly serious decline in the number of engineering graduates </span><br><span class="hljs-string">    and a lack of well-educated engineers.</span><br><span class="hljs-string">"""</span><br>)<br><br><br><span class="hljs-comment"># Result [{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil , electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India, as well as other industrial countries in Europe and Asia, continue to encourage and advance engineering .'}]</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>ä¸æ–‡æœ¬ç”Ÿæˆä¸€æ ·ï¼Œæ‚¨æŒ‡å®šç»“æœçš„ <strong>max_length</strong> æˆ– <strong>min_length</strong>ã€‚</p>
</blockquote>
</li>
<li><p>Translation</p>
<p>å¯¹äºç¿»è¯‘ï¼Œå¦‚æœæ‚¨åœ¨ä»»åŠ¡åç§°ä¸­æä¾›è¯­è¨€å¯¹ï¼ˆä¾‹å¦‚â€œ<strong>translation_en_to_fr</strong>â€ï¼‰ï¼Œåˆ™å¯ä»¥ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼Œä½†æœ€ç®€å•çš„æ–¹æ³•æ˜¯åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/models">æ¨¡å‹ä¸­å¿ƒï¼ˆhubï¼‰</a>é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>translator = pipeline(<span class="hljs-string">"translation"</span>, model=<span class="hljs-string">"Helsinki-NLP/opus-mt-fr-en"</span>)<br>translator(<span class="hljs-string">"Ce cours est produit par Hugging Face."</span>)<br><br><span class="hljs-comment"># Result [{'translation_text': 'This course is produced by Hugging Face.'}]</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>ä¸æ–‡æœ¬ç”Ÿæˆå’Œæ‘˜è¦ä¸€æ ·ï¼Œæ‚¨å¯ä»¥æŒ‡å®šç»“æœçš„ <strong>max_length</strong> æˆ– <strong>min_length</strong>ã€‚</p>
</blockquote>
</li>
<li><p>Using any model from the Hub in a pipeline</p>
<ul>
<li><p>æ‚¨ä¹Ÿå¯ä»¥ä» Hub ä¸­é€‰æ‹©ç‰¹å®šæ¨¡å‹ä»¥åœ¨ç‰¹å®šä»»åŠ¡çš„pipelineä¸­ä½¿ç”¨ - ä¾‹å¦‚ï¼Œæ–‡æœ¬ç”Ÿæˆã€‚è½¬åˆ°<a target="_blank" rel="noopener" href="https://huggingface.co/models"><strong>æ¨¡å‹ä¸­å¿ƒï¼ˆhubï¼‰</strong></a>å¹¶å•å‡»å·¦ä¾§çš„ç›¸åº”æ ‡ç­¾å°†ä¼šåªæ˜¾ç¤ºè¯¥ä»»åŠ¡æ”¯æŒçš„æ¨¡å‹ã€‚ <a target="_blank" rel="noopener" href="https://huggingface.co/distilgpt2"><strong>distilgpt2</strong></a> æ¨¡å‹ä¸ºä¾‹å­</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>generator = pipeline(<span class="hljs-string">"text-generation"</span>, model=<span class="hljs-string">"distilgpt2"</span>)<br>generator(<br>    <span class="hljs-string">"In this course, we will teach you how to"</span>,<br>    max_length=<span class="hljs-number">30</span>,<br>    num_return_sequences=<span class="hljs-number">2</span>,<br>)<br><br><span class="hljs-comment"># Result: [{'generated_text': 'In this course, we will teach you how to manipulate the world and move your mental and physical capabilities to your advantage.'}, {'generated_text': 'In this course, we will teach you how to become an expert and practice realtime, and with a hands on experience on both real time and real'}]</span><br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>å¯ä»¥ä»ç½‘ç«™ä¸Šæ‰¾åˆ°å¯¹åº”çš„ä½¿ç”¨ä»£ç ï¼š</p>
<ul>
<li><p>æ¨¡å‹é¡µé¢ï¼š<img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202408032240087.png" srcset="/img/loading.gif" lazyload alt="image-20240803224043007" style="zoom:50%;"></p>
</li>
<li><p>æ¨¡å‹ä½¿ç”¨ä»£ç ï¼š<img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202408032241609.png" srcset="/img/loading.gif" lazyload alt="image-20240803224104569" style="zoom:50%;"></p>
</li>
<li><p>The Inference APIï¼šæ‰€æœ‰æ¨¡å‹éƒ½å¯ä»¥ä½¿ç”¨ Inference API ç›´æ¥é€šè¿‡æµè§ˆå™¨è¿›è¡Œæµ‹è¯•ï¼Œè¯¥ API å¯åœ¨ <a target="_blank" rel="noopener" href="https://huggingface.co/">Hugging Face ç½‘ç«™</a>ä¸Šæ‰¾åˆ°ã€‚é€šè¿‡è¾“å…¥è‡ªå®šä¹‰æ–‡æœ¬å¹¶è§‚å¯Ÿæ¨¡å‹çš„è¾“å‡ºï¼Œæ‚¨å¯ä»¥ç›´æ¥åœ¨æ­¤é¡µé¢ä¸Šä½¿ç”¨æ¨¡å‹ã€‚å°ç»„ä»¶å½¢å¼çš„æ¨ç† API ä¹Ÿå¯ä½œä¸ºä»˜è´¹äº§å“ä½¿ç”¨ï¼Œå¦‚æœæ‚¨çš„å·¥ä½œæµç¨‹éœ€è¦å®ƒï¼Œå®ƒä¼šæ´¾ä¸Šç”¨åœºã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…<a target="_blank" rel="noopener" href="https://huggingface.co/pricing">å®šä»·é¡µé¢</a>ã€‚</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202408032253866.png" srcset="/img/loading.gif" lazyload alt="image-20240803225327829" style="zoom:50%;">









<h2 id="How-Transformer-Work"><a href="#How-Transformer-Work" class="headerlink" title="How Transformer Work"></a>How Transformer Work</h2><ul>
<li><p>ä»¥ä¸‹æ˜¯ Transformer æ¨¡å‹ï¼ˆç®€çŸ­ï¼‰å†å²ä¸­çš„ä¸€äº›å…³é”®èŠ‚ç‚¹ï¼š</p>
<ul>
<li><p>Development Graph for Transformer<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_chrono.svg" srcset="/img/loading.gif" lazyload alt="A brief chronology of Transformers models."></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">Transformer æ¶æ„</a> äº 2017 å¹´ 6 æœˆæ¨å‡ºã€‚åŸæœ¬ç ”ç©¶çš„é‡ç‚¹æ˜¯ç¿»è¯‘ä»»åŠ¡ã€‚éšåæ¨å‡ºäº†å‡ ä¸ªæœ‰å½±å“åŠ›çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬</p>
<ul>
<li><p><strong>2018 å¹´ 6 æœˆ</strong>: <a target="_blank" rel="noopener" href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT</a>, ç¬¬ä¸€ä¸ªé¢„è®­ç»ƒçš„ Transformer æ¨¡å‹ï¼Œç”¨äºå„ç§ NLP ä»»åŠ¡å¹¶è·å¾—æå¥½çš„ç»“æœ</p>
</li>
<li><p><strong>2018 å¹´ 10 æœˆ</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.04805">BERT</a>, å¦ä¸€ä¸ªå¤§å‹é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨ç”Ÿæˆæ›´å¥½çš„å¥å­æ‘˜è¦ï¼ˆä¸‹ä¸€ç« å°†è¯¦ç»†ä»‹ç»ï¼ï¼‰</p>
</li>
<li><p><strong>2019 å¹´ 2 æœˆ</strong>: <a target="_blank" rel="noopener" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2</a>, GPT çš„æ”¹è¿›ï¼ˆå¹¶ä¸”æ›´å¤§ï¼‰ç‰ˆæœ¬ï¼Œç”±äºé“å¾·é—®é¢˜æ²¡æœ‰ç«‹å³å…¬å¼€å‘å¸ƒ</p>
</li>
<li><p><strong>2019 å¹´ 10 æœˆ</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.01108">DistilBERT</a>, BERT çš„æç‚¼ç‰ˆæœ¬ï¼Œé€Ÿåº¦æé«˜ 60%ï¼Œå†…å­˜å‡è½» 40%ï¼Œä½†ä»ä¿ç•™ BERT 97% çš„æ€§èƒ½</p>
</li>
<li><p><strong>2019 å¹´ 10 æœˆ</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.13461">BART</a> å’Œ <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.10683">T5</a>, ä¸¤ä¸ªä½¿ç”¨ä¸åŸå§‹ Transformer æ¨¡å‹ç›¸åŒæ¶æ„çš„å¤§å‹é¢„è®­ç»ƒæ¨¡å‹ï¼ˆç¬¬ä¸€ä¸ªè¿™æ ·åšï¼‰</p>
</li>
<li><p><strong>2020 å¹´ 5 æœˆ</strong>, <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.14165">GPT-3</a>, GPT-2 çš„æ›´å¤§ç‰ˆæœ¬ï¼Œæ— éœ€å¾®è°ƒå³å¯åœ¨å„ç§ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼ˆç§°ä¸ºé›¶æ ·æœ¬å­¦ä¹ ï¼‰</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>å¤§ä½“ä¸Šï¼Œå®ƒä»¬å¯ä»¥åˆ†ä¸ºä¸‰ç±»ï¼š</p>
<ul>
<li><p>GPT-like (ä¹Ÿè¢«ç§°ä½œè‡ªå›å½’Transformeræ¨¡å‹, Decoder)</p>
</li>
<li><p>BERT-like (ä¹Ÿè¢«ç§°ä½œè‡ªåŠ¨ç¼–ç Transformeræ¨¡å‹, Encoder)</p>
</li>
<li><p>BART/T5-like (ä¹Ÿè¢«ç§°ä½œåºåˆ—åˆ°åºåˆ—çš„ Transformeræ¨¡å‹, Encoder + Decoder)</p>
</li>
</ul>
</li>
</ul>
<h3 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h3><p><img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/pretraining.svg" srcset="/img/loading.gif" lazyload alt="The pretraining of a language model is costly in both time and money."></p>
<p><img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/finetuning.svg" srcset="/img/loading.gif" lazyload alt="The fine-tuning of a language model is cheaper than pretraining in both time and money."></p>
<ul>
<li>é¢„è®­ç»ƒé€šå¸¸æ˜¯åœ¨éå¸¸å¤§é‡çš„æ•°æ®ä¸Šè¿›è¡Œçš„ã€‚å› æ­¤ï¼Œå®ƒéœ€è¦å¤§é‡çš„æ•°æ®ï¼Œè€Œä¸”è®­ç»ƒå¯èƒ½éœ€è¦å‡ å‘¨çš„æ—¶é—´ã€‚ å¦ä¸€æ–¹é¢ï¼Œå¾®è°ƒæ˜¯åœ¨æ¨¡å‹ç»è¿‡é¢„è®­ç»ƒåå®Œæˆçš„è®­ç»ƒã€‚è¦æ‰§è¡Œå¾®è°ƒï¼Œé¦–å…ˆéœ€è¦è·å–ä¸€ä¸ªç»è¿‡é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œç„¶åä½¿ç”¨ç‰¹å®šäºä»»åŠ¡çš„æ•°æ®é›†æ‰§è¡Œé¢å¤–çš„è®­ç»ƒã€‚ç­‰ç­‰ï¼Œä¸ºä»€ä¹ˆä¸ç›´æ¥ä¸ºæœ€åçš„ä»»åŠ¡è€Œè®­ç»ƒå‘¢ï¼Ÿæœ‰å‡ ä¸ªåŸå› ï¼š<ul>
<li>é¢„è®­ç»ƒæ¨¡å‹å·²ç»åœ¨ä¸å¾®è°ƒæ•°æ®é›†æœ‰ä¸€äº›ç›¸ä¼¼ä¹‹å¤„çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒã€‚å› æ­¤ï¼Œå¾®è°ƒè¿‡ç¨‹èƒ½å¤Ÿåˆ©ç”¨æ¨¡å‹åœ¨é¢„è®­ç»ƒæœŸé—´è·å¾—çš„çŸ¥è¯†ï¼ˆä¾‹å¦‚ï¼Œå¯¹äºNLPé—®é¢˜ï¼Œé¢„è®­ç»ƒæ¨¡å‹å°†å¯¹æ‚¨åœ¨ä»»åŠ¡ä¸­ä½¿ç”¨çš„è¯­è¨€æœ‰æŸç§ç»Ÿè®¡è§„å¾‹ä¸Šçš„ç†è§£ï¼‰ã€‚</li>
<li>ç”±äºé¢„è®­ç»ƒæ¨¡å‹å·²ç»åœ¨å¤§é‡æ•°æ®ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå› æ­¤å¾®è°ƒéœ€è¦æ›´å°‘çš„æ•°æ®æ¥è·å¾—ä¸é”™çš„ç»“æœã€‚</li>
<li>å‡ºäºåŒæ ·çš„åŸå› ï¼Œè·å¾—å¥½ç»“æœæ‰€éœ€çš„æ—¶é—´å’Œèµ„æºè¦å°‘å¾—å¤š</li>
</ul>
</li>
</ul>
<blockquote>
<p>å¾®è°ƒæ¨¡å‹å…·æœ‰è¾ƒä½çš„æ—¶é—´ã€æ•°æ®ã€è´¢åŠ¡å’Œç¯å¢ƒæˆæœ¬ã€‚è¿­ä»£ä¸åŒçš„å¾®è°ƒæ–¹æ¡ˆä¹Ÿæ›´å¿«ã€æ›´å®¹æ˜“ï¼Œå› ä¸ºä¸å®Œæ•´çš„é¢„è®­ç»ƒç›¸æ¯”ï¼Œè®­ç»ƒçš„çº¦æŸæ›´å°‘ã€‚è¿™ä¸ªè¿‡ç¨‹ä¹Ÿä¼šæ¯”ä»å¤´å¼€å§‹çš„è®­ç»ƒï¼ˆé™¤éä½ æœ‰å¾ˆå¤šæ•°æ®ï¼‰å–å¾—æ›´å¥½çš„æ•ˆæœï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ åº”è¯¥æ€»æ˜¯å°è¯•åˆ©ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„æ¨¡å‹â€”ä¸€ä¸ªå°½å¯èƒ½æ¥è¿‘ä½ æ‰‹å¤´çš„ä»»åŠ¡çš„æ¨¡å‹â€”å¹¶å¯¹å…¶è¿›è¡Œå¾®è°ƒã€‚ï¼ˆå¤§å¤šæ•°åœºæ™¯ä¸‹ï¼Œä½ å…¶å®éƒ½æ²¡æœ‰è¶³å¤Ÿé‡çš„æ•°æ®orzï¼‰</p>
</blockquote>
<h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202408051003943.png" srcset="/img/loading.gif" lazyload alt="Architecture of a Transformers models" style="zoom:50%;">

<ul>
<li><p>ç»“æ„ä»‹ç»</p>
<ul>
<li><p><strong>Encoder (å·¦ä¾§)</strong>: ç¼–ç å™¨æ¥æ”¶è¾“å…¥å¹¶æ„å»ºå…¶è¡¨ç¤ºï¼ˆå…¶ç‰¹å¾ï¼‰ã€‚è¿™æ„å‘³ç€å¯¹æ¨¡å‹è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥ä»è¾“å…¥ä¸­è·å¾—ç†è§£ã€‚</p>
<img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202408050956329.png" srcset="/img/loading.gif" lazyload alt="image-20240805095646242" style="zoom:50%;">

<blockquote>
<p>å°†Sentenceä¸­çš„æ¯ä¸€ä¸ªå•è¯ï¼Œé€šè¿‡self-attentionæå–å®ƒçš„contextå’Œå®ƒæœ¬èº«çš„å«ä¹‰ï¼Œå¹¶è½¬æ¢ä¸ºä¸€ä¸ªå¤šç»´çš„å‘é‡ï¼ˆä¾‹å¦‚768çº¬ï¼‰ï¼Œè¿™ä¸ªå‘é‡å®é™…ä¸Šå°±å¯ä»¥ç†è§£ä¸ºï¼Œä¿å­˜äº†å½“å‰è¯åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸­çš„â€è¯­ä¹‰â€œã€‚å› æ­¤è¿™ä¸ªè¯­ä¹‰vectoråç»­å°±å¯ä»¥è¢«ç”¨æ¥å®ç°æ›´å¤šçš„NLPä»»åŠ¡ã€‚ï¼ˆä¾‹å¦‚åŠ DNNï¼Œåšæƒ…æ„Ÿåˆ†ç±»ä¹‹ç±»çš„äº‹å„¿ï¼‰</p>
</blockquote>
</li>
<li><p><strong>Decoder (å³ä¾§)</strong>: è§£ç å™¨ä½¿ç”¨ç¼–ç å™¨çš„è¡¨ç¤ºï¼ˆç‰¹å¾ï¼‰ä»¥åŠå…¶ä»–è¾“å…¥æ¥ç”Ÿæˆç›®æ ‡åºåˆ—ã€‚è¿™æ„å‘³ç€è¯¥æ¨¡å‹å·²é’ˆå¯¹ç”Ÿæˆè¾“å‡ºè¿›è¡Œäº†ä¼˜åŒ–ã€‚</p>
<img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202408051007934.png" srcset="/img/loading.gif" lazyload alt="image-20240805100710856" style="zoom:50%;">

<blockquote>
<p>é€šè¿‡Masked Self-Attentionï¼ŒæŠŠå³è¾¹é®ä½ï¼Œåªæš´éœ²å·¦è¾¹ç»™Decoderï¼Œå¹¶è®©å…¶è¾“å‡ºå³è¾¹ã€‚Good at Causal Language Modeling(Guessing the next word in the sentence).</p>
</blockquote>
</li>
<li><p><strong>Seq2Seq</strong>: Encoder-Decoderæ¥åœ¨ä¸€èµ·ã€‚</p>
</li>
</ul>
  <img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202408051015069.png" srcset="/img/loading.gif" lazyload alt="image-20240805101526009" style="zoom:50%;">

<blockquote>
<ul>
<li>Encoderå°†è¾“å…¥Sentenceæ‰€è¡¨è¿°çš„è¯­ä¹‰æŠ½å–å‡ºæ¥ï¼Œå¹¶ä¸”åœ¨Decoderç”ŸæˆæœŸé—´ä½¿ç”¨(Encoderåœ¨è¾“å‡ºäº†å¯¹åº”çš„è¯­ä¹‰åï¼Œä¾¿ä¸åœ¨Decoderç”Ÿæˆçš„è¿‡ç¨‹ä¸­èµ·åˆ«çš„ä½œç”¨äº†ï¼ŒDecoderç”Ÿæˆæœ¬è´¨ä¸Šæ˜¯æ‹¿ç€Encoderçš„è¾“å‡ºä½œä¸ºè‡ªå·±çš„è¾“å…¥çš„ä¸€éƒ¨åˆ†çš„ã€‚</li>
<li>Decoderä¼šæ¥å—ä¸€ä¸ªç‰¹æ®Šçš„Start tokenï¼Œå’ŒEncoderè¾“å‡ºçš„è¯­ä¹‰ï¼Œå¼€å§‹ç”Ÿæˆæ–‡æœ¬ã€‚æ¯æ¬¡ç”Ÿæˆçš„æ–°çš„tokenï¼Œéƒ½ä¼šæ¥åœ¨ç°æœ‰çš„token sequenceæœ€åï¼Œå¹¶æˆä¸ºä¸€ä¸ªæ–°çš„token sequenceé‡æ–°è¾“å…¥Decoderï¼ŒDecoderä¼šä¸€ç›´è¾“å‡ºï¼Œç›´åˆ°é‡åˆ°æŸä¸ªç‰¹æ®Šçš„End tokenä¸ºæ­¢ã€‚(Encoderå°±ä½¿ç”¨äº†ä¸€æ¬¡ï¼ŒDecoderä¼šè¢«ä½¿ç”¨å¤šæ¬¡)</li>
<li>Encoderå’ŒDecoderæƒé‡ä¸ä¸€å®šæ˜¯å…±äº«çš„ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥åªä½¿ç”¨å…¶ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œä¾‹å¦‚Encoder or Decoder onlyï¼Œå»è§£å†³ä¸€äº›å®é™…ä»»åŠ¡ã€‚</li>
</ul>
</blockquote>
</li>
<li><p>è¿™äº›éƒ¨ä»¶ä¸­çš„æ¯ä¸€ä¸ªéƒ½å¯ä»¥ç‹¬ç«‹ä½¿ç”¨ï¼Œå…·ä½“å–å†³äºä»»åŠ¡ï¼š</p>
<ul>
<li><p><strong>Encoder-only models</strong>: é€‚ç”¨äºéœ€è¦ç†è§£è¾“å…¥çš„ä»»åŠ¡ï¼Œå¦‚å¥å­åˆ†ç±»å’Œå‘½åå®ä½“è¯†åˆ«ã€‚</p>
</li>
<li><p><strong>Decoder-only models</strong>: é€‚ç”¨äºç”Ÿæˆä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬ç”Ÿæˆã€‚</p>
</li>
<li><p><strong>Encoder-decoder models</strong> æˆ–è€… <strong>sequence-to-sequence models</strong>: é€‚ç”¨äºéœ€è¦æ ¹æ®è¾“å…¥è¿›è¡Œç”Ÿæˆçš„ä»»åŠ¡ï¼Œå¦‚ç¿»è¯‘æˆ–æ‘˜è¦ã€‚</p>
</li>
</ul>
</li>
<li><p>Attension Layer</p>
<ul>
<li>Transformeræ¨¡å‹çš„ä¸€ä¸ªå…³é”®ç‰¹æ€§æ˜¯<em>æ³¨æ„åŠ›å±‚</em>ã€‚äº‹å®ä¸Šï¼Œä»‹ç»Transformeræ¶æ„çš„æ–‡ç« çš„æ ‡é¢˜æ˜¯<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">â€œAttention Is All You Needâ€</a>ï¼è¿™ä¸€å±‚å°†å‘Šè¯‰æ¨¡å‹åœ¨å¤„ç†æ¯ä¸ªå•è¯çš„è¡¨ç¤ºæ—¶ï¼Œè¦ç‰¹åˆ«é‡è§†æ‚¨ä¼ é€’ç»™å®ƒçš„å¥å­ä¸­çš„æŸäº›å•è¯ï¼ˆå¹¶ä¸”æˆ–å¤šæˆ–å°‘åœ°å¿½ç•¥å…¶ä»–å•è¯ï¼‰ã€‚</li>
</ul>
</li>
</ul>
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers.svg" srcset="/img/loading.gif" lazyload alt="Architecture of a Transformers models" style="zoom:50%;">

<ul>
<li>åŸå§‹çš„Transformeræ¶æ„å¦‚ä¸‹æ‰€ç¤ºï¼Œç¼–ç å™¨åœ¨å·¦ä¾§ï¼Œè§£ç å™¨åœ¨å³ä¾§ï¼šè¯·æ³¨æ„ï¼Œè§£ç å™¨å—ä¸­çš„ç¬¬ä¸€ä¸ªæ³¨æ„åŠ›å±‚å…³æ³¨è§£ç å™¨çš„æ‰€æœ‰ï¼ˆè¿‡å»çš„ï¼‰è¾“å…¥ï¼Œä½†ç¬¬äºŒä¸ªæ³¨æ„åŠ›å±‚ä½¿ç”¨ç¼–ç å™¨çš„è¾“å‡ºã€‚å› æ­¤ï¼Œå®ƒå¯ä»¥è®¿é—®æ•´ä¸ªè¾“å…¥å¥å­ï¼Œä»¥æœ€å¥½åœ°é¢„æµ‹å½“å‰çš„è¯ã€‚è¿™éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºä¸åŒçš„è¯­è¨€å¯èƒ½æœ‰å°†å•è¯æ”¾åœ¨ä¸åŒé¡ºåºçš„è¯­æ³•è§„åˆ™ï¼Œæˆ–è€…å¥å­åé¢çš„ä¸€äº›ä¸Šä¸‹æ–‡å¯èƒ½æœ‰åŠ©äºç¡®å®šç»™å®šè¯çš„æœ€ä½³ç¿»è¯‘ã€‚æ³¨æ„åŠ›æ©ç ä¹Ÿå¯ä»¥åœ¨ç¼–ç å™¨/è§£ç å™¨ä¸­ä½¿ç”¨ï¼Œä»¥é˜²æ­¢æ¨¡å‹å…³æ³¨ä¸€äº›ç‰¹æ®Šè¯â€”â€”ä¾‹å¦‚ï¼Œç”¨äºä½¿æ‰€æœ‰è¾“å…¥åœ¨æ‰¹å¤„ç†å¥å­æ—¶å…·æœ‰ç›¸åŒé•¿åº¦çš„ç‰¹æ®Šå¡«å……è¯ã€‚</li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li><p>å½“æˆ‘ä»¬æ·±å…¥æ¢è®¨Transformersæ¨¡å‹æ—¶ï¼Œæ‚¨å°†çœ‹åˆ° æ¶æ„ã€å‚æ•°å’Œæ¨¡å‹ã€‚è¿™äº›æœ¯è¯­çš„å«ä¹‰ç•¥æœ‰ä¸åŒï¼š</p>
<ul>
<li><p><strong>Architecture</strong>: è¿™æ˜¯æ¨¡å‹çš„éª¨æ¶ â€” æ¯ä¸ªå±‚çš„å®šä¹‰ä»¥åŠæ¨¡å‹ä¸­å‘ç”Ÿçš„æ¯ä¸ªæ“ä½œã€‚</p>
</li>
<li><p><strong>Checkpoints</strong>: è¿™äº›æ˜¯å°†åœ¨ç»™æ¶æ„ä¸­ç»“æ„ä¸­åŠ è½½çš„æƒé‡ã€‚</p>
</li>
<li><p><strong>Model</strong>: è¿™æ˜¯ä¸€ä¸ªç¬¼ç»Ÿçš„æœ¯è¯­ï¼Œæ²¡æœ‰â€œæ¶æ„â€æˆ–â€œå‚æ•°â€é‚£ä¹ˆç²¾ç¡®ï¼šå®ƒå¯ä»¥æŒ‡ä¸¤è€…ã€‚ä¸ºäº†é¿å…æ­§ä¹‰ï¼Œæœ¬è¯¾ç¨‹ä½¿ç”¨å°†ä½¿ç”¨æ¶æ„å’Œå‚æ•°ã€‚</p>
</li>
</ul>
</li>
<li><p>Bias and limitations: å…¶ä¸­æœ€å¤§çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œä¸ºäº†å¯¹å¤§é‡æ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œç ”ç©¶äººå‘˜é€šå¸¸ä¼šæœé›†æ‰€æœ‰ä»–ä»¬èƒ½æ‰¾åˆ°çš„å†…å®¹ï¼Œä¸­é—´å¯èƒ½å¤¹å¸¦ä¸€äº›æ„è¯†å½¢æ€æˆ–è€…ä»·å€¼è§‚çš„åˆ»æ¿å°è±¡ã€‚ å°½ç®¡ä¸€äº›å¤§æ¨¡å‹æ˜¯ä½¿ç”¨ç»è¿‡ç­›é€‰å’Œæ¸…æ´—åï¼Œæ˜æ˜¾ä¸­ç«‹çš„æ•°æ®é›†ä¸Šå»ºç«‹çš„çš„Transformeræ¨¡å‹ï¼Œä»ç„¶ä¼šæœ‰è¿™æ ·çš„é—®é¢˜å­˜åœ¨ã€‚å½“æ‚¨ä½¿ç”¨è¿™äº›å·¥å…·æ—¶ï¼Œæ‚¨éœ€è¦è®°ä½ï¼Œä½¿ç”¨çš„åŸå§‹æ¨¡å‹çš„æ—¶å€™ï¼Œå¾ˆå®¹æ˜“ç”Ÿæˆæ€§åˆ«æ­§è§†ã€ç§æ—ä¸»ä¹‰æˆ–æåŒå†…å®¹ã€‚è¿™ç§å›ºæœ‰åè§ä¸ä¼šéšç€å¾®è°ƒæ¨¡å‹è€Œä½¿æ¶ˆå¤±ã€‚</p>
</li>
<li><p>Summary: æ‚¨å¯ä»¥ä½¿ç”¨å®Œæ•´çš„ä½“ç³»ç»“æ„ï¼Œä¹Ÿå¯ä»¥ä»…ä½¿ç”¨ç¼–ç å™¨æˆ–è§£ç å™¨ï¼Œå…·ä½“å–å†³äºæ‚¨è¦è§£å†³çš„ä»»åŠ¡ç±»å‹ã€‚ä¸‹è¡¨æ€»ç»“äº†è¿™ä¸€ç‚¹ï¼š</p>
<table>
<thead>
<tr>
<th>æ¨¡å‹</th>
<th>ç¤ºä¾‹</th>
<th>ä»»åŠ¡</th>
</tr>
</thead>
<tbody><tr>
<td>ç¼–ç å™¨</td>
<td>ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa</td>
<td>å¥å­åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€ä»æ–‡æœ¬ä¸­æå–ç­”æ¡ˆ</td>
</tr>
<tr>
<td>è§£ç å™¨</td>
<td>CTRL, GPT, GPT-2, Transformer XL</td>
<td>æ–‡æœ¬ç”Ÿæˆ</td>
</tr>
<tr>
<td>ç¼–ç å™¨-è§£ç å™¨</td>
<td>BART, T5, Marian, mBART</td>
<td>æ–‡æœ¬æ‘˜è¦ã€ç¿»è¯‘ã€ç”Ÿæˆé—®é¢˜çš„å›ç­”</td>
</tr>
</tbody></table>
</li>
<li><p>Little test: <a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/en/chapter1/10?fw=pt">https://huggingface.co/learn/nlp-course/en/chapter1/10?fw=pt</a></p>
</li>
</ul>
<h1 id="Using-Transformers"><a href="#Using-Transformers" class="headerlink" title="Using Transformers"></a>Using Transformers</h1><h2 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><p>ç”±äºå‡ ä¹æ¯å¤©éƒ½åœ¨å‘å¸ƒæ–°æ¨¡å‹ï¼Œè€Œä¸”æ¯ç§æ¨¡å‹éƒ½æœ‰è‡ªå·±çš„å®ç°ï¼Œå› æ­¤å°è¯•å®ƒä»¬ç»éæ˜“äº‹ã€‚åˆ›å»ºğŸ¤— Transformersåº“å°±æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å®ƒçš„ç›®æ ‡æ˜¯æä¾›ä¸€ä¸ªAPIï¼Œé€šè¿‡å®ƒå¯ä»¥åŠ è½½ã€è®­ç»ƒå’Œä¿å­˜ä»»ä½•Transformeræ¨¡å‹ã€‚è¿™ä¸ªåº“çš„ä¸»è¦ç‰¹ç‚¹æ˜¯ï¼š</p>
<ul>
<li><p><strong>æ˜“äºä½¿ç”¨</strong>ï¼šä¸‹è½½ã€åŠ è½½å’Œä½¿ç”¨æœ€å…ˆè¿›çš„NLPæ¨¡å‹è¿›è¡Œæ¨ç†åªéœ€ä¸¤è¡Œä»£ç å³å¯å®Œæˆã€‚</p>
</li>
<li><p><strong>çµæ´»</strong>ï¼šæ‰€æœ‰å‹å·çš„æ ¸å¿ƒéƒ½æ˜¯ç®€å•çš„PyTorch <strong>nn.Module</strong> æˆ–è€… TensorFlow <strong>tf.kears.Model</strong>ï¼Œå¯ä»¥åƒå®ƒä»¬å„è‡ªçš„æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æ¡†æ¶ä¸­çš„ä»»ä½•å…¶ä»–æ¨¡å‹ä¸€æ ·è¿›è¡Œå¤„ç†ã€‚</p>
</li>
<li><p><strong>ç®€å•</strong>ï¼šå½“å‰ä½ç½®æ•´ä¸ªåº“å‡ ä¹æ²¡æœ‰ä»»ä½•æ‘˜è¦ã€‚â€œéƒ½åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­â€æ˜¯ä¸€ä¸ªæ ¸å¿ƒæ¦‚å¿µï¼šæ¨¡å‹çš„æ­£å‘ä¼ é€’å®Œå…¨å®šä¹‰åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼Œå› æ­¤ä»£ç æœ¬èº«æ˜¯å¯ä»¥ç†è§£çš„ï¼Œå¹¶ä¸”æ˜¯å¯ä»¥ç ´è§£çš„ã€‚</p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>æœ€åä¸€ä¸ªç‰¹æ€§ä½¿ğŸ¤— Transformersä¸å…¶ä»–MLåº“æˆªç„¶ä¸åŒã€‚è¿™äº›æ¨¡å‹<strong>ä¸æ˜¯åŸºäºé€šè¿‡æ–‡ä»¶å…±äº«çš„æ¨¡å—æ„å»ºçš„</strong>ï¼›ç›¸åï¼Œæ¯ä¸€ä¸ªæ¨¡å‹éƒ½æœ‰è‡ªå·±çš„èœå•ã€‚é™¤äº†ä½¿æ¨¡å‹æ›´åŠ å®¹æ˜“æ¥å—å’Œæ›´å®¹æ˜“ç†è§£ï¼Œè¿™è¿˜å…è®¸ä½ è½»æ¾åœ°åœ¨ä¸€ä¸ªæ¨¡å‹ä¸Šå®éªŒï¼Œè€Œä¸”ä¸å½±å“å…¶ä»–æ¨¡å‹ã€‚</p>
</blockquote>
<h2 id="How-Pipeline-Works"><a href="#How-Pipeline-Works" class="headerlink" title="How Pipeline Works"></a>How Pipeline Works</h2><ul>
<li>Demo</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>classifier = pipeline(<span class="hljs-string">"sentiment-analysis"</span>)<br>classifier(<br>    [<br>        <span class="hljs-string">"I've been waiting for a HuggingFace course my whole life."</span>,<br>        <span class="hljs-string">"I hate this so much!"</span>,<br>    ]<br>)<br><br><span class="hljs-comment"># Result: [{'label': 'POSITIVE', 'score': 0.9598047137260437}, {'label': 'NEGATIVE', 'score': 0.9994558095932007}]</span><br></code></pre></td></tr></tbody></table></figure>

<p>æ­¤ç®¡é“å°†ä¸‰ä¸ªæ­¥éª¤ç»„åˆåœ¨ä¸€èµ·ï¼šé¢„å¤„ç†ã€é€šè¿‡æ¨¡å‹ä¼ é€’è¾“å…¥å’Œåå¤„ç†ï¼š</p>
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg" srcset="/img/loading.gif" lazyload alt="The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head." style="zoom:50%;">

<h3 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h3><ul>
<li>ä½¿ç”¨åˆ†è¯å™¨è¿›è¡Œé¢„å¤„ç†ï¼š æˆ‘ä»¬ç®¡é“çš„ç¬¬ä¸€æ­¥æ˜¯å°†æ–‡æœ¬è¾“å…¥è½¬æ¢ä¸ºæ¨¡å‹èƒ½å¤Ÿç†è§£çš„æ•°å­—ã€‚ ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨<em>tokenizer</em>ï¼Œè´Ÿè´£ï¼š<ul>
<li>å°†è¾“å…¥æ‹†åˆ†ä¸ºå•è¯ã€å­å•è¯æˆ–ç¬¦å·ï¼ˆå¦‚æ ‡ç‚¹ç¬¦å·ï¼‰ï¼Œç§°ä¸ºæ ‡è®°(<em>token</em>)</li>
<li>å°†æ¯ä¸ªæ ‡è®°(token)æ˜ å°„åˆ°ä¸€ä¸ªæ•´æ•°</li>
<li>æ·»åŠ å¯èƒ½å¯¹æ¨¡å‹æœ‰ç”¨çš„å…¶ä»–è¾“å…¥</li>
</ul>
</li>
<li>æ‰€æœ‰è¿™äº›é¢„å¤„ç†éƒ½éœ€è¦ä»¥ä¸æ¨¡å‹é¢„è®­ç»ƒæ—¶å®Œå…¨ç›¸åŒçš„æ–¹å¼å®Œæˆï¼Œå› æ­¤æˆ‘ä»¬é¦–å…ˆéœ€è¦ä»<a target="_blank" rel="noopener" href="https://huggingface.co/models">Model Hub</a>ä¸­ä¸‹è½½è¿™äº›ä¿¡æ¯ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨<code>AutoTokenizer</code>ç±»åŠå…¶<code>from_pretrained()</code>æ–¹æ³•ã€‚ä½¿ç”¨æˆ‘ä»¬æ¨¡å‹çš„æ£€æŸ¥ç‚¹åç§°ï¼Œå®ƒå°†è‡ªåŠ¨è·å–ä¸æ¨¡å‹çš„æ ‡è®°å™¨ç›¸å…³è”çš„æ•°æ®ï¼Œå¹¶å¯¹å…¶è¿›è¡Œç¼“å­˜ï¼ˆå› æ­¤åªæœ‰åœ¨æ‚¨ç¬¬ä¸€æ¬¡è¿è¡Œä¸‹é¢çš„ä»£ç æ—¶æ‰ä¼šä¸‹è½½ï¼‰ã€‚</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>checkpoint = <span class="hljs-string">"distilbert-base-uncased-finetuned-sst-2-english"</span><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>ä¸€æ—¦æˆ‘ä»¬æœ‰äº†tokenizerï¼Œæˆ‘ä»¬å°±å¯ä»¥ç›´æ¥å°†æˆ‘ä»¬çš„å¥å­ä¼ é€’ç»™å®ƒï¼Œç„¶åæˆ‘ä»¬å°±ä¼šå¾—åˆ°è¿”å›çš„dictionaryï¼Œå®ƒå¯ä»¥æä¾›ç»™æˆ‘ä»¬çš„æ¨¡å‹ï¼The only thing left to do is to convert the list of input IDs to tensors.</p>
</blockquote>
<ul>
<li>æ‚¨å¯ä»¥ä½¿ç”¨Transformersï¼Œè€Œä¸å¿…æ‹…å¿ƒä½¿ç”¨çš„æ˜¯å“ªä¸ªæœºå™¨å­¦ä¹ æ¡†æ¶ä½œä¸ºåç«¯ï¼›å®ƒå¯èƒ½æ˜¯PyTorchæˆ–TensorFlowï¼Œæˆ–è€…å¯¹äºæŸäº›æ¨¡å‹æ¥è¯´æ˜¯Flaxã€‚ç„¶è€Œï¼ŒTransformeræ¨¡å‹åªæ¥å—å¼ é‡ä½œä¸ºè¾“å…¥ã€‚ä¸ºäº†æŒ‡å®šæˆ‘ä»¬æƒ³è¦è¿”å›çš„å¼ é‡ç±»å‹ï¼ˆPyTorchã€TensorFlowæˆ–æ™®é€šçš„NumPyï¼‰ï¼Œæˆ‘ä»¬ä½¿ç”¨<code>return_tensors</code>å‚æ•°ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">raw_inputs = [<br>    <span class="hljs-string">"I've been waiting for a HuggingFace course my whole life."</span>,<br>    <span class="hljs-string">"I hate this so much!"</span>,<br>]<br>inputs = tokenizer(raw_inputs, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">"pt"</span>)<br><span class="hljs-built_in">print</span>(inputs)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>ä¸è¦æ‹…å¿ƒå¡«å……å’Œæˆªæ–­çš„é—®é¢˜ï¼Œæˆ‘ä»¬ç¨åä¼šè§£é‡Šè¿™äº›ã€‚è¿™é‡Œè¦è®°ä½çš„ä¸»è¦äº‹é¡¹æ˜¯æ‚¨å¯ä»¥ä¼ é€’ä¸€ä¸ªå¥å­æˆ–ä¸€ä¸ªå¥å­åˆ—è¡¨ï¼Œå¹¶ä¸”å¯ä»¥æŒ‡å®šæ‚¨æƒ³è¦è¿”å›çš„å¼ é‡ç±»å‹ï¼ˆå¦‚æœæ²¡æœ‰ä¼ é€’ç±»å‹ï¼Œæ‚¨å°†å¾—åˆ°ä¸€ä¸ªåˆ—è¡¨åˆ—è¡¨ä½œä¸ºç»“æœï¼‰ã€‚ä»¥ä¸‹æ˜¯PyTorchå¼ é‡å½¢å¼çš„ç»“æœç¤ºä¾‹ï¼š</p>
</blockquote>
<figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">{</span><br>    'input_ids'<span class="hljs-punctuation">:</span> tensor(<span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">[</span>  <span class="hljs-number">101</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">1045</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">1005</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">2310</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">2042</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">3403</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">2005</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">1037</span><span class="hljs-punctuation">,</span> <span class="hljs-number">17662</span><span class="hljs-punctuation">,</span> <span class="hljs-number">12172</span><span class="hljs-punctuation">,</span> <span class="hljs-number">2607</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">2026</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">2878</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">2166</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">1012</span><span class="hljs-punctuation">,</span>   <span class="hljs-number">102</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">[</span>  <span class="hljs-number">101</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">1045</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">5223</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">2023</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">2061</span><span class="hljs-punctuation">,</span>  <span class="hljs-number">2172</span><span class="hljs-punctuation">,</span>   <span class="hljs-number">999</span><span class="hljs-punctuation">,</span>   <span class="hljs-number">102</span><span class="hljs-punctuation">,</span>     <span class="hljs-number">0</span><span class="hljs-punctuation">,</span>     <span class="hljs-number">0</span><span class="hljs-punctuation">,</span>     <span class="hljs-number">0</span><span class="hljs-punctuation">,</span>     <span class="hljs-number">0</span><span class="hljs-punctuation">,</span>     <span class="hljs-number">0</span><span class="hljs-punctuation">,</span>     <span class="hljs-number">0</span><span class="hljs-punctuation">,</span>     <span class="hljs-number">0</span><span class="hljs-punctuation">,</span>     <span class="hljs-number">0</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span>)<span class="hljs-punctuation">,</span> <br>    'attention_mask'<span class="hljs-punctuation">:</span> tensor(<span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span>)<br><span class="hljs-punctuation">}</span><br></code></pre></td></tr></tbody></table></figure>



<h3 id="Going-through-the-model"><a href="#Going-through-the-model" class="headerlink" title="Going through the model"></a>Going through the model</h3><ul>
<li>æˆ‘ä»¬å¯ä»¥åƒä½¿ç”¨æ ‡è®°å™¨ä¸€æ ·ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ã€‚Transformersæä¾›äº†ä¸€ä¸ª<code>AutoModel</code>ç±»ï¼Œè¯¥ç±»è¿˜å…·æœ‰<code>from_pretrained()</code>æ–¹æ³•ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel<br><br>checkpoint = <span class="hljs-string">"distilbert-base-uncased-finetuned-sst-2-english"</span><br>model = AutoModel.from_pretrained(checkpoint)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>åœ¨è¿™æ®µä»£ç ç‰‡æ®µä¸­ï¼Œæˆ‘ä»¬ä¸‹è½½äº†ä¹‹å‰åœ¨ç®¡é“ä¸­ä½¿ç”¨è¿‡çš„åŒä¸€ä¸ªæ£€æŸ¥ç‚¹ï¼ˆå®é™…ä¸Šåº”è¯¥å·²ç»è¢«ç¼“å­˜äº†ï¼‰ï¼Œå¹¶ç”¨å®ƒå®ä¾‹åŒ–äº†ä¸€ä¸ªæ¨¡å‹ã€‚è¿™ä¸ªæ¶æ„åªåŒ…å«åŸºç¡€çš„Transformeræ¨¡å—ï¼šç»™å®šä¸€äº›è¾“å…¥ï¼Œå®ƒè¾“å‡ºæˆ‘ä»¬ç§°ä¹‹ä¸ºéšè—çŠ¶æ€ï¼Œä¹Ÿè¢«ç§°ä¸ºç‰¹å¾çš„ä¸œè¥¿ã€‚å¯¹äºæ¯ä¸ªæ¨¡å‹è¾“å…¥ï¼Œæˆ‘ä»¬å°†æ£€ç´¢åˆ°ä¸€ä¸ªé«˜ç»´å‘é‡ï¼Œä»£è¡¨Transformeræ¨¡å‹å¯¹é‚£ä¸ªè¾“å…¥çš„ä¸Šä¸‹æ–‡ç†è§£ã€‚è™½ç„¶è¿™äº›éšè—çŠ¶æ€æœ¬èº«å¯èƒ½å¾ˆæœ‰ç”¨ï¼Œä½†å®ƒä»¬é€šå¸¸æ˜¯æ¨¡å‹å¦ä¸€éƒ¨åˆ†çš„è¾“å…¥ã€‚</p>
</blockquote>
<ul>
<li>High dimension vectorï¼ŒTransformersæ¨¡å—çš„çŸ¢é‡è¾“å‡ºé€šå¸¸è¾ƒå¤§ã€‚å®ƒé€šå¸¸æœ‰ä¸‰ä¸ªç»´åº¦ï¼š<ul>
<li><strong>Batch size</strong>: ä¸€æ¬¡å¤„ç†çš„åºåˆ—æ•°ï¼ˆåœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ä¸º2ï¼‰ã€‚</li>
<li><strong>Sequence length</strong>: åºåˆ—çš„æ•°å€¼è¡¨ç¤ºçš„é•¿åº¦ï¼ˆåœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ä¸º16ï¼‰ã€‚</li>
<li><strong>Hidden size</strong>: æ¯ä¸ªæ¨¡å‹è¾“å…¥çš„å‘é‡ç»´åº¦ã€‚</li>
</ul>
</li>
</ul>
<blockquote>
<p>ç”±äºæœ€åä¸€ä¸ªå€¼ï¼Œå®ƒè¢«ç§°ä¸ºâ€œé«˜ç»´â€ã€‚éšè—çš„å¤§å°å¯èƒ½éå¸¸å¤§ï¼ˆ768é€šå¸¸ç”¨äºè¾ƒå°çš„å‹å·ï¼Œè€Œåœ¨è¾ƒå¤§çš„å‹å·ä¸­ï¼Œè¿™å¯èƒ½è¾¾åˆ°3072æˆ–æ›´å¤§ï¼‰ã€‚</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">outputs = model(**inputs)<br><span class="hljs-built_in">print</span>(outputs.last_hidden_state.shape)<br><br><span class="hljs-comment"># Result torch.Size([2, 16, 768])</span><br></code></pre></td></tr></tbody></table></figure>



<h3 id="Model-heads-Making-sense-out-of-numbers"><a href="#Model-heads-Making-sense-out-of-numbers" class="headerlink" title="Model heads: Making sense out of numbers"></a>Model heads: Making sense out of numbers</h3><img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg" srcset="/img/loading.gif" lazyload alt="A Transformer network alongside its head." style="zoom:50%;">

<ul>
<li><p>æ¨¡å‹å¤´éƒ¨æ¥æ”¶é«˜ç»´éšè—çŠ¶æ€å‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å®ƒä»¬æŠ•å½±åˆ°ä¸åŒçš„ç»´åº¦ã€‚å®ƒä»¬é€šå¸¸ç”±ä¸€ä¸ªæˆ–å‡ ä¸ªçº¿æ€§å±‚ç»„æˆï¼šTransformeræ¨¡å‹çš„è¾“å‡ºç›´æ¥å‘é€åˆ°æ¨¡å‹å¤´éƒ¨è¿›è¡Œå¤„ç†ã€‚</p>
</li>
<li><p>æ¨¡å‹ç”±å…¶åµŒå…¥å±‚å’Œéšåçš„å±‚è¡¨ç¤ºã€‚åµŒå…¥å±‚å°†æ ‡è®°åŒ–è¾“å…¥ä¸­çš„æ¯ä¸ªè¾“å…¥IDè½¬æ¢ä¸ºè¡¨ç¤ºç›¸å…³æ ‡è®°çš„å‘é‡ã€‚éšåçš„å±‚ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æ“ä½œè¿™äº›å‘é‡ï¼Œä»¥äº§ç”Ÿå¥å­çš„æœ€ç»ˆè¡¨ç¤ºã€‚</p>
</li>
<li><p>Transformersä¸­æœ‰è®¸å¤šä¸åŒçš„ä½“ç³»ç»“æ„ï¼Œæ¯ç§ä½“ç³»ç»“æ„éƒ½æ˜¯å›´ç»•å¤„ç†ç‰¹å®šä»»åŠ¡è€Œè®¾è®¡çš„ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªéè¯¦å°½çš„åˆ—è¡¨ï¼š</p>
<ul>
<li><p><code>*Model</code> (retrieve the hidden states)</p>
</li>
<li><p><code>*ForCausalLM</code></p>
</li>
<li><p><code>*ForMaskedLM</code></p>
</li>
<li><p><code>*ForMultipleChoice</code></p>
</li>
<li><p><code>*ForQuestionAnswering</code></p>
</li>
<li><p><code>*ForSequenceClassification</code></p>
</li>
<li><p><code>*ForTokenClassification</code></p>
</li>
<li><p>ä»¥åŠå…¶ä»–</p>
</li>
</ul>
</li>
<li><p>å¯¹äºæˆ‘ä»¬çš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¸¦æœ‰åºåˆ—åˆ†ç±»å¤´çš„æ¨¡å‹ï¼ˆèƒ½å¤Ÿå°†å¥å­åˆ†ç±»ä¸ºè‚¯å®šæˆ–å¦å®šï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å®é™…ä¸Šä¸ä¼šä½¿ç”¨<code>AutoModel</code>ç±»ï¼Œè€Œæ˜¯ä½¿ç”¨<code>AutoModelForSequenceClassification</code>ï¼š</p>
</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification<br><br>checkpoint = <span class="hljs-string">"distilbert-base-uncased-finetuned-sst-2-english"</span><br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint)<br>outputs = model(**inputs)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬è§‚å¯Ÿè¾“å‡ºçš„å½¢çŠ¶ï¼Œç»´åº¦å°†ä½å¾—å¤šï¼šæ¨¡å‹å¤´å°†æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„é«˜ç»´å‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºåŒ…å«ä¸¤ä¸ªå€¼çš„å‘é‡ã€‚å› ä¸ºæˆ‘ä»¬åªæœ‰ä¸¤ä¸ªå¥å­å’Œä¸¤ä¸ªæ ‡ç­¾ï¼Œæ‰€ä»¥æˆ‘ä»¬ä»æ¨¡å‹ä¸­å¾—åˆ°çš„ç»“æœæ˜¯2 x 2çš„å½¢çŠ¶ã€‚</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(outputs.logits.shape)<br><br><span class="hljs-comment"># torch.Size([2, 2])</span><br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>ä»€ä¹ˆæ˜¯æ¨¡å‹çš„Headå±‚ï¼Ÿ ä¸€ä¸ªé™„åŠ ç»„ä»¶ï¼Œé€šå¸¸ç”±ä¸€ä¸ªæˆ–å‡ ä¸ªå±‚ç»„æˆï¼Œç”¨äºå°†Transformerçš„é¢„æµ‹è½¬æ¢ä¸ºç‰¹å®šäºä»»åŠ¡çš„è¾“å‡ºã€‚</li>
</ul>
<h3 id="Postprocessing-the-output"><a href="#Postprocessing-the-output" class="headerlink" title="Postprocessing the output"></a>Postprocessing the output</h3><ul>
<li>æˆ‘ä»¬ä»æ¨¡å‹ä¸­å¾—åˆ°çš„è¾“å‡ºå€¼æœ¬èº«å¹¶ä¸ä¸€å®šæœ‰æ„ä¹‰ï¼Œæˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹ç¬¬ä¸€å¥ä¸º<code>[-1.5607, 1.6123]</code>ï¼Œç¬¬äºŒå¥ä¸º<code>[ 4.1692, -3.3464]</code>ã€‚è¿™äº›ä¸æ˜¯æ¦‚ç‡ï¼Œè€Œæ˜¯<em>logits</em>ï¼Œå³æ¨¡å‹æœ€åä¸€å±‚è¾“å‡ºçš„åŸå§‹éæ ‡å‡†åŒ–åˆ†æ•°ã€‚è¦è½¬æ¢ä¸ºæ¦‚ç‡ï¼Œå®ƒä»¬éœ€è¦ç»è¿‡<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Softmax_function">SoftMax</a>å±‚ï¼ˆæ‰€æœ‰Transformersæ¨¡å‹è¾“å‡ºlogitsï¼Œå› ä¸ºç”¨äºè®­ç»ƒçš„æŸè€—å‡½æ•°é€šå¸¸ä¼šå°†æœ€åçš„æ¿€æ´»å‡½æ•°ï¼ˆå¦‚SoftMaxï¼‰ä¸å®é™…æŸè€—å‡½æ•°ï¼ˆå¦‚äº¤å‰ç†µï¼‰èåˆï¼‰ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>predictions = torch.nn.functional.softmax(outputs.logits, dim=-<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(predictions)<br><br><span class="hljs-comment"># tensor([[4.0195e-02, 9.5980e-01], [9.9946e-01, 5.4418e-04]], grad_fn=&lt;SoftmaxBackward&gt;)</span><br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>ç°åœ¨æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ¨¡å‹é¢„æµ‹ç¬¬ä¸€å¥ä¸º<code>[0.0402, 0.9598]</code>ï¼Œç¬¬äºŒå¥ä¸º<code>[0.9995, 0.0005]</code>ã€‚è¿™äº›æ˜¯å¯è¯†åˆ«çš„æ¦‚ç‡åˆ†æ•°ã€‚ä¸ºäº†è·å¾—æ¯ä¸ªä½ç½®å¯¹åº”çš„æ ‡ç­¾ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ¨¡å‹é…ç½®çš„<code>id2label</code>å±æ€§ï¼ˆä¸‹ä¸€èŠ‚å°†å¯¹æ­¤è¿›è¡Œè¯¦ç»†ä»‹ç»ï¼‰ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">model.config.id2label<br><br><span class="hljs-comment"># Result {0: 'NEGATIVE', 1: 'POSITIVE'}</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<ul>
<li><p>ç¬¬ä¸€å¥ï¼šå¦å®šï¼š0.0402ï¼Œè‚¯å®šï¼š0.9598</p>
</li>
<li><p>ç¬¬äºŒå¥ï¼šå¦å®šï¼š0.9995ï¼Œè‚¯å®šï¼š0.0005</p>
</li>
</ul>
</blockquote>
<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>ç®¡é“çš„ä¸‰ä¸ªæ­¥éª¤ï¼š<ul>
<li>ä½¿ç”¨æ ‡è®°åŒ–å™¨è¿›è¡Œé¢„å¤„ç†ï¼ˆæ˜¯å°†æ–‡æœ¬è½¬æ¢ä¸ºå•è¯æˆ–å­è¯åºåˆ—çš„è¿‡ç¨‹ã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œæ–‡æœ¬é€šå¸¸æ˜¯ç”±ä¸€ç³»åˆ—å•è¯æˆ–å­è¯ç»„æˆçš„ï¼Œè€Œåˆ†è¯å™¨çš„ä»»åŠ¡å°±æ˜¯å°†è¿™äº›å•è¯æˆ–å­è¯ä»æ–‡æœ¬ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œå¹¶å°†å®ƒä»¬è½¬æ¢ä¸ºè®¡ç®—æœºå¯ä»¥å¤„ç†çš„æ•°å­—è¡¨ç¤ºã€‚ï¼‰</li>
<li>é€šè¿‡æ¨¡å‹ä¼ é€’è¾“å…¥ï¼ˆæ˜¯å°†å•è¯æˆ–å­è¯è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºçš„è¿‡ç¨‹ã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œå•è¯æˆ–å­è¯é€šå¸¸è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªé«˜ç»´åº¦çš„ç¨€ç–å‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªç»´åº¦å¯¹åº”ä¸€ä¸ªå•è¯æˆ–å­è¯çš„ç‰¹å¾ã€‚ç„¶åå†æŠŠEmbeddingå¡å…¥æ¨¡å‹ä¸­ï¼Œæ‹¿åˆ°è¾“å‡ºçš„Logitsï¼‰</li>
<li>åå¤„ç†ï¼ˆå°†Logitså¡å…¥Softmaxä¸­ï¼Œæ‹¿åˆ°æœ€åçš„æ¦‚ç‡ç»“æœï¼‰</li>
</ul>
</li>
</ul>
<h2 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h2><ul>
<li><p>AutoModelç±»åŠå…¶æ‰€æœ‰ç›¸å…³é¡¹å®é™…ä¸Šæ˜¯å¯¹åº“ä¸­å„ç§å¯ç”¨æ¨¡å‹çš„ç®€å•åŒ…è£…ã€‚å®ƒæ˜¯ä¸€ä¸ªèªæ˜çš„åŒ…è£…å™¨ï¼Œå› ä¸ºå®ƒå¯ä»¥è‡ªåŠ¨çŒœæµ‹checkpointçš„é€‚å½“architectureï¼Œç„¶åç”¨è¯¥ä½“ç³»ç»“æ„å®ä¾‹åŒ–æ¨¡å‹ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ‚¨çŸ¥é“è¦ä½¿ç”¨çš„æ¨¡å‹ç±»å‹ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ç›´æ¥å®šä¹‰å…¶ä½“ç³»ç»“æ„çš„ç±»ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™æ˜¯å¦‚ä½•ä¸BERTæ¨¡å‹ä¸€èµ·å·¥ä½œçš„ã€‚</p>
</li>
<li><p>Create a Transformer</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, BertModel<br><br><span class="hljs-comment"># Building the config</span><br>config = BertConfig()<br><br><span class="hljs-comment"># Building the model from the config</span><br>model = BertModel(config)<br><br><span class="hljs-comment"># ä»é»˜è®¤é…ç½®åˆ›å»ºæ¨¡å‹ä¼šä½¿ç”¨éšæœºå€¼å¯¹å…¶è¿›è¡Œåˆå§‹åŒ–ã€‚Model is randomly initialized!</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>è¯¥æ¨¡å‹å¯ä»¥åœ¨è¿™ç§çŠ¶æ€ä¸‹ä½¿ç”¨ï¼Œä½†ä¼šè¾“å‡ºèƒ¡è¨€ä¹±è¯­ï¼›é¦–å…ˆéœ€è¦å¯¹å…¶è¿›è¡Œè®­ç»ƒã€‚ä¸ºäº†é¿å…ä¸å¿…è¦çš„é‡å¤å·¥ä½œï¼Œå¿…é¡»èƒ½å¤Ÿå…±äº«å’Œé‡ç”¨å·²ç»è®­ç»ƒè¿‡çš„æ¨¡å‹ã€‚</p>
</blockquote>
</li>
<li><p>Load a Transformer</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel<br><br>model = BertModel.from_pretrained(<span class="hljs-string">"bert-base-cased"</span>)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>æˆ‘ä»¬å¯ä»¥å°†BertModelæ›¿æ¢ä¸ºç­‰ä»·çš„AutoModelç±»ã€‚æˆ‘ä»¬å°†è¿™æ ·åšï¼Œå› ä¸ºè¿™ä¼šäº§ç”Ÿä¸checkpointæ— å…³çš„ä»£ç ï¼›å¦‚æœæ‚¨çš„ä»£ç é€‚ç”¨äºä¸€ä¸ªcheckpointï¼Œå®ƒåº”è¯¥å¯ä»¥æ— ç¼åœ°é€‚ç”¨äºå¦ä¸€ä¸ªã€‚å³ä½¿æ¶æ„ä¸åŒï¼Œåªè¦æ£€æŸ¥ç‚¹æ˜¯ä¸ºç±»ä¼¼ä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼Œæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼‰è®­ç»ƒçš„ï¼Œè¿™ä¹Ÿé€‚ç”¨ã€‚</p>
<p>åœ¨ä¸Šé¢çš„ä»£ç ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨BertConfigï¼Œè€Œæ˜¯é€šè¿‡bert-base-casedæ ‡è¯†ç¬¦åŠ è½½äº†ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªç”±BERTçš„ä½œè€…è‡ªå·±è®­ç»ƒçš„æ¨¡å‹æ£€æŸ¥ç‚¹ï¼›æ‚¨å¯ä»¥åœ¨å…¶æ¨¡å‹å¡ç‰‡ä¸­æ‰¾åˆ°æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚</p>
<p>è¿™ä¸ªæ¨¡å‹ç°åœ¨å·²ç”¨æ£€æŸ¥ç‚¹çš„æ‰€æœ‰æƒé‡åˆå§‹åŒ–ã€‚<strong>å®ƒå¯ä»¥ç›´æ¥ç”¨äºå®ƒæ‰€è®­ç»ƒçš„ä»»åŠ¡ä¸Šçš„æ¨ç†ï¼Œä¹Ÿå¯ä»¥åœ¨æ–°ä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒã€‚</strong>é€šè¿‡ä½¿ç”¨é¢„è®­ç»ƒæƒé‡è€Œä¸æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒï¼Œæˆ‘ä»¬å¯ä»¥å¿«é€Ÿå–å¾—è‰¯å¥½çš„ç»“æœã€‚</p>
<p>æƒé‡å·²ç»è¢«ä¸‹è½½å¹¶ç¼“å­˜ï¼ˆå› æ­¤future calls to the from_pretrained()æ–¹æ³•ä¸ä¼šé‡æ–°ä¸‹è½½å®ƒä»¬ï¼‰ï¼Œç¼“å­˜æ–‡ä»¶å¤¹é»˜è®¤ä¸º~/.cache/huggingface/transformersã€‚<strong>æ‚¨å¯ä»¥é€šè¿‡è®¾ç½®HF_HOMEç¯å¢ƒå˜é‡æ¥è‡ªå®šä¹‰æ‚¨çš„ç¼“å­˜æ–‡ä»¶å¤¹ã€‚</strong></p>
<p>ç”¨äºåŠ è½½æ¨¡å‹çš„æ ‡è¯†ç¬¦å¯ä»¥æ˜¯æ¨¡å‹ä¸­å¿ƒä¸Š<strong>ä»»ä½•ä¸BERTæ¶æ„å…¼å®¹çš„æ¨¡å‹çš„æ ‡è¯†ç¬¦</strong>ã€‚å®Œæ•´çš„å¯ç”¨BERTæ£€æŸ¥ç‚¹åˆ—è¡¨å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/models?other=bert">è¿™é‡Œ</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
</li>
<li><p>Save methods</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model.save_pretrained(<span class="hljs-string">"directory_on_my_computer"</span>)<br></code></pre></td></tr></tbody></table></figure>

<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">ls directory_on_my_computer<br><br>config.json pytorch_model.bin<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>config.json: æ‚¨å°†è¯†åˆ«æ„å»ºæ¨¡å‹ä½“ç³»ç»“æ„æ‰€éœ€çš„å±æ€§ã€‚è¯¥æ–‡ä»¶è¿˜åŒ…å«ä¸€äº›å…ƒæ•°æ®ï¼Œä¾‹å¦‚checkpointçš„æ¥æºä»¥åŠä¸Šæ¬¡ä¿å­˜æ£€æŸ¥ç‚¹æ—¶ä½¿ç”¨çš„Transformersç‰ˆæœ¬ã€‚</p>
<p><em>pytorch_model.bin</em>: <em>state dictionary</em>; å®ƒåŒ…å«æ¨¡å‹çš„æ‰€æœ‰æƒé‡ã€‚</p>
<p>è¿™ä¸¤ä¸ªæ–‡ä»¶é½å¤´å¹¶è¿›ï¼›é…ç½®æ˜¯äº†è§£æ¨¡å‹ä½“ç³»ç»“æ„æ‰€å¿…éœ€çš„ï¼Œè€Œæ¨¡å‹æƒé‡æ˜¯æ¨¡å‹çš„å‚æ•°ã€‚</p>
</blockquote>
</li>
<li><p>Using a Transformer model for inference</p>
<ul>
<li>Transformeræ¨¡å‹åªèƒ½å¤„ç†æ•°å­—â€”è¿™äº›æ•°å­—æ˜¯ç”±åˆ†è¯å™¨ç”Ÿæˆçš„ã€‚åˆ†è¯å™¨å¯ä»¥è´Ÿè´£å°†è¾“å…¥è½¬æ¢ä¸ºé€‚å½“æ¡†æ¶çš„å¼ é‡ã€‚</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">sequences = [<span class="hljs-string">"Hello!"</span>, <span class="hljs-string">"Cool."</span>, <span class="hljs-string">"Nice!"</span>]<br><br>=====================&gt; Tokenizer<br><br>encoded_sequences = [<br>    [<span class="hljs-number">101</span>, <span class="hljs-number">7592</span>, <span class="hljs-number">999</span>, <span class="hljs-number">102</span>],<br>    [<span class="hljs-number">101</span>, <span class="hljs-number">4658</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>],<br>    [<span class="hljs-number">101</span>, <span class="hljs-number">3835</span>, <span class="hljs-number">999</span>, <span class="hljs-number">102</span>],<br>]<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>è¿™æ˜¯ä¸€ç³»åˆ—ç¼–ç åºåˆ—ï¼šä¸€ä¸ªåˆ—è¡¨çš„åˆ—è¡¨ã€‚å¼ é‡åªæ¥å—çŸ©å½¢å½¢çŠ¶ï¼ˆæƒ³è±¡çŸ©é˜µï¼‰ã€‚è¿™ä¸ªâ€œæ•°ç»„â€å·²ç»æ˜¯çŸ©å½¢å½¢çŠ¶ï¼Œæ‰€ä»¥å°†å…¶è½¬æ¢ä¸ºå¼ é‡å¾ˆå®¹æ˜“ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>model_inputs = torch.tensor(encoded_sequences)<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>ä½¿ç”¨å¼ é‡ä½œä¸ºæ¨¡å‹çš„è¾“å…¥</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">output = model(model_inputs)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>While the model accepts a lot of different arguments, <strong>only the input IDs are necessary</strong>.</p>
</blockquote>
</li>
</ul>
<h2 id="Tokenizers"><a href="#Tokenizers" class="headerlink" title="Tokenizers"></a>Tokenizers</h2><ul>
<li><p>åœ¨ NLP ä»»åŠ¡ä¸­ï¼Œé€šå¸¸å¤„ç†çš„æ•°æ®æ˜¯åŸå§‹æ–‡æœ¬ã€‚ ä½†æ˜¯ï¼Œæ¨¡å‹åªèƒ½å¤„ç†æ•°å­—ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ç§å°†åŸå§‹æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—çš„æ–¹æ³•ã€‚è¿™å°±æ˜¯æ ‡è®°å™¨ï¼ˆtokenizerï¼‰æ‰€åšçš„ï¼Œå¹¶ä¸”æœ‰å¾ˆå¤šæ–¹æ³•å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç›®æ ‡æ˜¯æ‰¾åˆ°æœ€æœ‰æ„ä¹‰çš„è¡¨ç¤ºâ€”â€”å³å¯¹æ¨¡å‹æœ€æœ‰æ„ä¹‰çš„è¡¨ç¤ºâ€”â€”å¹¶ä¸”å¦‚æœå¯èƒ½çš„è¯ï¼Œæ‰¾åˆ°æœ€å°çš„è¡¨ç¤ºã€‚</p>
</li>
<li><p>Tokenizersçš„ç¤ºä¾‹ï¼š</p>
<ul>
<li><p>Word-based: </p>
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/word_based_tokenization.svg" srcset="/img/loading.gif" lazyload alt="An example of word-based tokenization." style="zoom:50%;">

<ul>
<li><p>å®ƒé€šå¸¸å¾ˆå®¹æ˜“è®¾ç½®å’Œä½¿ç”¨ï¼Œåªéœ€å‡ æ¡è§„åˆ™ï¼Œå¹¶ä¸”é€šå¸¸ä¼šäº§ç”Ÿä¸é”™çš„ç»“æœã€‚ä¾‹å¦‚ï¼Œå°†åŸå§‹æ–‡æœ¬æ‹†åˆ†ä¸ºå•è¯ï¼Œå¹¶ä¸ºæ¯ä¸ªå•è¯æ‰¾åˆ°ä¸€ä¸ªæ•°å­—è¡¨ç¤ºï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenized_text = <span class="hljs-string">"Jim Henson was a puppeteer"</span>.split()<br><span class="hljs-built_in">print</span>(tokenized_text)<br><br><span class="hljs-comment"># Result: ['Jim', 'Henson', 'was', 'a', 'puppeteer']</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>è¿˜æœ‰ä¸€äº›å•è¯æ ‡è®°å™¨çš„å˜ä½“ï¼Œå®ƒä»¬å…·æœ‰é¢å¤–çš„æ ‡ç‚¹ç¬¦å·è§„åˆ™ã€‚ä½¿ç”¨è¿™ç§æ ‡è®°å™¨ï¼Œæˆ‘ä»¬æœ€ç»ˆå¯ä»¥å¾—åˆ°ä¸€äº›éå¸¸å¤§çš„â€œè¯æ±‡è¡¨â€ï¼Œå…¶ä¸­è¯æ±‡è¡¨ç”±æˆ‘ä»¬åœ¨è¯­æ–™åº“ä¸­æ‹¥æœ‰çš„ç‹¬ç«‹æ ‡è®°çš„æ€»æ•°å®šä¹‰ã€‚æ¯ä¸ªå•è¯éƒ½åˆ†é…äº†ä¸€ä¸ª IDï¼Œä» 0 å¼€å§‹ä¸€ç›´åˆ°è¯æ±‡è¡¨çš„å¤§å°ã€‚è¯¥æ¨¡å‹ä½¿ç”¨è¿™äº› ID æ¥è¯†åˆ«æ¯ä¸ªå•è¯ã€‚</p>
</blockquote>
</li>
<li><p>å¦‚æœæˆ‘ä»¬æƒ³ç”¨åŸºäºå•è¯çš„æ ‡è®°å™¨(tokenizer)å®Œå…¨è¦†ç›–ä¸€ç§è¯­è¨€ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºè¯­è¨€ä¸­çš„æ¯ä¸ªå•è¯éƒ½æœ‰ä¸€ä¸ªæ ‡è¯†ç¬¦ï¼Œè¿™å°†ç”Ÿæˆå¤§é‡çš„æ ‡è®°ã€‚ä¾‹å¦‚ï¼Œè‹±è¯­ä¸­æœ‰è¶…è¿‡ 500,000 ä¸ªå•è¯ï¼Œå› æ­¤è¦æ„å»ºä»æ¯ä¸ªå•è¯åˆ°è¾“å…¥ ID çš„æ˜ å°„ï¼Œæˆ‘ä»¬éœ€è¦è·Ÿè¸ªè¿™ä¹ˆå¤š IDã€‚æ­¤å¤–ï¼Œåƒâ€œdogâ€è¿™æ ·çš„è¯ä¸â€œdogsâ€è¿™æ ·çš„è¯çš„è¡¨ç¤ºæ–¹å¼ä¸åŒï¼Œæ¨¡å‹æœ€åˆæ— æ³•çŸ¥é“â€œdogâ€å’Œâ€œdogsâ€æ˜¯ç›¸ä¼¼çš„ï¼šå®ƒä¼šå°†è¿™ä¸¤ä¸ªè¯è¯†åˆ«ä¸ºä¸ç›¸å…³ã€‚è¿™åŒæ ·é€‚ç”¨äºå…¶ä»–ç›¸ä¼¼çš„è¯ï¼Œä¾‹å¦‚â€œrunâ€å’Œâ€œrunningâ€ï¼Œæ¨¡å‹æœ€åˆä¸ä¼šè®¤ä¸ºå®ƒä»¬æ˜¯ç›¸ä¼¼çš„ã€‚</p>
</li>
<li><p>æœ€åï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªè‡ªå®šä¹‰æ ‡è®°(token)æ¥è¡¨ç¤ºä¸åœ¨æˆ‘ä»¬è¯æ±‡è¡¨ä¸­çš„å•è¯ã€‚è¿™è¢«ç§°ä¸ºâ€œæœªçŸ¥â€æ ‡è®°(token)ï¼Œé€šå¸¸è¡¨ç¤ºä¸ºâ€œ[UNK]â€æˆ–â€<unk>â€œã€‚å¦‚æœä½ çœ‹åˆ°æ ‡è®°å™¨äº§ç”Ÿäº†å¾ˆå¤šè¿™æ ·çš„æ ‡è®°ï¼Œè¿™é€šå¸¸æ˜¯ä¸€ä¸ªä¸å¥½çš„è¿¹è±¡ï¼Œå› ä¸ºå®ƒæ— æ³•æ£€ç´¢åˆ°ä¸€ä¸ªè¯çš„åˆç†è¡¨ç¤ºï¼Œå¹¶ä¸”ä½ ä¼šåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ä¸¢å¤±ä¿¡æ¯ã€‚åˆ¶ä½œè¯æ±‡è¡¨æ—¶çš„ç›®æ ‡æ˜¯ä»¥è¿™æ ·ä¸€ç§æ–¹å¼è¿›è¡Œï¼Œå³æ ‡è®°å™¨å°†å°½å¯èƒ½å°‘çš„å•è¯æ ‡è®°ä¸ºæœªçŸ¥æ ‡è®°ã€‚</unk></p>
</li>
<li><p>å‡å°‘æœªçŸ¥æ ‡è®°æ•°é‡çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨æ›´æ·±ä¸€å±‚çš„æ ‡è®°å™¨(tokenizer)ï¼Œå³åŸºäºå­—ç¬¦çš„(<em>character-based</em>)æ ‡è®°å™¨(tokenizer)ã€‚</p>
</li>
</ul>
</li>
<li><p>Character-based:</p>
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/character_based_tokenization.svg" srcset="/img/loading.gif" lazyload alt="An example of character-based tokenization." style="zoom:50%;">

<ul>
<li>åŸºäºå­—ç¬¦çš„æ ‡è®°å™¨(tokenizer)å°†æ–‡æœ¬æ‹†åˆ†ä¸ºå­—ç¬¦ï¼Œè€Œä¸æ˜¯å•è¯ã€‚è¿™æœ‰ä¸¤ä¸ªä¸»è¦å¥½å¤„ï¼š è¯æ±‡é‡è¦å°å¾—å¤šã€‚ è¯æ±‡å¤–ï¼ˆæœªçŸ¥ï¼‰æ ‡è®°(token)è¦å°‘å¾—å¤šï¼Œå› ä¸ºæ¯ä¸ªå•è¯éƒ½å¯ä»¥ä»å­—ç¬¦æ„å»ºã€‚</li>
<li>è¿™ç§æ–¹æ³•ä¹Ÿä¸æ˜¯å®Œç¾çš„ã€‚ç”±äºç°åœ¨è¡¨ç¤ºæ˜¯åŸºäºå­—ç¬¦è€Œä¸æ˜¯å•è¯ï¼Œå› æ­¤äººä»¬å¯èƒ½ä¼šäº‰è¾©è¯´ï¼Œä»ç›´è§‰ä¸Šè®²ï¼Œå®ƒçš„æ„ä¹‰ä¸å¤§ï¼šæ¯ä¸ªå­—ç¬¦æœ¬èº«å¹¶æ²¡æœ‰å¤šå¤§æ„ä¹‰ï¼Œè€Œå•è¯å°±æ˜¯è¿™ç§æƒ…å†µã€‚ç„¶è€Œï¼Œè¿™åˆå› è¯­è¨€è€Œå¼‚ï¼›ä¾‹å¦‚ï¼Œåœ¨ä¸­æ–‡ä¸­ï¼Œæ¯ä¸ªå­—ç¬¦æ¯”æ‹‰ä¸è¯­è¨€ä¸­çš„å­—ç¬¦åŒ…å«æ›´å¤šçš„ä¿¡æ¯ã€‚å¦ä¸€ä¸ªéœ€è¦è€ƒè™‘çš„é—®é¢˜æ˜¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æœ€ç»ˆå°†å¤„ç†å¤§é‡çš„æ ‡è®°ï¼šä½¿ç”¨åŸºäºè¯çš„åˆ†è¯å™¨æ—¶ï¼Œä¸€ä¸ªè¯åªä¼šæ˜¯ä¸€ä¸ªå•ç‹¬çš„æ ‡è®°ï¼Œä½†åœ¨è½¬æ¢ä¸ºå­—ç¬¦æ—¶ï¼Œå®ƒå¾ˆå®¹æ˜“å˜æˆ10ä¸ªæˆ–æ›´å¤šçš„æ ‡è®°ã€‚</li>
<li>æ ‡ç‚¹ç¬¦å·ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„é—®é¢˜å’Œè€ƒé‡æ–¹é¢ã€‚</li>
</ul>
</li>
<li><p>Subword tokenization</p>
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/bpe_subword.svg" srcset="/img/loading.gif" lazyload alt="A subword tokenization algorithm." style="zoom:50%;">

<ul>
<li>å­è¯åˆ†è¯ç®—æ³•åŸºäºè¿™æ ·ä¸€ä¸ªåŸåˆ™ï¼šå¸¸ç”¨è¯ä¸åº”è¢«æ‹†åˆ†ä¸ºæ›´å°å­è¯ï¼Œä½†ç½•è§è¯åº”è¯¥è¢«åˆ†è§£æˆæœ‰æ„ä¹‰çš„å­è¯ã€‚ä¾‹å¦‚ï¼Œâ€œannoyinglyâ€å¯èƒ½è¢«è§†ä¸ºä¸€ä¸ªç½•è§è¯ï¼Œå¹¶å¯ä»¥è¢«åˆ†è§£ä¸ºâ€œannoyingâ€å’Œâ€œlyâ€ã€‚è¿™ä¸¤ä¸ªå­è¯ä½œä¸ºç‹¬ç«‹çš„å­è¯å‡ºç°çš„å¯èƒ½æ€§æ›´å¤§ï¼ŒåŒæ—¶â€œannoyinglyâ€çš„å«ä¹‰é€šè¿‡â€œannoyingâ€å’Œâ€œlyâ€çš„ç»„åˆå«ä¹‰å¾—ä»¥ä¿ç•™ã€‚</li>
<li>ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œå±•ç¤ºäº†å­è¯åˆ†è¯ç®—æ³•å¦‚ä½•å¯¹åºåˆ—â€œLetâ€™s do tokenization!â€è¿›è¡Œåˆ†è¯ï¼š<ol>
<li>â€œLetâ€ -&gt; â€œLetâ€</li>
<li>â€œâ€™sâ€ -&gt; â€œâ€˜sâ€ (å¯èƒ½è¢«è§†ä¸ºä¸€ä¸ªç‰¹æ®Šå­—ç¬¦æˆ–ç¼©å†™)</li>
<li>â€œdoâ€ -&gt; â€œdoâ€</li>
<li>â€œtokenâ€ -&gt; â€œtokenâ€</li>
<li>â€œizationâ€ -&gt; â€œizationâ€</li>
<li>â€œ!â€ -&gt; â€œ!â€</li>
</ol>
</li>
</ul>
</li>
<li><p>Other tokenizers</p>
<ul>
<li>**å­—èŠ‚çº§BPE (Byte-level BPE)**ï¼šåœ¨GPT-2ä¸­ä½¿ç”¨ï¼Œå®ƒå°†æ–‡æœ¬åˆ†è§£ä¸ºå­—èŠ‚çº§åˆ«çš„å­è¯ï¼Œè¿™å…è®¸æ¨¡å‹å¤„ç†Unicodeå­—ç¬¦ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†æœªçŸ¥è¯æ±‡ã€‚</li>
<li><strong>WordPiece</strong>ï¼šåœ¨BERTä¸­ä½¿ç”¨ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå­è¯çš„åˆ†è¯æ–¹æ³•ï¼Œå®ƒå…è®¸æ¨¡å‹å¤„ç†è¶…å‡ºè¯æ±‡è¡¨çš„è¯æ±‡ï¼Œé€šè¿‡å°†å®ƒä»¬åˆ†è§£ä¸ºå·²çŸ¥çš„å­è¯ã€‚</li>
<li><strong>SentencePieceæˆ–Unigram</strong>ï¼šåœ¨å¤šç§å¤šè¯­è¨€æ¨¡å‹ä¸­ä½¿ç”¨ï¼Œè¿™äº›æŠ€æœ¯é€šå¸¸ç”¨äºå¤„ç†å¤šç§è¯­è¨€çš„æ–‡æœ¬ï¼Œå¹¶ä¸”èƒ½å¤Ÿå¾ˆå¥½åœ°å¤„ç†è¯æ±‡è¡¨å¤–çš„è¯æ±‡ã€‚</li>
</ul>
</li>
</ul>
</li>
<li><p>How to use tokenizers?</p>
<ul>
<li><p>Loading and saving</p>
<ul>
<li><p>åŠ è½½å’Œä¿å­˜æ ‡è®°å™¨(tokenizer)å°±åƒä½¿ç”¨æ¨¡å‹ä¸€æ ·ç®€å•ã€‚å®é™…ä¸Šï¼Œå®ƒåŸºäºç›¸åŒçš„ä¸¤ç§æ–¹æ³•ï¼š from_pretrained() å’Œ save_pretrained() ã€‚è¿™äº›æ–¹æ³•å°†åŠ è½½æˆ–ä¿å­˜æ ‡è®°å™¨(tokenizer)ä½¿ç”¨çš„ç®—æ³•åŠ è½½å’Œä¿å­˜tokenizerï¼Œå°±åƒä½¿ç”¨æ¨¡å‹ä¸€æ ·ç®€å•ã€‚å®é™…ä¸Šï¼Œå®ƒåŸºäºç›¸åŒçš„ä¸¤ç§æ–¹æ³•ï¼š from_pretrained() å’Œ save_pretrained() ã€‚è¿™äº›æ–¹æ³•å°†åŠ è½½æˆ–ä¿å­˜tokenizerä½¿ç”¨çš„ç®—æ³•(ç±»ä¼¼äºarchitectureï¼‰ä»¥åŠå®ƒçš„è¯æ±‡ï¼ˆç±»ä¼¼äºweightsï¼‰ã€‚</p>
</li>
<li><p>åŠ è½½æ–¹å¼ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer<br><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">"bert-base-cased"</span>)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>å¦‚åŒ <code>AutoModel</code>ï¼Œ<code>AutoTokenizer</code> ç±»å°†æ ¹æ®æ£€æŸ¥ç‚¹åç§°åœ¨åº“ä¸­è·å–æ­£ç¡®çš„æ ‡è®°å™¨(tokenizer)ç±»ï¼Œå¹¶ä¸”å¯ä»¥ç›´æ¥ä¸ä»»ä½•æ£€æŸ¥ç‚¹ä¸€èµ·ä½¿ç”¨ã€‚</p>
</blockquote>
</li>
<li><p>ä½¿ç”¨æ–¹å¼ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">  tokenizer(<span class="hljs-string">"Using a Transformer network is simple"</span>)<br>  <br><span class="hljs-comment"># {'input_ids': [101, 7993, 170, 11303, 1200, 2443, 1110, 3014, 102], token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}</span><br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>ä¿å­˜æ–¹å¼ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer.save_pretrained(<span class="hljs-string">"directory_on_my_computer"</span>)<br></code></pre></td></tr></tbody></table></figure></li>
</ul>
</li>
</ul>
</li>
<li><p>ç¼–ç </p>
<ul>
<li><p>å°†æ–‡æœ¬ç¿»è¯‘æˆæ•°å­—è¢«ç§°ä¸ºç¼–ç (<em>encoding</em>).ç¼–ç åˆ†ä¸¤æ­¥å®Œæˆï¼šæ ‡è®°åŒ–ï¼Œç„¶åè½¬æ¢ä¸ºè¾“å…¥ IDã€‚</p>
<ul>
<li>ç¬¬ä¸€æ­¥æ˜¯å°†æ–‡æœ¬æ‹†åˆ†ä¸ºå•è¯ï¼ˆæˆ–å•è¯çš„ä¸€éƒ¨åˆ†ã€æ ‡ç‚¹ç¬¦å·ç­‰ï¼‰ï¼Œé€šå¸¸ç§°ä¸º*æ ‡è®°(token)*ã€‚æœ‰å¤šä¸ªè§„åˆ™å¯ä»¥ç®¡ç†è¯¥è¿‡ç¨‹ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ä½¿ç”¨æ¨¡å‹åç§°æ¥å®ä¾‹åŒ–æ ‡è®°å™¨(tokenizer)ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬ä½¿ç”¨æ¨¡å‹é¢„è®­ç»ƒæ—¶ä½¿ç”¨çš„ç›¸åŒè§„åˆ™ã€‚</li>
<li>ç¬¬äºŒæ­¥æ˜¯å°†è¿™äº›æ ‡è®°è½¬æ¢ä¸ºæ•°å­—ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥ç”¨å®ƒä»¬æ„å»ºä¸€ä¸ªå¼ é‡å¹¶å°†å®ƒä»¬æä¾›ç»™æ¨¡å‹ã€‚ä¸ºæ­¤ï¼Œæ ‡è®°å™¨(tokenizer)æœ‰ä¸€ä¸ª*è¯æ±‡(vocabulary)*ï¼Œè¿™æ˜¯æˆ‘ä»¬åœ¨å®ä¾‹åŒ–å®ƒæ—¶ä¸‹è½½çš„éƒ¨åˆ† <code>from_pretrained()</code> æ–¹æ³•ã€‚åŒæ ·ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨æ¨¡å‹é¢„è®­ç»ƒæ—¶ä½¿ç”¨çš„ç›¸åŒè¯æ±‡ã€‚</li>
</ul>
</li>
<li><p><strong>æˆ‘ä»¬å°†ä½¿ç”¨ä¸€äº›å•ç‹¬æ‰§è¡Œéƒ¨åˆ†æ ‡è®°åŒ–ç®¡é“çš„æ–¹æ³•æ¥å‘æ‚¨å±•ç¤ºè¿™äº›æ­¥éª¤çš„ä¸­é—´ç»“æœï¼Œä½†å®é™…ä¸Šï¼Œæ‚¨åº”è¯¥ç›´æ¥åœ¨æ‚¨çš„è¾“å…¥ä¸Šè°ƒç”¨tokenizer</strong></p>
<ul>
<li><p>æ ‡è®°åŒ–è¿‡ç¨‹ç”±tokenizerçš„<code>tokenize()</code> æ–¹æ³•å®ç°ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"bert-base-cased"</span>)<br><br>sequence = <span class="hljs-string">"Using a Transformer network is simple"</span><br>tokens = tokenizer.tokenize(sequence)<br><br><span class="hljs-built_in">print</span>(tokens)<br><br><span class="hljs-comment"># Result ['Using', 'a', 'transform', '##er', 'network', 'is', 'simple']</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>è¿™ä¸ªæ ‡è®°å™¨(tokenizer)æ˜¯ä¸€ä¸ªå­è¯æ ‡è®°å™¨(tokenizer)ï¼šå®ƒå¯¹è¯è¿›è¡Œæ‹†åˆ†ï¼Œç›´åˆ°è·å¾—å¯ä»¥ç”¨å…¶è¯æ±‡è¡¨è¡¨ç¤ºçš„æ ‡è®°(token)ã€‚<code>transformer</code> å°±æ˜¯è¿™ç§æƒ…å†µï¼Œå®ƒåˆ†ä¸ºä¸¤ä¸ªæ ‡è®°ï¼š<code>transform</code> å’Œ <code>##er</code>ã€‚</p>
</blockquote>
</li>
<li><p>Tokens -&gt; Input IDs</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">ids = tokenizer.convert_tokens_to_ids(tokens)<br><br><span class="hljs-built_in">print</span>(ids)<br><br><span class="hljs-comment"># Result [7993, 170, 11303, 1200, 2443, 1110, 3014]</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>è¿™äº›è¾“å‡º(Input IDs)ä¸€æ—¦è½¬æ¢ä¸ºé€‚å½“çš„æ¡†æ¶å¼ é‡(Tensor)ï¼Œå°±å¯ä»¥ç”¨ä½œæ¨¡å‹çš„è¾“å…¥</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
<li><p>è§£ç ï¼š</p>
<ul>
<li><p><em>è§£ç (Decoding)</em> æ­£å¥½ç›¸åï¼šä»è¯æ±‡ç´¢å¼•ä¸­ï¼Œæˆ‘ä»¬æƒ³è¦å¾—åˆ°ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚è¿™å¯ä»¥é€šè¿‡ <code>decode()</code> æ–¹æ³•å®ç°ï¼Œå¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">decoded_string = tokenizer.decode([<span class="hljs-number">7993</span>, <span class="hljs-number">170</span>, <span class="hljs-number">11303</span>, <span class="hljs-number">1200</span>, <span class="hljs-number">2443</span>, <span class="hljs-number">1110</span>, <span class="hljs-number">3014</span>])<br><span class="hljs-built_in">print</span>(decoded_string)<br><br><span class="hljs-comment"># 'Using a Transformer network is simple'</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>è¯·æ³¨æ„ï¼Œ <code>decode</code> æ–¹æ³•ä¸ä»…å°†ç´¢å¼•è½¬æ¢å›æ ‡è®°(token)ï¼Œè¿˜å°†å±äºç›¸åŒå•è¯çš„æ ‡è®°(token)ç»„åˆåœ¨ä¸€èµ·ä»¥ç”Ÿæˆå¯è¯»çš„å¥å­ã€‚å½“æˆ‘ä»¬ä½¿ç”¨é¢„æµ‹æ–°æ–‡æœ¬çš„æ¨¡å‹ï¼ˆæ ¹æ®æç¤ºç”Ÿæˆçš„æ–‡æœ¬ï¼Œæˆ–åºåˆ—åˆ°åºåˆ—é—®é¢˜ï¼ˆå¦‚ç¿»è¯‘æˆ–æ‘˜è¦ï¼‰ï¼‰æ—¶ï¼Œè¿™ç§è¡Œä¸ºå°†éå¸¸æœ‰ç”¨ã€‚</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="Handling-multiple-sequences"><a href="#Handling-multiple-sequences" class="headerlink" title="Handling multiple sequences"></a>Handling multiple sequences</h2><ul>
<li><p>New questions:</p>
<ul>
<li>æˆ‘ä»¬å¦‚ä½•å¤„ç†å¤šä¸ªåºåˆ—ï¼Ÿ</li>
<li>æˆ‘ä»¬å¦‚ä½•å¤„ç†ä¸åŒé•¿åº¦çš„å¤šä¸ªåºåˆ—ï¼Ÿ</li>
<li>è¯æ±‡ç´¢å¼•æ˜¯å”¯ä¸€èƒ½è®©æ¨¡å‹è‰¯å¥½å·¥ä½œçš„è¾“å…¥å—ï¼Ÿ</li>
<li>åºåˆ—æ˜¯å¦å¯èƒ½å¤ªé•¿ï¼Ÿ</li>
</ul>
</li>
<li><p>Models expect a batch of inputs:</p>
<ul>
<li><p>æ‰¹å¤„ç†æ˜¯å°†å¤šä¸ªå¥å­ä¸€æ¬¡æ€§é€šè¿‡æ¨¡å‹å‘é€çš„è¡Œä¸ºã€‚å¦‚æœæ‚¨åªæœ‰ä¸€ä¸ªå¥å­ï¼Œæ‚¨å¯ä»¥åªæ„å»ºä¸€ä¸ªåŒ…å«å•ä¸ªåºåˆ—çš„æ‰¹æ¬¡ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">batched_ids = [ids, ids]<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>æ‰¹å¤„ç†å…è®¸æ¨¡å‹åœ¨æ‚¨ç»™å®ƒè¾“å…¥å¤šä¸ªå¥å­æ—¶å·¥ä½œã€‚ä½¿ç”¨å¤šä¸ªåºåˆ—å°±åƒæ„å»ºä¸€ä¸ªåŒ…å«å•ä¸ªåºåˆ—çš„æ‰¹æ¬¡ä¸€æ ·ç®€å•ã€‚ç„¶è€Œï¼Œè¿˜æœ‰ç¬¬äºŒä¸ªé—®é¢˜ã€‚å½“æ‚¨å°è¯•å°†ä¸¤ä¸ªï¼ˆæˆ–æ›´å¤šï¼‰å¥å­ç»„åˆæˆä¸€ä¸ªæ‰¹æ¬¡æ—¶ï¼Œå®ƒä»¬å¯èƒ½é•¿åº¦ä¸åŒã€‚å¦‚æœæ‚¨ä»¥å‰ä½¿ç”¨è¿‡å¼ é‡ï¼Œæ‚¨çŸ¥é“å®ƒä»¬éœ€è¦æ˜¯çŸ©å½¢å½¢çŠ¶ï¼Œæ‰€ä»¥æ‚¨ä¸èƒ½ç›´æ¥å°†è¾“å…¥IDåˆ—è¡¨è½¬æ¢ä¸ºå¼ é‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬é€šå¸¸å¯¹è¾“å…¥è¿›è¡Œå¡«å……ã€‚</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Padding the inputs</p>
<ul>
<li><p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¡«å……ä½¿å¼ é‡å…·æœ‰çŸ©å½¢ã€‚Paddingé€šè¿‡åœ¨å€¼è¾ƒå°‘çš„å¥å­ä¸­æ·»åŠ ä¸€ä¸ªåä¸ºPadding tokençš„ç‰¹æ®Šå•è¯æ¥ç¡®ä¿æˆ‘ä»¬æ‰€æœ‰çš„å¥å­é•¿åº¦ç›¸åŒã€‚</p>
</li>
<li><p>Transformeræ¨¡å‹çš„å…³é”®ç‰¹æ€§æ˜¯å…³æ³¨å±‚ï¼Œå®ƒå°†æ¯ä¸ªæ ‡è®°ä¸Šä¸‹æ–‡åŒ–ã€‚è¿™äº›å°†è€ƒè™‘å¡«å……æ ‡è®°ï¼Œå› ä¸ºå®ƒä»¬æ¶‰åŠåºåˆ—ä¸­çš„æ‰€æœ‰æ ‡è®°ã€‚ä¸ºäº†åœ¨é€šè¿‡æ¨¡å‹ä¼ é€’ä¸åŒé•¿åº¦çš„å•ä¸ªå¥å­æ—¶ï¼Œæˆ–è€…åœ¨ä¼ é€’ä¸€æ‰¹åº”ç”¨äº†ç›¸åŒå¥å­å’Œå¡«å……çš„å¥å­æ—¶è·å¾—ç›¸åŒçš„ç»“æœï¼Œæˆ‘ä»¬éœ€è¦å‘Šè¯‰è¿™äº›æ³¨æ„å±‚å¿½ç•¥å¡«å……æ ‡è®°ã€‚è¿™æ˜¯é€šè¿‡ä½¿ç”¨ attention maskæ¥å®ç°çš„ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">batched_ids = [<br>    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, <span class="hljs-number">200</span>],<br>    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, tokenizer.pad_token_id],<br>]<br><br><span class="hljs-built_in">print</span>(model(torch.tensor(batched_ids)).logits)<br></code></pre></td></tr></tbody></table></figure></li>
</ul>
</li>
<li><p>Attention masks</p>
<ul>
<li><p><em>Attention masks</em>æ˜¯ä¸è¾“å…¥IDå¼ é‡å½¢çŠ¶å®Œå…¨ç›¸åŒçš„å¼ é‡ï¼Œç”¨0å’Œ1å¡«å……ï¼š1sè¡¨ç¤ºåº”æ³¨æ„ç›¸åº”çš„æ ‡è®°ï¼Œ0sè¡¨ç¤ºä¸åº”æ³¨æ„ç›¸åº”çš„æ ‡è®°ï¼ˆå³ï¼Œæ¨¡å‹çš„æ³¨æ„åŠ›å±‚åº”å¿½ç•¥å®ƒä»¬ï¼‰ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">batched_ids = [<br>    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, <span class="hljs-number">200</span>],<br>    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, tokenizer.pad_token_id],<br>]<br><br>attention_mask = [<br>    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>]<br><br>outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))<br><span class="hljs-built_in">print</span>(outputs.logits)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>ç¬¬äºŒä¸ªåºåˆ—çš„æœ€åä¸€ä¸ªå€¼æ˜¯ä¸€ä¸ªå¡«å……IDï¼Œå®ƒåœ¨attention maskä¸­æ˜¯ä¸€ä¸ª0å€¼ã€‚</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Longer sequences</p>
<ul>
<li><p>å¯¹äºTransformersæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ¨¡å‹çš„åºåˆ—é•¿åº¦æ˜¯æœ‰é™çš„ã€‚å¤§å¤šæ•°æ¨¡å‹å¤„ç†å¤šè¾¾512æˆ–1024ä¸ªä»¤ç‰Œçš„åºåˆ—ï¼Œå½“è¦æ±‚å¤„ç†æ›´é•¿çš„åºåˆ—æ—¶ï¼Œä¼šå´©æºƒã€‚æ­¤é—®é¢˜æœ‰ä¸¤ç§è§£å†³æ–¹æ¡ˆï¼š</p>
<ul>
<li><p>ä½¿ç”¨æ”¯æŒçš„åºåˆ—é•¿åº¦è¾ƒé•¿çš„æ¨¡å‹ã€‚</p>
</li>
<li><p>æˆªæ–­åºåˆ—ã€‚</p>
</li>
</ul>
</li>
<li><p>æ¨¡å‹æœ‰ä¸åŒçš„æ”¯æŒåºåˆ—é•¿åº¦ï¼Œæœ‰äº›æ¨¡å‹ä¸“é—¨å¤„ç†å¾ˆé•¿çš„åºåˆ—ã€‚ <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/longformer.html">Longformer</a> è¿™æ˜¯ä¸€ä¸ªä¾‹å­ï¼Œå¦ä¸€ä¸ªæ˜¯ <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/led.html">LED</a> . å¦‚æœæ‚¨æ­£åœ¨å¤„ç†ä¸€é¡¹éœ€è¦å¾ˆé•¿åºåˆ—çš„ä»»åŠ¡ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨æŸ¥çœ‹è¿™äº›æ¨¡å‹ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨é€šè¿‡æŒ‡å®šmax_sequence_lengthå‚æ•°ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">sequence = sequence[:max_sequence_length]<br></code></pre></td></tr></tbody></table></figure></li>
</ul>
</li>
</ul>
<h2 id="Putting-it-all-together"><a href="#Putting-it-all-together" class="headerlink" title="Putting it all together"></a>Putting it all together</h2><ul>
<li>Transformers APIå¯ä»¥é€šè¿‡ä¸€ä¸ªé«˜çº§å‡½æ•°ä¸ºæˆ‘ä»¬å¤„ç†æ‰€æœ‰è¿™äº›</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>checkpoint = <span class="hljs-string">"distilbert-base-uncased-finetuned-sst-2-english"</span><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br><br>sequence = <span class="hljs-string">"I've been waiting for a HuggingFace course my whole life."</span><br><br>model_inputs = tokenizer(sequence)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p><code>model_inputs</code> å˜é‡åŒ…å«æ¨¡å‹è‰¯å¥½è¿è¡Œæ‰€éœ€çš„ä¸€åˆ‡ã€‚å¯¹äºDistilBERTï¼Œå®ƒåŒ…æ‹¬è¾“å…¥ IDå’Œæ³¨æ„åŠ›æ©ç (attention mask)ã€‚å…¶ä»–æ¥å—é¢å¤–è¾“å…¥çš„æ¨¡å‹ä¹Ÿä¼šæœ‰tokenizerçš„è¾“å‡ºã€‚</p>
</blockquote>
<ul>
<li>ä¸€æ¬¡å¤„ç†å¤šä¸ªåºåˆ—ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">sequences = [<span class="hljs-string">"I've been waiting for a HuggingFace course my whole life."</span>, <span class="hljs-string">"So have I!"</span>]<br><br>model_inputs = tokenizer(sequences)<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>æ ‡è®°å™¨å¯¹è±¡å¯ä»¥å¤„ç†åˆ°ç‰¹å®šæ¡†æ¶å¼ é‡çš„è½¬æ¢ï¼Œç„¶åå¯ä»¥ç›´æ¥å‘é€åˆ°æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸‹é¢çš„ä»£ç ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬æç¤ºæ ‡è®°å™¨ä»ä¸åŒçš„æ¡†æ¶è¿”å›å¼ é‡â€”â€”<code>"pt"</code>è¿”å›Py Torchå¼ é‡ï¼Œ<code>"tf"</code>è¿”å›TensorFlowå¼ é‡ï¼Œ<code>"np"</code>è¿”å›NumPyæ•°ç»„ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">sequences = [<span class="hljs-string">"I've been waiting for a HuggingFace course my whole life."</span>, <span class="hljs-string">"So have I!"</span>]<br><br><span class="hljs-comment"># Returns PyTorch tensors</span><br>model_inputs = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">"pt"</span>)<br><br><span class="hljs-comment"># Returns TensorFlow tensors</span><br>model_inputs = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">"tf"</span>)<br><br><span class="hljs-comment"># Returns NumPy arrays</span><br>model_inputs = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">"np"</span>)<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li><p>Special tokens</p>
<ul>
<li><p>æˆ‘ä»¬çœ‹ä¸€ä¸‹æ ‡è®°å™¨è¿”å›çš„è¾“å…¥ IDï¼Œæˆ‘ä»¬ä¼šå‘ç°å®ƒä»¬ä¸ä¹‹å‰çš„ç•¥æœ‰ä¸åŒï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">sequence = <span class="hljs-string">"I've been waiting for a HuggingFace course my whole life."</span><br><br>model_inputs = tokenizer(sequence)<br><span class="hljs-built_in">print</span>(model_inputs[<span class="hljs-string">"input_ids"</span>])<br><br>tokens = tokenizer.tokenize(sequence)<br>ids = tokenizer.convert_tokens_to_ids(tokens)<br><span class="hljs-built_in">print</span>(ids)<br><br><span class="hljs-built_in">print</span>(tokenizer.decode(model_inputs[<span class="hljs-string">"input_ids"</span>]))<br><span class="hljs-built_in">print</span>(tokenizer.decode(ids))<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>Result</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">[101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102]<br><br>[1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012]<br><br>"[CLS] i've been waiting for a huggingface course my whole life. [SEP]"<br><br>"i've been waiting for a huggingface course my whole life."<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>Tokenizeråœ¨å¼€å¤´æ·»åŠ äº†ç‰¹æ®Šå•è¯<code>[CLS]</code>ï¼Œåœ¨ç»“å°¾æ·»åŠ äº†ç‰¹æ®Šå•è¯<code>[SEP]</code>ã€‚è¿™æ˜¯å› ä¸ºæ¨¡å‹æ˜¯ç”¨è¿™äº›æ•°æ®é¢„è®­ç»ƒçš„ï¼Œæ‰€ä»¥ä¸ºäº†å¾—åˆ°ç›¸åŒçš„æ¨ç†ç»“æœï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ·»åŠ å®ƒä»¬ã€‚è¯·æ³¨æ„ï¼Œæœ‰äº›æ¨¡å‹ä¸æ·»åŠ ç‰¹æ®Šå•è¯ï¼Œæˆ–è€…æ·»åŠ ä¸åŒçš„å•è¯ï¼›æ¨¡å‹ä¹Ÿå¯èƒ½åªåœ¨å¼€å¤´æˆ–ç»“å°¾æ·»åŠ è¿™äº›ç‰¹æ®Šå•è¯ã€‚åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼ŒTokenizeréƒ½çŸ¥é“éœ€è¦å“ªäº›è¯ç¬¦ï¼Œå¹¶å°†ä¸ºæ‚¨å¤„ç†è¿™äº›è¯ç¬¦ã€‚</p>
</li>
</ul>
</li>
<li><p>Wrapping up: From tokenizer to model</p>
</li>
</ul>
<p>ç°åœ¨æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†æ ‡è®°å™¨å¯¹è±¡åœ¨åº”ç”¨äºæ–‡æœ¬æ—¶ä½¿ç”¨çš„æ‰€æœ‰å•ç‹¬æ­¥éª¤ï¼Œè®©æˆ‘ä»¬æœ€åä¸€æ¬¡çœ‹çœ‹å®ƒå¦‚ä½•å¤„ç†å¤šä¸ªåºåˆ—ï¼ˆå¡«å……ï¼ï¼‰ï¼Œéå¸¸é•¿çš„åºåˆ—ï¼ˆæˆªæ–­ï¼ï¼‰ï¼Œä»¥åŠå¤šç§ç±»å‹çš„å¼ é‡åŠå…¶ä¸»è¦APIï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification<br><br>checkpoint = <span class="hljs-string">"distilbert-base-uncased-finetuned-sst-2-english"</span><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint)<br>sequences = [<span class="hljs-string">"I've been waiting for a HuggingFace course my whole life."</span>, <span class="hljs-string">"So have I!"</span>]<br><br>tokens = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">"pt"</span>)<br>output = model(**tokens)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<ol>
<li><strong>å¡«å……ï¼ˆPaddingï¼‰</strong>ï¼šå°†è¾ƒçŸ­çš„åºåˆ—ç”¨ç‰¹æ®Šçš„å¡«å……å€¼ï¼ˆé€šå¸¸æ˜¯<code>&lt;PAD&gt;</code> tokenï¼‰æ‰©å±•åˆ°ä¸æœ€é•¿åºåˆ—ç›¸åŒçš„é•¿åº¦ã€‚è¿™å¯ä»¥é¿å…æ‰¹å¤„ç†ä¸­å› ä¸ºåºåˆ—é•¿åº¦ä¸ä¸€è‡´è€Œå¯¼è‡´çš„å¼ é‡ç»´åº¦ä¸åŒ¹é…çš„é—®é¢˜ã€‚</li>
<li><strong>æˆªæ–­ï¼ˆTruncationï¼‰</strong>ï¼šå¯¹äºè¿‡é•¿çš„åºåˆ—ï¼Œæˆªå–åˆ°æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼Œé¿å…åºåˆ—è¿‡é•¿è¶…è¿‡æ¨¡å‹çš„æœ€å¤§å¤„ç†èƒ½åŠ›ã€‚</li>
</ol>
<p><code>padding=True</code>å’Œ<code>truncation=True</code>ä¸€èµ·ä½¿ç”¨ï¼Œå¯ä»¥ç¡®ä¿æ‰€æœ‰è¾“å…¥åºåˆ—çš„é•¿åº¦ä¸€è‡´ï¼Œä»è€Œå¯ä»¥æ–¹ä¾¿åœ°è¿›è¡Œæ‰¹é‡å¤„ç†ã€‚<code>return_tensors="pt"</code>åˆ™è¡¨ç¤ºè¿”å›çš„æ˜¯PyTorchå¼ é‡ã€‚</p>
</blockquote>
<h2 id="Summary-2"><a href="#Summary-2" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li><p>å­¦ä¹ çš„å†…å®¹</p>
<ul>
<li><p>å­¦ä¹ äº†Transformersæ¨¡å‹çš„åŸºæœ¬æ„é€ å—ã€‚</p>
</li>
<li><p>äº†è§£äº†æ ‡è®°åŒ–ç®¡é“çš„ç»„æˆã€‚</p>
</li>
<li><p>äº†è§£äº†å¦‚ä½•åœ¨å®è·µä¸­ä½¿ç”¨Transformersæ¨¡å‹ã€‚</p>
</li>
<li><p>å­¦ä¹ äº†å¦‚ä½•åˆ©ç”¨åˆ†è¯å™¨å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„å¼ é‡ã€‚</p>
</li>
<li><p>å°†åˆ†è¯å™¨å’Œæ¨¡å‹ä¸€èµ·è®¾ç½®ï¼Œä»¥ä»æ–‡æœ¬åˆ°é¢„æµ‹ã€‚</p>
</li>
<li><p>äº†è§£äº†inputs IDsçš„å±€é™æ€§ï¼Œå¹¶äº†è§£äº†attention maskã€‚</p>
</li>
<li><p>ä½¿ç”¨å¤šåŠŸèƒ½å’Œå¯é…ç½®çš„åˆ†è¯å™¨æ–¹æ³•ã€‚</p>
</li>
</ul>
</li>
<li><p>Little test: <a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/en/chapter2/8?fw=pt">https://huggingface.co/learn/nlp-course/en/chapter2/8?fw=pt</a></p>
</li>
</ul>
<h1 id="Fine-tuning-a-pretrained-model"><a href="#Fine-tuning-a-pretrained-model" class="headerlink" title="Fine-tuning a pretrained model"></a>Fine-tuning a pretrained model</h1><h2 id="Introduction-2"><a href="#Introduction-2" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>Table of contents<ul>
<li>å¦‚ä½•ä»æ¨¡å‹ä¸­å¿ƒ(hub)å‡†å¤‡å¤§å‹æ•°æ®é›†</li>
<li>å¦‚ä½•ä½¿ç”¨é«˜çº§<code>è®­ç»ƒ</code>APIå¾®è°ƒä¸€ä¸ªæ¨¡å‹</li>
<li>å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒè¿‡ç¨‹</li>
<li>å¦‚ä½•åˆ©ç”¨ğŸ¤— Accelerateåº“åœ¨ä»»ä½•åˆ†å¸ƒå¼è®¾å¤‡ä¸Šè½»æ¾è¿è¡Œè‡ªå®šä¹‰è®­ç»ƒè¿‡ç¨‹</li>
</ul>
</li>
</ul>
<h2 id="Processing-the-data"><a href="#Processing-the-data" class="headerlink" title="Processing the data"></a>Processing the data</h2><ul>
<li>Easy demo</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW, AutoTokenizer, AutoModelForSequenceClassification<br><br><span class="hljs-comment"># Same as before</span><br>checkpoint = <span class="hljs-string">"bert-base-uncased"</span><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint)<br>sequences = [<br>    <span class="hljs-string">"I've been waiting for a HuggingFace course my whole life."</span>,<br>    <span class="hljs-string">"This course is amazing!"</span>,<br>]<br>batch = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">"pt"</span>)<br><br><span class="hljs-comment"># This is new</span><br>batch[<span class="hljs-string">"labels"</span>] = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])<br><br>optimizer = AdamW(model.parameters())<br>loss = model(**batch).loss<br>loss.backward()<br>optimizer.step()<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>æ•°æ®å¤ªå°‘äº†ï¼Œè®­ç»ƒæ²¡æœ‰æ•ˆæœï¼</p>
</blockquote>
<ul>
<li><p>MRPCæ•°æ®é›†Demo</p>
<ul>
<li><p>è¯¥æ•°æ®é›†ç”±å¨å»‰Â·å¤šå…°å’Œå…‹é‡Œæ–¯Â·å¸ƒç½—å…‹ç‰¹åœ¨<a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/I05-5002.pdf">è¿™ç¯‡æ–‡ç« </a>å‘å¸ƒã€‚è¯¥æ•°æ®é›†ç”±5801å¯¹å¥å­ç»„æˆï¼Œæ¯ä¸ªå¥å­å¯¹å¸¦æœ‰ä¸€ä¸ªæ ‡ç­¾ï¼ŒæŒ‡ç¤ºå®ƒä»¬æ˜¯å¦ä¸ºåŒä¹‰ï¼ˆå³ï¼Œå¦‚æœä¸¤ä¸ªå¥å­çš„æ„æ€ç›¸åŒï¼‰ã€‚æˆ‘ä»¬åœ¨æœ¬ç« ä¸­é€‰æ‹©äº†å®ƒï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå°æ•°æ®é›†ï¼Œæ‰€ä»¥å¾ˆå®¹æ˜“å¯¹å®ƒè¿›è¡Œè®­ç»ƒã€‚</p>
</li>
<li><p>ç‚¹å‡»<a target="_blank" rel="noopener" href="https://huggingface.co/datasets">æ•°æ®é›†</a>çš„é“¾æ¥å³å¯è¿›è¡Œæµè§ˆï¼Œä¹Ÿå¯ä»¥å­¦ä¹ ï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/docs/datasets/loading">åŠ è½½å’Œå¤„ç†æ–°çš„æ•°æ®é›†</a>è¿™ç¯‡æ–‡ç« ã€‚æˆ‘ä»¬ä½¿ç”¨MRPCæ•°æ®é›†ä¸­çš„<a target="_blank" rel="noopener" href="https://gluebenchmark.com/">GLUE åŸºå‡†æµ‹è¯•æ•°æ®é›†</a>ï¼Œå®ƒæ˜¯æ„æˆMRPCæ•°æ®é›†çš„10ä¸ªæ•°æ®é›†ä¹‹ä¸€ï¼Œè¿™æ˜¯ä¸€ä¸ªå­¦æœ¯åŸºå‡†ï¼Œç”¨äºè¡¡é‡æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨10ä¸ªä¸åŒæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚</p>
</li>
<li><p>Datasetsåº“æä¾›äº†ä¸€ä¸ªéå¸¸ä¾¿æ·çš„å‘½ä»¤ï¼Œå¯ä»¥åœ¨æ¨¡å‹ä¸­å¿ƒï¼ˆhubï¼‰ä¸Šä¸‹è½½å’Œç¼“å­˜æ•°æ®é›†ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹çš„ä»£ç ä¸‹è½½MRPCæ•°æ®é›†ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>raw_datasets = load_dataset(<span class="hljs-string">"glue"</span>, <span class="hljs-string">"mrpc"</span>)<br>raw_datasets<br><span class="hljs-comment"># æ­¤å‘½ä»¤åœ¨ä¸‹è½½æ•°æ®é›†å¹¶ç¼“å­˜åˆ° ~/.cache/huggingface/datasetsï¼Œæ‚¨å¯ä»¥é€šè¿‡è®¾ç½®HF_HOMEç¯å¢ƒå˜é‡æ¥è‡ªå®šä¹‰ç¼“å­˜çš„æ–‡ä»¶å¤¹ã€‚</span><br><br><span class="hljs-comment"># Result</span><br>DatasetDict({<br>    train: Dataset({<br>        features: [<span class="hljs-string">'sentence1'</span>, <span class="hljs-string">'sentence2'</span>, <span class="hljs-string">'label'</span>, <span class="hljs-string">'idx'</span>],<br>        num_rows: <span class="hljs-number">3668</span><br>    })<br>    validation: Dataset({<br>        features: [<span class="hljs-string">'sentence1'</span>, <span class="hljs-string">'sentence2'</span>, <span class="hljs-string">'label'</span>, <span class="hljs-string">'idx'</span>],<br>        num_rows: <span class="hljs-number">408</span><br>    })<br>    test: Dataset({<br>        features: [<span class="hljs-string">'sentence1'</span>, <span class="hljs-string">'sentence2'</span>, <span class="hljs-string">'label'</span>, <span class="hljs-string">'idx'</span>],<br>        num_rows: <span class="hljs-number">1725</span><br>    })<br>})<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>æˆ‘ä»¬è·å¾—äº†ä¸€ä¸ª<strong>DatasetDict</strong>å¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚æ¯ä¸€ä¸ªé›†åˆéƒ½åŒ…å«å‡ ä¸ªåˆ—(<strong>sentence1</strong>, <strong>sentence2</strong>, <strong>label</strong>, and <strong>idx</strong>)ä»¥åŠä¸€ä¸ªä»£è¡¨è¡Œæ•°çš„å˜é‡ã€‚</p>
</blockquote>
</li>
<li><p>è®¿é—®æ•°æ®</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">raw_train_dataset = raw_datasets[<span class="hljs-string">"train"</span>]<br>raw_train_dataset[<span class="hljs-number">0</span>]<br><span class="hljs-comment"># è¿™ä¸ªå°±æ˜¯ä¸€æ¡çœŸçœŸåˆ‡åˆ‡ï¼Œå«æœ‰å„ç§featureçš„æ•°æ®</span><br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>è¦çŸ¥é“å“ªä¸ªæ•°å­—å¯¹åº”äºå“ªä¸ªæ ‡ç­¾ï¼Œæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹<strong>raw_train_dataset</strong>çš„<strong>features</strong>. </p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">raw_train_dataset.features<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p><strong>Labelï¼ˆæ ‡ç­¾ï¼‰</strong> æ˜¯ä¸€ç§<strong>ClassLabelï¼ˆåˆ†ç±»æ ‡ç­¾ï¼‰</strong>ï¼Œä½¿ç”¨æ•´æ•°å»ºç«‹èµ·åˆ°ç±»åˆ«æ ‡ç­¾çš„æ˜ å°„å…³ç³»ã€‚<strong>0</strong>å¯¹åº”äº<strong>not_equivalent</strong>ï¼Œ<strong>1</strong>å¯¹åº”äº<strong>equivalent</strong>ã€‚</p>
</blockquote>
</li>
</ul>
</li>
<li><p>é¢„å¤„ç†æ•°æ®é›†</p>
<ul>
<li><p>å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹èƒ½å¤Ÿç†è§£çš„æ•°å­—</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">inputs = tokenizer(<span class="hljs-string">"This is the first sentence."</span>, <span class="hljs-string">"This is the second one."</span>)<br>inputs<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p><strong>è¾“å…¥è¯id(input_ids)</strong> å’Œ <strong>æ³¨æ„åŠ›é®ç½©(attention_mask)</strong> ï¼Œ**ç±»å‹æ ‡è®°ID(token_type_ids)**çš„ä½œç”¨å°±æ˜¯å‘Šè¯‰æ¨¡å‹è¾“å…¥çš„å“ªä¸€éƒ¨åˆ†æ˜¯ç¬¬ä¸€å¥ï¼Œå“ªä¸€éƒ¨åˆ†æ˜¯ç¬¬äºŒå¥ã€‚</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer.convert_ids_to_tokens(inputs[<span class="hljs-string">"input_ids"</span>])<br><br><span class="hljs-comment"># ['[CLS]', 'this', 'is', 'the', 'first', 'sentence', '.', '[SEP]', 'this', 'is', 'the', 'second', 'one', '.', '[SEP]']</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p><strong>[CLS] sentence1 [SEP] sentence2 [SEP]<strong>ï¼Œè¾“å…¥ä¸­ <strong>[CLS] sentence1 [SEP]</strong> å®ƒä»¬çš„ç±»å‹æ ‡è®°IDå‡ä¸º</strong>0</strong>ï¼Œè€Œå…¶ä»–éƒ¨åˆ†ï¼Œå¯¹åº”äº<strong>sentence2 [SEP]<strong>ï¼Œæ‰€æœ‰çš„ç±»å‹æ ‡è®°IDå‡ä¸º</strong>1</strong>ã€‚</p>
</blockquote>
</li>
<li><p>å¦‚æœé€‰æ‹©å…¶ä»–çš„checkpointï¼Œåˆ™ä¸ä¸€å®šå…·æœ‰<strong>token_type_ids</strong>ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœä½¿ç”¨DistilBERTæ¨¡å‹ï¼Œå°±ä¸ä¼šè¿”å›å®ƒä»¬ï¼‰ã€‚åªæœ‰å½“å®ƒåœ¨é¢„è®­ç»ƒæœŸé—´ä½¿ç”¨è¿‡è¿™ä¸€å±‚ï¼Œæ¨¡å‹åœ¨æ„å»ºæ—¶ä¾èµ–å®ƒä»¬ï¼Œæ‰ä¼šè¿”å›å®ƒä»¬ã€‚</p>
</li>
</ul>
</li>
<li><p>ä½¿ç”¨<a target="_blank" rel="noopener" href="https://huggingface.co/course/chapter1">ç¬¬ä¸€ç« </a>çš„é®ç½©è¯­è¨€æ¨¡å‹ï¼Œè¿˜æœ‰ä¸€ä¸ªé¢å¤–çš„åº”ç”¨ç±»å‹ï¼Œå«åšä¸‹ä¸€å¥é¢„æµ‹ã€‚</p>
<ul>
<li><p>è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šç»™æ¨¡å‹è¾“å…¥æˆå¯¹çš„å¥å­ï¼ˆå¸¦æœ‰éšæœºé®ç½©çš„æ ‡è®°ï¼‰ï¼Œå¹¶è¢«è¦æ±‚é¢„æµ‹ç¬¬äºŒä¸ªå¥å­æ˜¯å¦ç´§è·Ÿç¬¬ä¸€ä¸ªå¥å­ã€‚ä¸ºäº†æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ•°æ®é›†ä¸­ä¸€åŠçš„ä¸¤ä¸ªå¥å­åœ¨åŸå§‹æ–‡æ¡£ä¸­æŒ¨åœ¨ä¸€èµ·ï¼Œå¦ä¸€åŠçš„ä¸¤ä¸ªå¥å­æ¥è‡ªä¸¤ä¸ªä¸åŒçš„æ–‡æ¡£ã€‚</p>
</li>
<li><p>ä¸€èˆ¬æ¥è¯´ï¼Œä¸éœ€è¦æ‹…å¿ƒæ˜¯å¦æœ‰token_type_idsã€‚åœ¨æ‚¨çš„æ ‡è¾“å…¥ä¸­ï¼šåªè¦æ‚¨å¯¹æ ‡è®°å™¨å’Œæ¨¡å‹ä½¿ç”¨ç›¸åŒçš„æ£€æŸ¥ç‚¹ï¼Œä¸€åˆ‡éƒ½ä¼šå¾ˆå¥½ï¼Œå› ä¸ºæ ‡è®°å™¨çŸ¥é“å‘å…¶æ¨¡å‹æä¾›ä»€ä¹ˆã€‚</p>
</li>
<li><p>æˆ‘ä»¬å¯ä»¥ç»™æ ‡è®°å™¨æä¾›ä¸€ç»„å¥å­ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å®ƒç¬¬ä¸€ä¸ªå¥å­çš„åˆ—è¡¨ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯ç¬¬äºŒä¸ªå¥å­çš„åˆ—è¡¨ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenized_dataset = tokenizer(<br>    raw_datasets[<span class="hljs-string">"train"</span>][<span class="hljs-string">"sentence1"</span>],<br>    raw_datasets[<span class="hljs-string">"train"</span>][<span class="hljs-string">"sentence2"</span>],<br>    padding=<span class="hljs-literal">True</span>,<br>    truncation=<span class="hljs-literal">True</span>,<br>)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>å®ƒçš„ç¼ºç‚¹æ˜¯è¿”å›å­—å…¸ï¼ˆå­—å…¸çš„é”®æ˜¯<strong>è¾“å…¥è¯id(input_ids)</strong> ï¼Œ <strong>æ³¨æ„åŠ›é®ç½©(attention_mask)</strong> å’Œ **ç±»å‹æ ‡è®°ID(token_type_ids)**ï¼Œå­—å…¸çš„å€¼æ˜¯é”®æ‰€å¯¹åº”å€¼çš„åˆ—è¡¨ï¼‰ã€‚è€Œä¸”åªæœ‰å½“æ‚¨åœ¨è½¬æ¢è¿‡ç¨‹ä¸­æœ‰è¶³å¤Ÿçš„å†…å­˜æ¥å­˜å‚¨æ•´ä¸ªæ•°æ®é›†æ—¶æ‰ä¸ä¼šå‡ºé”™</p>
</blockquote>
</li>
<li><p>Hugging faceæ•°æ®é›†åº“ä¸­çš„æ•°æ®é›†æ˜¯ä»¥<a target="_blank" rel="noopener" href="https://arrow.apache.org/">Apache Arrow</a>æ–‡ä»¶å­˜å‚¨åœ¨ç£ç›˜ä¸Šï¼Œå› æ­¤æ‚¨åªéœ€å°†æ¥ä¸‹æ¥è¦ç”¨çš„æ•°æ®åŠ è½½åœ¨å†…å­˜ä¸­ï¼Œå› æ­¤ä¼šå¯¹å†…å­˜å®¹é‡çš„éœ€æ±‚è¦ä½ä¸€äº›ã€‚</p>
</li>
</ul>
</li>
<li><p>ä¸ºäº†å°†æ•°æ®ä¿å­˜ä¸ºæ•°æ®é›†ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<a target="_blank" rel="noopener" href="https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.map">Dataset.map()</a>æ–¹æ³•ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦åšæ›´å¤šçš„é¢„å¤„ç†è€Œä¸ä»…ä»…æ˜¯æ ‡è®°åŒ–ï¼Œé‚£ä¹ˆè¿™ä¹Ÿç»™äº†æˆ‘ä»¬ä¸€äº›é¢å¤–çš„è‡ªå®šä¹‰çš„æ–¹æ³•ã€‚è¿™ä¸ªæ–¹æ³•çš„å·¥ä½œåŸç†æ˜¯åœ¨æ•°æ®é›†çš„æ¯ä¸ªå…ƒç´ ä¸Šåº”ç”¨ä¸€ä¸ªå‡½æ•°ã€‚</p>
<ul>
<li><p>ä»£ç </p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">example</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(example[<span class="hljs-string">"sentence1"</span>], example[<span class="hljs-string">"sentence2"</span>], truncation=<span class="hljs-literal">True</span>)<br>  <br>tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)<br>tokenized_datasets<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<ul>
<li>è¾“å…¥æ˜¯ä¸€ä¸ªå­—å…¸ï¼ˆä¸æ•°æ®é›†çš„é¡¹ç±»ä¼¼ï¼‰ï¼Œå¹¶è¿”å›ä¸€ä¸ªåŒ…å«<strong>è¾“å…¥è¯id(input_ids)</strong> ï¼Œ <strong>æ³¨æ„åŠ›é®ç½©(attention_mask)</strong> å’Œ <strong>ç±»å‹æ ‡è®°ID(token_type_ids)</strong> é”®çš„æ–°å­—å…¸ã€‚</li>
<li>å¯ä»¥å¤„ç†æˆå¯¹çš„å¥å­åˆ—è¡¨ åƒä¸Šé¢çš„ç¤ºä¾‹ä¸€æ ·ï¼Œå¦‚æœé”®æ‰€å¯¹åº”çš„å€¼åŒ…å«å¤šä¸ªå¥å­ï¼ˆæ¯ä¸ªé”®ä½œä¸ºä¸€ä¸ªå¥å­åˆ—è¡¨ï¼‰ï¼Œé‚£ä¹ˆå®ƒä¾ç„¶å¯ä»¥å·¥ä½œã€‚</li>
<li>æˆ‘ä»¬å¯ä»¥åœ¨è°ƒç”¨<strong>map()<strong>ä½¿ç”¨è¯¥é€‰é¡¹ <strong>batched=True</strong> ï¼Œè¿™å°†æ˜¾è‘—åŠ å¿«æ ‡è®°ä¸æ ‡è®°çš„é€Ÿåº¦ã€‚è¿™ä¸ª</strong>æ ‡è®°å™¨</strong>æ¥è‡ª<a target="_blank" rel="noopener" href="https://github.com/huggingface/tokenizers">ğŸ¤— Tokenizers</a>åº“ç”±Rustç¼–å†™è€Œæˆã€‚å½“æˆ‘ä»¬ä¸€æ¬¡ç»™å®ƒå¤§é‡çš„è¾“å…¥æ—¶ï¼Œè¿™ä¸ªæ ‡è®°å™¨å¯ä»¥éå¸¸å¿«ã€‚</li>
</ul>
</blockquote>
</li>
<li><p>æˆ‘ä»¬ç°åœ¨åœ¨æ ‡è®°å‡½æ•°ä¸­çœç•¥äº†<strong>padding</strong>å‚æ•°ã€‚è¿™æ˜¯å› ä¸ºåœ¨æ ‡è®°çš„æ—¶å€™å°†æ‰€æœ‰æ ·æœ¬å¡«å……åˆ°æœ€å¤§é•¿åº¦çš„æ•ˆç‡ä¸é«˜ã€‚ä¸€ä¸ªæ›´å¥½çš„åšæ³•ï¼šåœ¨æ„å»ºæ‰¹å¤„ç†æ—¶å¡«å……æ ·æœ¬æ›´å¥½ï¼Œå› ä¸ºè¿™æ ·æˆ‘ä»¬åªéœ€è¦å¡«å……åˆ°è¯¥æ‰¹å¤„ç†ä¸­çš„æœ€å¤§é•¿åº¦ï¼Œè€Œä¸æ˜¯æ•´ä¸ªæ•°æ®é›†çš„æœ€å¤§é•¿åº¦ã€‚å½“è¾“å…¥é•¿åº¦å˜åŒ–å¾ˆå¤§æ—¶ï¼Œè¿™å¯ä»¥èŠ‚çœå¤§é‡æ—¶é—´å’Œå¤„ç†èƒ½åŠ›!</p>
</li>
<li><p>Datasetsåº“åº”ç”¨è¿™ç§å¤„ç†çš„æ–¹å¼æ˜¯å‘æ•°æ®é›†æ·»åŠ æ–°çš„å­—æ®µï¼Œthose three fields are added to all splits of our dataset. </p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">DatasetDict({<br>    train: Dataset({<br>        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],<br>        num_rows: 3668<br>    })<br>    validation: Dataset({<br>        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],<br>        num_rows: 408<br>    })<br>    test: Dataset({<br>        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],<br>        num_rows: 1725<br>    })<br>})<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>You can even use multiprocessing when applying your preprocessing function with <code>map()</code> by passing along a <code>num_proc</code> argument. We didnâ€™t do this here because the Tokenizers library already uses multiple threads to tokenize our samples faster, but if you are <strong>not using a fast tokenizer backed by this library</strong>, this could speed up your preprocessing.</p>
</li>
<li><p>æˆ‘ä»¬çš„tokenize_functionè¿”å›ä¸€ä¸ªåŒ…å«input_idsã€attention_maskå’Œtoken_type_idsé”®çš„å­—å…¸ï¼Œå› æ­¤è¿™ä¸‰ä¸ªå­—æ®µè¢«æ·»åŠ åˆ°æˆ‘ä»¬æ•°æ®é›†çš„æ‰€æœ‰åˆ†å‰²ä¸­ã€‚è¯·æ³¨æ„ï¼Œå¦‚æœæˆ‘ä»¬çš„é¢„å¤„ç†å‡½æ•°è¿”å›äº†æ•°æ®é›†ä¸­ç°æœ‰é”®çš„æ–°å€¼ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ”¹å˜ç°æœ‰å­—æ®µï¼Œå‰ææ˜¯æˆ‘ä»¬å¯¹æ•°æ®é›†åº”ç”¨äº†map()ã€‚</p>
</li>
</ul>
</li>
<li><p>Dynamic padding</p>
<ul>
<li><p>è´Ÿè´£å°†æ ·æœ¬ç»„åˆæˆä¸€ä¸ªæ‰¹æ¬¡çš„å‡½æ•°ç§°ä¸ºcollateå‡½æ•°ã€‚å®ƒæ˜¯ä½ åœ¨æ„å»ºDataLoaderæ—¶å¯ä»¥ä¼ é€’çš„ä¸€ä¸ªå‚æ•°ï¼Œé»˜è®¤æƒ…å†µä¸‹æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒåªä¼šå°†ä½ çš„æ ·æœ¬è½¬æ¢ä¸ºPyTorchå¼ é‡å¹¶å°†å®ƒä»¬è¿æ¥èµ·æ¥ï¼ˆå¦‚æœä½ çš„å…ƒç´ æ˜¯åˆ—è¡¨ã€å…ƒç»„æˆ–å­—å…¸ï¼Œåˆ™é€’å½’è¿æ¥ï¼‰ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œè¿™å°†æ˜¯ä¸å¯èƒ½çš„ï¼Œå› ä¸ºæˆ‘ä»¬çš„è¾“å…¥ä¸ä¼šå…¨éƒ¨æ˜¯ç›¸åŒçš„å¤§å°ã€‚æˆ‘ä»¬æ•…æ„æ¨è¿Ÿäº†å¡«å……ï¼Œåªåœ¨æ¯ä¸ªæ‰¹æ¬¡ä¸­æŒ‰éœ€åº”ç”¨å®ƒï¼Œä»¥é¿å…æœ‰è¿‡å¤šå¡«å……çš„è¿‡é•¿è¾“å…¥ã€‚è¿™å°†é€šè¿‡ç›¸å½“å¤šçš„æ–¹å¼åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œä½†è¯·æ³¨æ„ï¼Œå¦‚æœä½ åœ¨TPUä¸Šè®­ç»ƒï¼Œå®ƒå¯èƒ½ä¼šå¯¼è‡´é—®é¢˜â€”â€”TPUæ›´å–œæ¬¢å›ºå®šçš„å½¢çŠ¶ï¼Œå³ä½¿è¿™éœ€è¦é¢å¤–çš„å¡«å……ã€‚</p>
</li>
<li><p>collateå‡½æ•°ï¼Œå®ƒå°†å¯¹æ•°æ®é›†ä¸­æˆ‘ä»¬æƒ³è¦ç»„åˆæˆæ‰¹æ¬¡çš„é¡¹ç›®åº”ç”¨æ­£ç¡®çš„å¡«å……é‡ã€‚Transformersåº“é€šè¿‡DataCollatorWithPaddingä¸ºæˆ‘ä»¬æä¾›äº†è¿™æ ·ä¸€ä¸ªå‡½æ•°ã€‚å½“ä½ å®ä¾‹åŒ–å®ƒæ—¶ï¼Œå®ƒéœ€è¦ä¸€ä¸ªtokenizerï¼ˆä»¥çŸ¥é“ä½¿ç”¨å“ªä¸ªå¡«å……æ ‡è®°ï¼Œä»¥åŠæ¨¡å‹æ˜¯å¦æœŸæœ›å¡«å……åœ¨è¾“å…¥çš„å·¦ä¾§è¿˜æ˜¯å³ä¾§ï¼‰ï¼Œå¹¶ä¸”ä¼šåšä½ éœ€è¦åšçš„ä¸€åˆ‡ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding<br><br>data_collator = DataCollatorWithPadding(tokenizer=tokenizer)<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>ä»æˆ‘ä»¬çš„è®­ç»ƒé›†ä¸­æŠ“å–ä¸€äº›æˆ‘ä»¬æƒ³è¦ç»„åˆåœ¨ä¸€èµ·çš„æ ·æœ¬ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ç§»é™¤äº†idxã€sentence1å’Œsentence2åˆ—ï¼Œå› ä¸ºå®ƒä»¬ä¸éœ€è¦ï¼Œå¹¶ä¸”åŒ…å«å­—ç¬¦ä¸²ã€‚ï¼ˆTensorä¸­ä¸èƒ½åŒ…å«å­—ç¬¦ä¸²ï¼‰ï¼ŒæŸ¥çœ‹æ¯ä¸ªæ¡ç›®çš„é•¿åº¦ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">samples = tokenized_datasets[<span class="hljs-string">"train"</span>][:<span class="hljs-number">8</span>]<br>samples = {k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> samples.items() <span class="hljs-keyword">if</span> k <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">"idx"</span>, <span class="hljs-string">"sentence1"</span>, <span class="hljs-string">"sentence2"</span>]}<br>[<span class="hljs-built_in">len</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> samples[<span class="hljs-string">"input_ids"</span>]]<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>åˆ°äº†ä¸åŒé•¿åº¦çš„æ ·æœ¬ï¼Œä»32åˆ°67ã€‚åŠ¨æ€å¡«å……æ„å‘³ç€è¿™ä¸ªä¸€æ¬¡sampleä¸­ï¼Œæ‰€æœ‰çš„æ ·æœ¬éƒ½åº”è¯¥è¢«å¡«å……åˆ°67çš„é•¿åº¦ï¼Œå³æ‰¹æ¬¡å†…çš„æœ€å¤§é•¿åº¦ã€‚å¦‚æœæ²¡æœ‰åŠ¨æ€å¡«å……ï¼Œæ‰€æœ‰çš„æ ·æœ¬éƒ½å¿…é¡»è¢«å¡«å……åˆ°æ•´ä¸ªæ•°æ®é›†ä¸­çš„æœ€å¤§é•¿åº¦ï¼Œæˆ–è€…æ¨¡å‹å¯ä»¥æ¥å—çš„æœ€å¤§é•¿åº¦ã€‚</p>
</blockquote>
</li>
<li><p>åŠ¨æ€å¡«å……æ•ˆæœ</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">batch = data_collator(samples)<br>{k: v.shape <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>Result</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">{<span class="hljs-string">'attention_mask'</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),<br> <span class="hljs-string">'input_ids'</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),<br> <span class="hljs-string">'token_type_ids'</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),<br> <span class="hljs-string">'labels'</span>: torch.Size([<span class="hljs-number">8</span>])}<br></code></pre></td></tr></tbody></table></figure></li>
</ul>
</li>
</ul>
<h2 id="Fine-tuning-a-model-with-the-Trainer-API"><a href="#Fine-tuning-a-model-with-the-Trainer-API" class="headerlink" title="Fine-tuning a model with the Trainer API"></a>Fine-tuning a model with the Trainer API</h2><ul>
<li><p>Train</p>
<ul>
<li><p>Transformersæä¾›äº†ä¸€ä¸ª <strong>Trainer</strong> ç±»æ¥å¸®åŠ©æ‚¨åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šå¾®è°ƒä»»ä½•é¢„è®­ç»ƒæ¨¡å‹ã€‚é¢„å¤„ç†æ•°æ®ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding<br><br>raw_datasets = load_dataset(<span class="hljs-string">"glue"</span>, <span class="hljs-string">"mrpc"</span>)<br>checkpoint = <span class="hljs-string">"bert-base-uncased"</span><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">example</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(example[<span class="hljs-string">"sentence1"</span>], example[<span class="hljs-string">"sentence2"</span>], truncation=<span class="hljs-literal">True</span>)<br><br><br>tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)<br>data_collator = DataCollatorWithPadding(tokenizer=tokenizer)<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>ç¬¬ä¸€æ­¥æ˜¯å®šä¹‰ä¸€ä¸ª <strong>TrainingArguments</strong> ç±»ï¼Œå®ƒå°†åŒ…å« <strong>Trainer</strong>ç”¨äºè®­ç»ƒå’Œè¯„ä¼°çš„æ‰€æœ‰è¶…å‚æ•°ã€‚æ‚¨å”¯ä¸€å¿…é¡»æä¾›çš„å‚æ•°æ˜¯ä¿å­˜è®­ç»ƒæ¨¡å‹çš„ç›®å½•ï¼Œä»¥åŠè®­ç»ƒè¿‡ç¨‹ä¸­çš„checkpointã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments<br><br>training_args = TrainingArguments(<span class="hljs-string">"test-trainer"</span>)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>å¦‚æœæ‚¨æƒ³åœ¨è®­ç»ƒæœŸé—´è‡ªåŠ¨å°†æ¨¡å‹ä¸Šä¼ åˆ° Hubï¼Œè¯·å°†push_to_hub=Trueæ·»åŠ åˆ°TrainingArgumentsä¹‹ä¸­</p>
</blockquote>
</li>
<li><p>ç¬¬äºŒæ­¥æ˜¯å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ <strong>AutoModelForSequenceClassification</strong>ç±»ï¼Œå®ƒæœ‰ä¸¤ä¸ªå‚æ•°ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification<br><br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>åœ¨å®ä¾‹åŒ–æ­¤é¢„è®­ç»ƒæ¨¡å‹åä¼šæ”¶åˆ°è­¦å‘Šã€‚è¿™æ˜¯å› ä¸º BERT æ²¡æœ‰åœ¨å¥å­å¯¹åˆ†ç±»æ–¹é¢è¿›è¡Œè¿‡é¢„è®­ç»ƒï¼Œæ‰€ä»¥é¢„è®­ç»ƒæ¨¡å‹çš„å¤´éƒ¨å·²ç»è¢«ä¸¢å¼ƒï¼Œè€Œæ˜¯æ·»åŠ äº†ä¸€ä¸ªé€‚åˆå¥å­åºåˆ—åˆ†ç±»çš„æ–°å¤´éƒ¨ã€‚è­¦å‘Šè¡¨æ˜ä¸€äº›æƒé‡æ²¡æœ‰ä½¿ç”¨ï¼ˆå¯¹åº”äºä¸¢å¼ƒçš„é¢„è®­ç»ƒå¤´çš„é‚£äº›ï¼‰ï¼Œè€Œå…¶ä»–ä¸€äº›æƒé‡è¢«éšæœºåˆå§‹åŒ–ï¼ˆæ–°å¤´çš„é‚£äº›ï¼‰ã€‚æœ€åé¼“åŠ±æ‚¨è®­ç»ƒæ¨¡å‹ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬ç°åœ¨è¦åšçš„ã€‚</p>
</blockquote>
</li>
<li><p>ç¬¬ä¸‰æ­¥å°±å¯ä»¥å®šä¹‰ä¸€ä¸ª <strong>Trainer</strong> é€šè¿‡å°†ä¹‹å‰æ„é€ çš„æ‰€æœ‰å¯¹è±¡ä¼ é€’ç»™å®ƒ</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer<br><br>trainer = Trainer(<br>  model,<br>  training_args,<br>  train_dataset=tokenized_datasets[<span class="hljs-string">"train"</span>],<br>  eval_dataset=tokenized_datasets[<span class="hljs-string">"validation"</span>],<br>  data_collator=data_collator,<br>  tokenizer=tokenizer,<br>)<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>å¼€å§‹è®­ç»ƒï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">trainer.train()<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>è¿™å°†å¼€å§‹å¾®è°ƒï¼Œå¹¶æ¯500æ­¥æŠ¥å‘Šä¸€æ¬¡è®­ç»ƒæŸå¤±ã€‚ä½†æ˜¯ï¼Œå®ƒä¸ä¼šå‘Šè¯‰æ‚¨æ¨¡å‹çš„æ€§èƒ½å¦‚ä½•ï¼ˆæˆ–è´¨é‡å¦‚ä½•ï¼‰ã€‚è¿™æ˜¯å› ä¸º:</p>
<ol>
<li>æˆ‘ä»¬æ²¡æœ‰é€šè¿‡å°†<strong>evaluation_strategy</strong>è®¾ç½®ä¸ºâ€œ<strong>steps</strong>â€(åœ¨æ¯æ¬¡æ›´æ–°å‚æ•°çš„æ—¶å€™è¯„ä¼°)æˆ–â€œ<strong>epoch</strong>â€(åœ¨æ¯ä¸ªepochç»“æŸæ—¶è¯„ä¼°)æ¥å‘Šè¯‰<strong>Trainer</strong>åœ¨è®­ç»ƒæœŸé—´è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>æˆ‘ä»¬æ²¡æœ‰ä¸º<strong>Trainer</strong>æä¾›ä¸€ä¸ª**compute_metrics()**å‡½æ•°æ¥ç›´æ¥è®¡ç®—æ¨¡å‹çš„å¥½å(å¦åˆ™è¯„ä¼°å°†åªè¾“å‡ºlossï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªéå¸¸ç›´è§‚çš„æ•°å­—)ã€‚</li>
</ol>
</blockquote>
</li>
</ul>
</li>
<li><p>Evaluate</p>
<ul>
<li><p>æ„å»ºä¸€ä¸ªæœ‰ç”¨çš„ <strong>compute_metrics()</strong> å‡½æ•°å¹¶åœ¨æˆ‘ä»¬ä¸‹æ¬¡è®­ç»ƒæ—¶ä½¿ç”¨å®ƒã€‚è¯¥å‡½æ•°å¿…é¡»é‡‡ç”¨ <strong>EvalPrediction</strong> å¯¹è±¡ï¼ˆå¸¦æœ‰ <strong>predictions</strong> å’Œ <strong>label_ids</strong> å­—æ®µçš„å‚æ•°å…ƒç»„ï¼‰å¹¶å°†è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²åˆ°æµ®ç‚¹æ•°çš„å­—å…¸ï¼ˆå­—ç¬¦ä¸²æ˜¯è¿”å›çš„æŒ‡æ ‡çš„åç§°ï¼Œè€Œæµ®ç‚¹æ•°æ˜¯å®ƒä»¬çš„å€¼ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ <strong>Trainer.predict()</strong> å‘½ä»¤æ¥ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">predictions = trainer.predict(tokenized_datasets[<span class="hljs-string">"validation"</span>])<br><span class="hljs-built_in">print</span>(predictions.predictions.shape, predictions.label_ids.shape)<br><br><span class="hljs-comment"># Result</span><br>(<span class="hljs-number">408</span>, <span class="hljs-number">2</span>) (<span class="hljs-number">408</span>,)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p><strong>predict()</strong> çš„è¾“å‡ºç»“æœæ˜¯å…·æœ‰ä¸‰ä¸ªå­—æ®µçš„å‘½åå…ƒç»„ï¼š <strong>predictions</strong> , <strong>label_ids</strong> ï¼Œ å’Œ <strong>metrics</strong> .è¿™ <strong>metrics</strong> å­—æ®µå°†åªåŒ…å«ä¼ é€’çš„æ•°æ®é›†çš„lossï¼Œä»¥åŠä¸€äº›è¿è¡Œæ—¶é—´ï¼ˆé¢„æµ‹æ‰€éœ€çš„æ€»æ—¶é—´å’Œå¹³å‡æ—¶é—´ï¼‰ã€‚å¦‚æœæˆ‘ä»¬å®šä¹‰äº†è‡ªå·±çš„ <strong>compute_metrics()</strong> å‡½æ•°å¹¶å°†å…¶ä¼ é€’ç»™ <strong>Trainer</strong> ï¼Œè¯¥å­—æ®µè¿˜å°†åŒ…å«**compute_metrics()**çš„ç»“æœã€‚</p>
<p><strong>predict()</strong> æ–¹æ³•æ˜¯å…·æœ‰ä¸‰ä¸ªå­—æ®µçš„å‘½åå…ƒç»„ï¼š <strong>predictions</strong> , <strong>label_ids</strong> ï¼Œ å’Œ <strong>metrics</strong> .è¿™ <strong>metrics</strong> å­—æ®µå°†åªåŒ…å«ä¼ é€’çš„æ•°æ®é›†çš„lossï¼Œä»¥åŠä¸€äº›è¿è¡Œæ—¶é—´ï¼ˆé¢„æµ‹æ‰€éœ€çš„æ€»æ—¶é—´å’Œå¹³å‡æ—¶é—´ï¼‰ã€‚å¦‚æœæˆ‘ä»¬å®šä¹‰äº†è‡ªå·±çš„ <strong>compute_metrics()</strong> å‡½æ•°å¹¶å°†å…¶ä¼ é€’ç»™ <strong>Trainer</strong> ï¼Œè¯¥å­—æ®µè¿˜å°†åŒ…å«<strong>compute_metrics()</strong> çš„ç»“æœã€‚å¦‚ä½ çœ‹åˆ°çš„ï¼Œ <strong>predictions</strong> æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º 408 x 2 çš„äºŒç»´æ•°ç»„ï¼ˆ408 æ˜¯æˆ‘ä»¬ä½¿ç”¨çš„æ•°æ®é›†ä¸­å…ƒç´ çš„æ•°é‡ï¼‰ã€‚è¿™äº›æ˜¯æˆ‘ä»¬ä¼ é€’ç»™**predict()**çš„æ•°æ®é›†çš„æ¯ä¸ªå…ƒç´ çš„ç»“æœ(logits)ã€‚</p>
</blockquote>
</li>
<li><p>è¦å°†æˆ‘ä»¬çš„é¢„æµ‹çš„å¯ä»¥ä¸çœŸæ­£çš„æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬éœ€è¦åœ¨ç¬¬äºŒä¸ªè½´ä¸Šå–æœ€å¤§å€¼çš„ç´¢å¼•ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>preds = np.argmax(predictions.predictions, axis=-<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>ç°åœ¨å»ºç«‹æˆ‘ä»¬çš„ compute_metric() å‡½æ•°æ¥è¾ƒä¸ºç›´è§‚åœ°è¯„ä¼°æ¨¡å‹çš„å¥½åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨   Evaluate åº“ä¸­çš„æŒ‡æ ‡ã€‚æˆ‘ä»¬å¯ä»¥åƒåŠ è½½æ•°æ®é›†ä¸€æ ·è½»æ¾åŠ è½½ä¸ MRPC æ•°æ®é›†å…³è”çš„æŒ‡æ ‡ï¼Œè¿™æ¬¡ä½¿ç”¨ evaluate.load() å‡½æ•°ã€‚è¿”å›çš„å¯¹è±¡æœ‰ä¸€ä¸ª compute()æ–¹æ³•æˆ‘ä»¬å¯ä»¥ç”¨æ¥è¿›è¡Œåº¦é‡è®¡ç®—çš„æ–¹æ³•ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> evaluate<br><br>metric = evaluate.load(<span class="hljs-string">"glue"</span>, <span class="hljs-string">"mrpc"</span>)<br>metric.compute(predictions=preds, references=predictions.label_ids)<br><br><span class="hljs-comment"># Result {'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}</span><br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>å°†æ‰€æœ‰ä¸œè¥¿æ‰“åŒ…åœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬å¾—åˆ°äº†æˆ‘ä»¬çš„ <strong>compute_metrics()</strong> å‡½æ•°ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):<br>    metric = evaluate.load(<span class="hljs-string">"glue"</span>, <span class="hljs-string">"mrpc"</span>)<br>    logits, labels = eval_preds<br>    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>ä¸ºäº†æŸ¥çœ‹æ¨¡å‹åœ¨æ¯ä¸ªè®­ç»ƒå‘¨æœŸç»“æŸçš„å¥½åï¼Œä¸‹é¢æ˜¯æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨**compute_metrics()**å‡½æ•°å®šä¹‰ä¸€ä¸ªæ–°çš„ <strong>Trainer</strong> ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">training_args = TrainingArguments(<span class="hljs-string">"test-trainer"</span>, evaluation_strategy=<span class="hljs-string">"epoch"</span>)<br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)<br><br>trainer = Trainer(<br>    model,<br>    training_args,<br>    train_dataset=tokenized_datasets[<span class="hljs-string">"train"</span>],<br>    eval_dataset=tokenized_datasets[<span class="hljs-string">"validation"</span>],<br>    data_collator=data_collator,<br>    tokenizer=tokenizer,<br>    compute_metrics=compute_metrics,<br>)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>å®ƒå°†åœ¨è®­ç»ƒlossä¹‹å¤–ï¼Œè¿˜ä¼šè¾“å‡ºæ¯ä¸ª epoch ç»“æŸæ—¶çš„éªŒè¯losså’ŒæŒ‡æ ‡ã€‚åŒæ ·ï¼Œç”±äºæ¨¡å‹çš„éšæœºå¤´éƒ¨åˆå§‹åŒ–ï¼Œæ‚¨è¾¾åˆ°çš„å‡†ç¡®ç‡/F1 åˆ†æ•°å¯èƒ½ä¸æˆ‘ä»¬å‘ç°çš„ç•¥æœ‰ä¸åŒï¼Œä½†å®ƒåº”è¯¥åœ¨åŒä¸€èŒƒå›´å†…ã€‚</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="A-Full-Training"><a href="#A-Full-Training" class="headerlink" title="A Full Training"></a>A Full Training</h2><ul>
<li>ç®€å•æ€»ç»“ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding<br><br>raw_datasets = load_dataset(<span class="hljs-string">"glue"</span>, <span class="hljs-string">"mrpc"</span>)<br>checkpoint = <span class="hljs-string">"bert-base-uncased"</span><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">example</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(example[<span class="hljs-string">"sentence1"</span>], example[<span class="hljs-string">"sentence2"</span>], truncation=<span class="hljs-literal">True</span>)<br><br><br>tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)<br>data_collator = DataCollatorWithPadding(tokenizer=tokenizer)<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li><p>æˆ‘ä»¬éœ€è¦å¯¹æˆ‘ä»¬çš„<code>tokenized_datasets</code>åšä¸€äº›å¤„ç†ï¼Œæ¥å¤„ç†<code>Trainer</code>è‡ªåŠ¨ä¸ºæˆ‘ä»¬åšçš„ä¸€äº›äº‹æƒ…ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬éœ€è¦:</p>
<ul>
<li>åˆ é™¤ä¸æ¨¡å‹ä¸æœŸæœ›çš„å€¼ç›¸å¯¹åº”çš„åˆ—ï¼ˆå¦‚<code>sentence1</code>å’Œ<code>sentence2</code>åˆ—ï¼‰ã€‚</li>
<li>å°†åˆ—å<code>label</code>é‡å‘½åä¸º<code>labels</code>ï¼ˆå› ä¸ºæ¨¡å‹æœŸæœ›å‚æ•°æ˜¯<code>labels</code>ï¼‰ã€‚</li>
<li>è®¾ç½®æ•°æ®é›†çš„æ ¼å¼ï¼Œä½¿å…¶è¿”å› PyTorch å¼ é‡è€Œä¸æ˜¯åˆ—è¡¨ã€‚</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenized_datasets = tokenized_datasets.remove_columns([<span class="hljs-string">"sentence1"</span>, <span class="hljs-string">"sentence2"</span>, <span class="hljs-string">"idx"</span>])<br>tokenized_datasets = tokenized_datasets.rename_column(<span class="hljs-string">"label"</span>, <span class="hljs-string">"labels"</span>)<br>tokenized_datasets.set_format(<span class="hljs-string">"torch"</span>)<br>tokenized_datasets[<span class="hljs-string">"train"</span>].column_names<br><br><br><span class="hljs-comment"># Result ["attention_mask", "input_ids", "labels", "token_type_ids"]</span><br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>å®šä¹‰Dataloader</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>train_dataloader = DataLoader(<br>    tokenized_datasets[<span class="hljs-string">"train"</span>], shuffle=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">8</span>, collate_fn=data_collator<br>)<br>eval_dataloader = DataLoader(<br>    tokenized_datasets[<span class="hljs-string">"validation"</span>], batch_size=<span class="hljs-number">8</span>, collate_fn=data_collator<br>)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>ä¸ºäº†å¿«é€Ÿæ£€éªŒæ•°æ®å¤„ç†ä¸­æ²¡æœ‰é”™è¯¯ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·æ£€éªŒå…¶ä¸­çš„ä¸€ä¸ªæ‰¹æ¬¡:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:<br>    <span class="hljs-keyword">break</span><br>{k: v.shape <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}<br></code></pre></td></tr></tbody></table></figure>

<p>å®é™…çš„å½¢çŠ¶å¯èƒ½ç•¥æœ‰ä¸åŒï¼Œå› ä¸ºæˆ‘ä»¬ä¸ºè®­ç»ƒæ•°æ®åŠ è½½å™¨è®¾ç½®äº†<code>shuffle=True</code>ï¼Œå¹¶ä¸”æ¨¡å‹ä¼šå°†å¥å­å¡«å……åˆ°<code>batch</code>ä¸­çš„æœ€å¤§é•¿åº¦ã€‚</p>
</blockquote>
</li>
<li><p>æ¨¡å‹</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification<br><br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)<br><br>outputs = model(**batch)<br><span class="hljs-built_in">print</span>(outputs.loss, outputs.logits.shape)<br><br><span class="hljs-comment"># Result tensor(0.5441, grad_fn=&lt;NllLossBackward&gt;) torch.Size([8, 2])</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>å½“æˆ‘ä»¬æä¾› <code>labels</code> æ—¶ï¼ŒTransformers æ¨¡å‹éƒ½å°†è¿”å›è¿™ä¸ª<code>batch</code>çš„<code>loss</code>ï¼Œæˆ‘ä»¬è¿˜å¾—åˆ°äº† <code>logits</code>(<code>batch</code>ä¸­çš„æ¯ä¸ªè¾“å…¥æœ‰ä¸¤ä¸ªï¼Œæ‰€ä»¥å¼ é‡å¤§å°ä¸º 8 x 2)ã€‚</p>
</blockquote>
</li>
<li><p>ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler<br><br>optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">5e-5</span>) <br>num_epochs = <span class="hljs-number">3</span><br>num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dataloader)<br>lr_scheduler = get_scheduler(<br>    <span class="hljs-string">"linear"</span>,<br>    optimizer=optimizer,<br>    num_warmup_steps=<span class="hljs-number">0</span>,<br>    num_training_steps=num_training_steps,<br>)<br><span class="hljs-built_in">print</span>(num_training_steps)<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>å¾ªç¯è®­ç»ƒï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm<br><br>device = torch.device(<span class="hljs-string">"cuda"</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">"cpu"</span>)<br>model.to(device)<br><br>progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))<br><br>model.train()<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:<br>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}<br>        outputs = model(**batch)<br>        loss = outputs.loss<br>        loss.backward()<br><br>        optimizer.step()<br>        lr_scheduler.step()<br>        optimizer.zero_grad()<br>        progress_bar.update(<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>æ·»åŠ è¯„ä¼°ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> evaluate<br><br>metric = evaluate.load(<span class="hljs-string">"glue"</span>, <span class="hljs-string">"mrpc"</span>)<br>model.<span class="hljs-built_in">eval</span>()<br><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:<br>    batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        outputs = model(**batch)<br><br>    logits = outputs.logits<br>    predictions = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)<br>    metric.add_batch(predictions=predictions, references=batch[<span class="hljs-string">"labels"</span>])<br><br>metric.compute()<br><br><span class="hljs-comment"># Result: {'accuracy': 0.8431372549019608, 'f1': 0.8907849829351535}</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>Evaluate åº“æä¾›çš„æŒ‡æ ‡ã€‚æˆ‘ä»¬å·²ç»äº†è§£äº† <code>metric.compute()</code> æ–¹æ³•ï¼Œå½“æˆ‘ä»¬ä½¿ç”¨ <code>add_batch()</code>æ–¹æ³•è¿›è¡Œé¢„æµ‹å¾ªç¯æ—¶ï¼Œå®é™…ä¸Šè¯¥æŒ‡æ ‡å¯ä»¥ä¸ºæˆ‘ä»¬ç´¯ç§¯æ‰€æœ‰ <code>batch</code> çš„ç»“æœã€‚ä¸€æ—¦æˆ‘ä»¬ç´¯ç§¯äº†æ‰€æœ‰ <code>batch</code> ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ <code>metric.compute()</code> å¾—åˆ°æœ€ç»ˆç»“æœ .ä»¥ä¸‹æ˜¯åœ¨è¯„ä¼°å¾ªç¯ä¸­å®ç°æ‰€æœ‰è¿™äº›çš„æ–¹æ³•ã€‚</p>
</blockquote>
</li>
<li><p>ä½¿ç”¨AccelerateåŠ é€Ÿ</p>
<ul>
<li><p>ä½¿ç”¨<a target="_blank" rel="noopener" href="https://github.com/huggingface/accelerate">Accelerate</a>åº“ï¼Œåªéœ€è¿›è¡Œä¸€äº›è°ƒæ•´ï¼Œæˆ‘ä»¬å°±å¯ä»¥åœ¨å¤šä¸ª GPU æˆ– TPU ä¸Šå¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW, AutoModelForSequenceClassification, get_scheduler<br><br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)<br>optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">3e-5</span>)<br><br>device = torch.device(<span class="hljs-string">"cuda"</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">"cpu"</span>)<br>model.to(device)<br><br>num_epochs = <span class="hljs-number">3</span><br>num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dataloader)<br>lr_scheduler = get_scheduler(<br>    <span class="hljs-string">"linear"</span>,<br>    optimizer=optimizer,<br>    num_warmup_steps=<span class="hljs-number">0</span>,<br>    num_training_steps=num_training_steps,<br>)<br><br>progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))<br><br>model.train()<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:<br>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}<br>        outputs = model(**batch)<br>        loss = outputs.loss<br>        loss.backward()<br><br>        optimizer.step()<br>        lr_scheduler.step()<br>        optimizer.zero_grad()<br>        progress_bar.update(<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>åŠ å…¥Accelerate</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW, AutoModelForSequenceClassification, get_scheduler<br><br>accelerator = Accelerator()<br><br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)<br>optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">3e-5</span>)<br><br>train_dl, eval_dl, model, optimizer = accelerator.prepare(<br>    train_dataloader, eval_dataloader, model, optimizer<br>)<br><br>num_epochs = <span class="hljs-number">3</span><br>num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dl)<br>lr_scheduler = get_scheduler(<br>    <span class="hljs-string">"linear"</span>,<br>    optimizer=optimizer,<br>    num_warmup_steps=<span class="hljs-number">0</span>,<br>    num_training_steps=num_training_steps,<br>)<br><br>progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))<br><br>model.train()<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dl:<br>        outputs = model(**batch)<br>        loss = outputs.loss<br>        accelerator.backward(loss)<br><br>        optimizer.step()<br>        lr_scheduler.step()<br>        optimizer.zero_grad()<br>        progress_bar.update(<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>è¦æ·»åŠ çš„ç¬¬ä¸€è¡Œæ˜¯å¯¼å…¥<code>Accelerator</code>ã€‚ç¬¬äºŒè¡Œå®ä¾‹åŒ–ä¸€ä¸ª <code>Accelerator</code>å¯¹è±¡ ï¼Œå®ƒå°†æŸ¥çœ‹ç¯å¢ƒå¹¶åˆå§‹åŒ–é€‚å½“çš„åˆ†å¸ƒå¼è®¾ç½®ã€‚ Accelerate ä¸ºæ‚¨å¤„ç†æ•°æ®åœ¨è®¾å¤‡é—´çš„ä¼ é€’ï¼Œå› æ­¤æ‚¨å¯ä»¥åˆ é™¤å°†æ¨¡å‹æ”¾åœ¨è®¾å¤‡ä¸Šçš„é‚£è¡Œä»£ç ï¼ˆæˆ–è€…ï¼Œå¦‚æœæ‚¨æ„¿æ„ï¼Œå¯ä½¿ç”¨ <code>accelerator.device</code> ä»£æ›¿ <code>device</code> ï¼‰ã€‚</p>
<p>å¤§éƒ¨åˆ†å·¥ä½œä¼šåœ¨å°†æ•°æ®åŠ è½½å™¨ã€æ¨¡å‹å’Œä¼˜åŒ–å™¨å‘é€åˆ°çš„<code>accelerator.prepare()</code>ä¸­å®Œæˆã€‚è¿™å°†ä¼šæŠŠè¿™äº›å¯¹è±¡åŒ…è£…åœ¨é€‚å½“çš„å®¹å™¨ä¸­ï¼Œä»¥ç¡®ä¿æ‚¨çš„åˆ†å¸ƒå¼è®­ç»ƒæŒ‰é¢„æœŸå·¥ä½œã€‚è¦è¿›è¡Œçš„å…¶ä½™æ›´æ”¹æ˜¯åˆ é™¤å°†<code>batch</code>æ”¾åœ¨ <code>device</code> çš„é‚£è¡Œä»£ç ï¼ˆåŒæ ·ï¼Œå¦‚æœæ‚¨æƒ³ä¿ç•™å®ƒï¼Œæ‚¨å¯ä»¥å°†å…¶æ›´æ”¹ä¸ºä½¿ç”¨ <code>accelerator.device</code> ) å¹¶å°† <code>loss.backward()</code> æ›¿æ¢ä¸º<code>accelerator.backward(loss)</code>ã€‚</p>
</blockquote>
</li>
<li><p>âš ï¸ ä¸ºäº†ä½¿äº‘ç«¯ TPU æä¾›çš„åŠ é€Ÿå‘æŒ¥æœ€å¤§çš„æ•ˆç›Šï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨æ ‡è®°å™¨(tokenizer)çš„ <code>padding=max_length</code> å’Œ <code>max_length</code> å‚æ•°å°†æ‚¨çš„æ ·æœ¬å¡«å……åˆ°å›ºå®šé•¿åº¦ã€‚</p>
</li>
<li><p>è¦åœ¨åˆ†å¸ƒå¼è®¾ç½®ä¸­è¯•ç”¨å®ƒï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤:</p>
<figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arduino">accelerate config<br></code></pre></td></tr></tbody></table></figure>

<p>è¿™å°†è¯¢é—®æ‚¨å‡ ä¸ªé…ç½®çš„é—®é¢˜å¹¶å°†æ‚¨çš„å›ç­”è½¬å‚¨åˆ°æ­¤å‘½ä»¤ä½¿ç”¨çš„é…ç½®æ–‡ä»¶ä¸­ã€‚</p>
</li>
<li><p>å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">accelerate launch train.py<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>å¦‚æœæ‚¨æƒ³åœ¨ Notebook ä¸­å°è¯•æ­¤æ“ä½œï¼ˆä¾‹å¦‚ï¼Œåœ¨ Colab ä¸Šä½¿ç”¨ TPU è¿›è¡Œæµ‹è¯•ï¼‰ï¼Œåªéœ€å°†ä»£ç ç²˜è´´åˆ° <code>training_function()</code> å¹¶ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œæœ€åä¸€ä¸ªå•å…ƒæ ¼:</p>
<figure class="highlight stylus"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">from accelerate import notebook_launcher<br><br><span class="hljs-function"><span class="hljs-title">notebook_launcher</span><span class="hljs-params">(training_function)</span></span><br></code></pre></td></tr></tbody></table></figure>

<p>æ‚¨å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://github.com/huggingface/accelerate/tree/main/examples">Accelerate repo</a>æ‰¾åˆ°æ›´å¤šçš„ç¤ºä¾‹ã€‚</p>
</li>
</ul>
</li>
</ul>
<h2 id="Summary-3"><a href="#Summary-3" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>æ±‡æ€»ï¼š<ul>
<li>äº†è§£äº†<a target="_blank" rel="noopener" href="https://huggingface.co/datasets">Hub</a>ä¸­çš„æ•°æ®é›†</li>
<li>å­¦ä¹ äº†å¦‚ä½•åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŠ¨æ€å¡«å……å’Œæ•´ç†å™¨</li>
<li>å®ç°æ‚¨è‡ªå·±çš„æ¨¡å‹å¾®è°ƒå’Œè¯„ä¼°</li>
<li>å®æ–½äº†ä¸€ä¸ªè¾ƒä¸ºåº•å±‚çš„è®­ç»ƒå¾ªç¯</li>
<li>ä½¿ç”¨ Accelerate è°ƒæ•´æ‚¨çš„è®­ç»ƒå¾ªç¯ï¼Œä½¿å…¶é€‚ç”¨äºå¤šä¸ª GPU æˆ– TPU</li>
</ul>
</li>
<li>Little test: <a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/en/chapter3/6?fw=pt">https://huggingface.co/learn/nlp-course/en/chapter3/6?fw=pt</a></li>
</ul>
<h1 id="Sharing-Models-and-Tokenizers-Optional"><a href="#Sharing-Models-and-Tokenizers-Optional" class="headerlink" title="Sharing Models and Tokenizers(Optional)"></a>Sharing Models and Tokenizers(Optional)</h1><h2 id="Using-pretrained-models"><a href="#Using-pretrained-models" class="headerlink" title="Using pretrained models"></a>Using pretrained models</h2><ul>
<li>ä½ å”¯ä¸€éœ€è¦æ³¨æ„çš„æ˜¯æ‰€é€‰æ£€æŸ¥ç‚¹æ˜¯å¦é€‚åˆå®ƒå°†ç”¨äºçš„ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œè¿™é‡Œæˆ‘ä»¬æ­£åœ¨å°† <code>camembert-base</code> æ£€æŸ¥ç‚¹åŠ è½½åœ¨ <code>fill-mask</code> ç®¡é“ï¼Œè¿™å®Œå…¨æ²¡é—®é¢˜ã€‚ä½†æ˜¯å¦‚æœæˆ‘ä»¬åœ¨ <code>text-classification</code> ç®¡é“åŠ è½½æ£€æŸ¥ç‚¹ï¼Œç»“æœæ²¡æœ‰ä»»ä½•æ„ä¹‰ï¼Œå› ä¸º <code>camembert-base</code> ä¸é€‚åˆè¿™ä¸ªä»»åŠ¡ï¼æˆ‘ä»¬å»ºè®®ä½¿ç”¨ Hugging Face Hub ç•Œé¢ä¸­çš„ä»»åŠ¡é€‰æ‹©å™¨æ¥é€‰æ‹©åˆé€‚çš„æ£€æŸ¥ç‚¹ï¼š</li>
</ul>
<p><img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/tasks.png" srcset="/img/loading.gif" lazyload alt="The task selector on the web interface."></p>
<ul>
<li>ç”¨pipelineä½¿ç”¨</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>camembert_fill_mask = pipeline(<span class="hljs-string">"fill-mask"</span>, model=<span class="hljs-string">"camembert-base"</span>)<br>results = camembert_fill_mask(<span class="hljs-string">"Le camembert est &lt;mask&gt; :)"</span>)<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li><p>ç”¨model/tokenizerä½¿ç”¨</p>
<ul>
<li><p>ç›´æ¥ä½¿ç”¨</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> CamembertTokenizer, CamembertForMaskedLM<br><br>tokenizer = CamembertTokenizer.from_pretrained(<span class="hljs-string">"camembert-base"</span>)<br>model = CamembertForMaskedLM.from_pretrained(<span class="hljs-string">"camembert-base"</span>)<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>ä½¿ç”¨Autoç±»(æˆ‘ä»¬å»ºè®®ä½¿ç”¨ <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/auto.html?highlight=auto#auto-classes"><code>Auto*</code> ç±»</a>ï¼Œå› ä¸º <code>Auto*</code> ç±»è®¾è®¡ä¸æ¶æ„æ— å…³ã€‚)ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForMaskedLM<br><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"camembert-base"</span>)<br>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">"camembert-base"</span>)<br></code></pre></td></tr></tbody></table></figure></li>
</ul>
</li>
</ul>
<h2 id="Sharing-pretrained-models"><a href="#Sharing-pretrained-models" class="headerlink" title="Sharing pretrained models"></a>Sharing pretrained models</h2><ul>
<li><p>åˆ›å»ºæ–°æ¨¡å‹å­˜å‚¨åº“çš„æ–¹æ³•æœ‰ä»¥ä¸‹ä¸‰ç§ï¼š</p>
<ul>
<li><p>ä½¿ç”¨ push_to_hub API æ¥å£</p>
</li>
<li><p>ä½¿ç”¨ huggingface_hub Python åº“</p>
</li>
<li><p>ä½¿ç”¨ web ç•Œé¢</p>
</li>
</ul>
</li>
<li><p>ä¸æ˜¯é‡ç‚¹ï¼Œå…¶ä½™è¯·å‚è€ƒï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/zh-CN/chapter4/3?fw=pt">https://huggingface.co/learn/nlp-course/zh-CN/chapter4/3?fw=pt</a></p>
</li>
</ul>
<h2 id="Building-model-cards"><a href="#Building-model-cards" class="headerlink" title="Building model cards"></a>Building model cards</h2><ul>
<li>ä¸æ˜¯é‡ç‚¹ï¼Œå…¶ä½™è¯·å‚è€ƒï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/zh-CN/chapter4/4?fw=pt">https://huggingface.co/learn/nlp-course/zh-CN/chapter4/4?fw=pt</a></li>
</ul>
<h2 id="Summary-4"><a href="#Summary-4" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>æ­¤ç« èŠ‚ä¸æ˜¯é‡ç‚¹ï¼Œè¯·å‚è€ƒï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/zh-CN/chapter4/6?fw=pt">https://huggingface.co/learn/nlp-course/zh-CN/chapter4/6?fw=pt</a></li>
</ul>
<h1 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h1><h2 id="Introduction-3"><a href="#Introduction-3" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><p>æˆ‘ä»¬å°†æ‰¾åˆ°ä»¥ä¸‹é—®é¢˜çš„ç­”æ¡ˆï¼š</p>
<ul>
<li><p>å½“æ•°æ®é›†ä¸åœ¨hubä¸Šæ—¶ï¼Œæ‚¨è¯¥æ€ä¹ˆåšï¼Ÿ</p>
</li>
<li><p>å¦‚ä½•å¯¹æ•°æ®é›†è¿›è¡Œåˆ‡ç‰‡ï¼Ÿï¼ˆå¦‚æœä½ çœŸæ­£çš„ç‰¹åˆ«éœ€è¦ä½¿ç”¨pandasçš„æ—¶å€™è¯¥æ€ä¹ˆåŠï¼Ÿï¼‰</p>
</li>
<li><p>å½“ä½ çš„æ•°æ®é›†å¾ˆå¤§ï¼Œä¼šæ’‘çˆ†ä½ ç¬”è®°æœ¬ç”µè„‘çš„RAMæ—¶ï¼Œä½ ä¼šæ€ä¹ˆåšï¼Ÿ</p>
</li>
<li><p>â€œå†…å­˜æ˜ å°„â€å’ŒApache Arrowåˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿ</p>
</li>
<li><p>å¦‚ä½•åˆ›å»ºè‡ªå·±çš„æ•°æ®é›†å¹¶å°†å…¶æ¨é€åˆ°ä¸­å¿ƒï¼Ÿ</p>
</li>
</ul>
</li>
</ul>
<h2 id="Dataset-Loading"><a href="#Dataset-Loading" class="headerlink" title="Dataset Loading"></a>Dataset Loading</h2><h3 id="Local-dataset"><a href="#Local-dataset" class="headerlink" title="Local dataset"></a>Local dataset</h3><ul>
<li>åŠ è½½æ•°æ®é›†çš„æ–¹æ³•ï¼š</li>
</ul>
<p>atasets æä¾›äº†åŠ è½½è„šæœ¬æ¥åŠ è½½æœ¬åœ°å’Œè¿œç¨‹æ•°æ®é›†ã€‚å®ƒæ”¯æŒå‡ ç§å¸¸è§çš„æ•°æ®æ ¼å¼ï¼Œä¾‹å¦‚ï¼š</p>
<table>
<thead>
<tr>
<th>Data format</th>
<th>Loading script</th>
<th>Example</th>
</tr>
</thead>
<tbody><tr>
<td>CSV &amp; TSV</td>
<td><code>csv</code></td>
<td><code>load_dataset("csv", data_files="my_file.csv")</code></td>
</tr>
<tr>
<td>Text files</td>
<td><code>text</code></td>
<td><code>load_dataset("text", data_files="my_file.txt")</code></td>
</tr>
<tr>
<td>JSON &amp; JSON Lines</td>
<td><code>json</code></td>
<td><code>load_dataset("json", data_files="my_file.jsonl")</code></td>
</tr>
<tr>
<td>Pickled DataFrames</td>
<td><code>pandas</code></td>
<td><code>load_dataset("pandas", data_files="my_dataframe.pkl")</code></td>
</tr>
</tbody></table>
<p>å¦‚è¡¨æ‰€ç¤º, å¯¹äºæ¯ç§æ•°æ®æ ¼å¼, æˆ‘ä»¬åªéœ€è¦ä½¿ç”¨ <code>load_dataset()</code> å‡½æ•°, ä½¿ç”¨ <code>data_files</code> æŒ‡å®šä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶çš„è·¯å¾„çš„å‚æ•°ã€‚ è®©æˆ‘ä»¬ä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ•°æ®é›†å¼€å§‹ï¼›ç¨åæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å¯¹è¿œç¨‹æ–‡ä»¶æ‰§è¡Œç›¸åŒçš„æ“ä½œã€‚</p>
<ul>
<li><p>ä¸€ä¸ªDemo</p>
<ul>
<li><p>ä¸‹è½½è§£å‹æ•°æ®é›†</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz<br>!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">æˆ‘ä»¬å¯ä»¥ç”¨Linuxçš„è§£å‹å‘½ä»¤ gzip</span><br>!gzip -dkv SQuAD_it-*.json.gz<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å‹ç¼©æ–‡ä»¶å·²ç»è¢«æ›¿æ¢ä¸ºSQuAD_it-train.jsonå’ŒSQuAD_it-test.json,å¹¶ä¸”æ•°æ®ä»¥ JSON æ ¼å¼å­˜å‚¨ã€‚ä½¿ç”¨<code>load_dataset()</code>å‡½æ•°æ¥åŠ è½½JSONæ–‡ä»¶, æˆ‘ä»¬åªéœ€è¦çŸ¥é“æˆ‘ä»¬æ˜¯åœ¨å¤„ç†æ™®é€šçš„ JSON(ç±»ä¼¼äºåµŒå¥—å­—å…¸)è¿˜æ˜¯ JSON è¡Œ(è¡Œåˆ†éš”çš„ JSON)ã€‚åƒè®¸å¤šé—®ç­”æ•°æ®é›†ä¸€æ ·, SQuAD-it ä½¿ç”¨åµŒå¥—æ ¼å¼,æ‰€æœ‰æ–‡æœ¬éƒ½å­˜å‚¨åœ¨ <code>data</code>æ–‡ä»¶ä¸­ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥é€šè¿‡æŒ‡å®šå‚æ•°<code>field</code>æ¥åŠ è½½æ•°æ®é›†,å¦‚ä¸‹æ‰€ç¤º:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>squad_it_dataset = load_dataset(<span class="hljs-string">"json"</span>, data_files=<span class="hljs-string">"SQuAD_it-train.json"</span>, field=<span class="hljs-string">"data"</span>)<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>é»˜è®¤æƒ…å†µä¸‹, åŠ è½½æœ¬åœ°æ–‡ä»¶ä¼šåˆ›å»ºä¸€ä¸ªå¸¦æœ‰<code>train</code>çš„<code>DatasetDict</code> å¯¹è±¡ã€‚ æˆ‘ä»¬å¯ä»¥é€šè¿‡ <code>squad_it_dataset</code>æŸ¥çœ‹:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">squad_it_dataset<br></code></pre></td></tr></tbody></table></figure>

<figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs json">DatasetDict(<span class="hljs-punctuation">{</span><br>    train<span class="hljs-punctuation">:</span> Dataset(<span class="hljs-punctuation">{</span><br>        features<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>'title'<span class="hljs-punctuation">,</span> 'paragraphs'<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        num_rows<span class="hljs-punctuation">:</span> <span class="hljs-number">442</span><br>    <span class="hljs-punctuation">}</span>)<br><span class="hljs-punctuation">}</span>)<br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>æˆ‘ä»¬å¯ä»¥é€šè¿‡ç´¢å¼•åˆ° <code>train</code> æŸ¥çœ‹ç¤ºä¾‹</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">squad_it_dataset[<span class="hljs-string">"train"</span>][<span class="hljs-number">0</span>]<br></code></pre></td></tr></tbody></table></figure>

<figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">{</span><br>    <span class="hljs-attr">"title"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Terremoto del Sichuan del 2008"</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">"paragraphs"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">{</span><br>            <span class="hljs-attr">"context"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Il terremoto del Sichuan del 2008 o il terremoto..."</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">"qas"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                <span class="hljs-punctuation">{</span><br>                    <span class="hljs-attr">"answers"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">{</span><span class="hljs-attr">"answer_start"</span><span class="hljs-punctuation">:</span> <span class="hljs-number">29</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"text"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"2008"</span><span class="hljs-punctuation">}</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>                    <span class="hljs-attr">"id"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"56cdca7862d2951400fa6826"</span><span class="hljs-punctuation">,</span><br>                    <span class="hljs-attr">"question"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"In quale anno si Ã¨ verificato il terremoto nel Sichuan?"</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span><br>                ...<br>            <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span><br>        ...<br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">}</span><br></code></pre></td></tr></tbody></table></figure>
</li>
<li><p>æˆ‘ä»¬çœŸæ­£æƒ³è¦çš„æ˜¯åŒ…æ‹¬ <code>train</code> å’Œ <code>test</code> çš„ <code>DatasetDict</code> å¯¹è±¡ã€‚è¿™æ ·çš„è¯å°±å¯ä»¥ä½¿ç”¨ <code>Dataset.map()</code> å‡½æ•°åŒæ—¶å¤„ç†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚ ä¸ºæ­¤, æˆ‘ä»¬æä¾›å‚æ•°<code>data_files</code>çš„å­—å…¸,å°†æ¯ä¸ªåˆ†å‰²åç§°æ˜ å°„åˆ°ä¸è¯¥åˆ†å‰²ç›¸å…³è”çš„æ–‡ä»¶ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">data_files = {<span class="hljs-string">"train"</span>: <span class="hljs-string">"SQuAD_it-train.json"</span>, <span class="hljs-string">"test"</span>: <span class="hljs-string">"SQuAD_it-test.json"</span>}<br>squad_it_dataset = load_dataset(<span class="hljs-string">"json"</span>, data_files=data_files, field=<span class="hljs-string">"data"</span>)<br>squad_it_dataset<br></code></pre></td></tr></tbody></table></figure>

<figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs json">DatasetDict(<span class="hljs-punctuation">{</span><br>    train<span class="hljs-punctuation">:</span> Dataset(<span class="hljs-punctuation">{</span><br>        features<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>'title'<span class="hljs-punctuation">,</span> 'paragraphs'<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        num_rows<span class="hljs-punctuation">:</span> <span class="hljs-number">442</span><br>    <span class="hljs-punctuation">}</span>)<br>    test<span class="hljs-punctuation">:</span> Dataset(<span class="hljs-punctuation">{</span><br>        features<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>'title'<span class="hljs-punctuation">,</span> 'paragraphs'<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        num_rows<span class="hljs-punctuation">:</span> <span class="hljs-number">48</span><br>    <span class="hljs-punctuation">}</span>)<br><span class="hljs-punctuation">}</span>)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p><code>load_dataset()</code>å‡½æ•°çš„<code>data_files</code>å‚æ•°éå¸¸çµæ´»å¹¶ä¸”å¯ä»¥æ˜¯å•ä¸ªæ–‡ä»¶è·¯å¾„ã€æ–‡ä»¶è·¯å¾„åˆ—è¡¨æˆ–å°†åˆ†å‰²åçš„åç§°æ˜ å°„åˆ°æ–‡ä»¶è·¯å¾„çš„å­—å…¸ã€‚æ‚¨è¿˜å¯ä»¥æ ¹æ®Unix shellä½¿ç”¨çš„è§„åˆ™å¯¹ä¸æŒ‡å®šæ¨¡å¼åŒ¹é…çš„æ–‡ä»¶è¿›è¡Œå…¨å±€å®šä½ï¼ˆä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥é€šè¿‡è®¾ç½®â€™data_files=â€œ*.JSONâ€â€˜å°†ç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶ä½œä¸ºå•ä¸ªæ‹†åˆ†è¿›è¡Œå…¨å±€å®šä½ï¼‰ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…ğŸ¤—Datasets æ–‡æ¡£ã€‚</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Datasetså®é™…ä¸Šæ”¯æŒè¾“å…¥æ–‡ä»¶çš„è‡ªåŠ¨è§£å‹,æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è·³è¿‡ä½¿ç”¨<code>gzip</code>,ç›´æ¥è®¾ç½® <code>data_files</code>å‚æ•°ä¼ é€’å‹ç¼©æ–‡ä»¶:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data_files = {<span class="hljs-string">"train"</span>: <span class="hljs-string">"SQuAD_it-train.json.gz"</span>, <span class="hljs-string">"test"</span>: <span class="hljs-string">"SQuAD_it-test.json.gz"</span>}<br>squad_it_dataset = load_dataset(<span class="hljs-string">"json"</span>, data_files=data_files, field=<span class="hljs-string">"data"</span>)<br></code></pre></td></tr></tbody></table></figure>

<p>å¦‚æœæ‚¨ä¸æƒ³æ‰‹åŠ¨è§£å‹ç¼©è®¸å¤š GZIP æ–‡ä»¶ï¼Œè¿™ä¼šå¾ˆæœ‰ç”¨ã€‚è‡ªåŠ¨è§£å‹ä¹Ÿé€‚ç”¨äºå…¶ä»–å¸¸è§æ ¼å¼,å¦‚ ZIP å’Œ TAR,å› æ­¤æ‚¨åªéœ€å°† <code>data_files</code> è®¾ç½®ä¸ºå‹ç¼©æ–‡ä»¶æ‰€åœ¨çš„è·¯å¾„,ä½ å°±å¯ä»¥å¼€å§‹äº†!</p>
</li>
</ul>
<h3 id="Remote-dataset"><a href="#Remote-dataset" class="headerlink" title="Remote dataset"></a>Remote dataset</h3><p>æˆ‘ä»¬æ²¡æœ‰æä¾›æœ¬åœ°æ–‡ä»¶çš„è·¯å¾„, è€Œæ˜¯å°†<code>load_dataset()</code>çš„<code>data_files</code>å‚æ•°æŒ‡å‘å­˜å‚¨è¿œç¨‹æ–‡ä»¶çš„ä¸€ä¸ªæˆ–å¤šä¸ªURLã€‚ä¾‹å¦‚, å¯¹äºæ‰˜ç®¡åœ¨ GitHub ä¸Šçš„ SQuAD-it æ•°æ®é›†, æˆ‘ä»¬å¯ä»¥å°† <code>data_files</code> æŒ‡å‘ <em>SQuAD_it-*.json.gz</em> çš„ç½‘å€,å¦‚ä¸‹æ‰€ç¤º:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">url = <span class="hljs-string">"https://github.com/crux82/squad-it/raw/master/"</span><br>data_files = {<br>    <span class="hljs-string">"train"</span>: url + <span class="hljs-string">"SQuAD_it-train.json.gz"</span>,<br>    <span class="hljs-string">"test"</span>: url + <span class="hljs-string">"SQuAD_it-test.json.gz"</span>,<br>}<br>squad_it_dataset = load_dataset(<span class="hljs-string">"json"</span>, data_files=data_files, field=<span class="hljs-string">"data"</span>)<br></code></pre></td></tr></tbody></table></figure>

<p>è¿™å°†è¿”å›å’Œä¸Šé¢çš„æœ¬åœ°ä¾‹å­ç›¸åŒçš„ <code>DatasetDict</code> å¯¹è±¡, ä½†çœå»äº†æˆ‘ä»¬æ‰‹åŠ¨ä¸‹è½½å’Œè§£å‹ <em>SQuAD_it-*.json.gz</em> æ–‡ä»¶çš„æ­¥éª¤ã€‚</p>
<h2 id="Slice-and-dice"><a href="#Slice-and-dice" class="headerlink" title="Slice and dice"></a>Slice and dice</h2><h3 id="Slicing-and-dicing-our-data"><a href="#Slicing-and-dicing-our-data" class="headerlink" title="Slicing and dicing our data"></a>Slicing and dicing our data</h3><ul>
<li>Datasets æä¾›äº†å‡ ä¸ªå‡½æ•°æ¥æ“ä½œ <strong>Dataset</strong> å’Œ <strong>DatasetDict</strong> å¯¹è±¡ã€‚</li>
</ul>
<blockquote>
<p>è¿™ä¸€èŠ‚çš„æ•°æ®Demo: æˆ‘ä»¬å°†ä½¿ç”¨æ‰˜ç®¡åœ¨<a target="_blank" rel="noopener" href="https://archive.ics.uci.edu/ml/index.php">åŠ å·å¤§å­¦æ¬§æ–‡åˆ†æ ¡æœºå™¨å­¦ä¹ å­˜å‚¨åº“</a>çš„<a target="_blank" rel="noopener" href="https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+(Drugs.com)">è¯ç‰©å®¡æŸ¥æ•°æ®é›†</a>ï¼Œå…¶ä¸­åŒ…å«æ‚£è€…å¯¹å„ç§è¯ç‰©çš„è¯„è®ºï¼Œä»¥åŠæ­£åœ¨æ²»ç–—çš„ç—…æƒ…å’Œæ‚£è€…æ»¡æ„åº¦çš„ 10 æ˜Ÿè¯„çº§ã€‚</p>
</blockquote>
<ul>
<li>åŠ è½½æ•°æ®</li>
</ul>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"<br>!unzip drugsCom_raw.zip<br></code></pre></td></tr></tbody></table></figure>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>data_files = {<span class="hljs-string">"train"</span>: <span class="hljs-string">"drugsComTrain_raw.tsv"</span>, <span class="hljs-string">"test"</span>: <span class="hljs-string">"drugsComTest_raw.tsv"</span>}<br><span class="hljs-comment"># \t is the tab character in Python</span><br>drug_dataset = load_dataset(<span class="hljs-string">"csv"</span>, data_files=data_files, delimiter=<span class="hljs-string">"\t"</span>)<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>æŠ½å–ä¸€ä¸ªå°çš„éšæœºæ ·æœ¬ï¼Œä»¥å¿«é€Ÿäº†è§£æ‚¨æ­£åœ¨å¤„ç†çš„æ•°æ®ç±»å‹(shuffle + select)</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">drug_sample = drug_dataset[<span class="hljs-string">"train"</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))<br><span class="hljs-comment"># Peek at the first few examples</span><br>drug_sample[:<span class="hljs-number">3</span>]<br></code></pre></td></tr></tbody></table></figure>

<figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">{</span>'Unnamed<span class="hljs-punctuation">:</span> <span class="hljs-number">0</span>'<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">87571</span><span class="hljs-punctuation">,</span> <span class="hljs-number">178045</span><span class="hljs-punctuation">,</span> <span class="hljs-number">80482</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br> 'drugName'<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>'Naproxen'<span class="hljs-punctuation">,</span> 'Duloxetine'<span class="hljs-punctuation">,</span> 'Mobic'<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br> 'condition'<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>'Gout<span class="hljs-punctuation">,</span> Acute'<span class="hljs-punctuation">,</span> 'ibromyalgia'<span class="hljs-punctuation">,</span> 'Inflammatory Conditions'<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br> 'review'<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>'<span class="hljs-string">"like the previous person mention, I&amp;#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!"</span>'<span class="hljs-punctuation">,</span><br>  '<span class="hljs-string">"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\r\nas a pain reducer and an anti-depressant, however, the side effects outweighed \r\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\r\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\r\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\r\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects."</span>'<span class="hljs-punctuation">,</span><br>  '<span class="hljs-string">"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days."</span>'<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br> 'rating'<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">9.0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">3.0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">10.0</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br> 'date'<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>'September <span class="hljs-number">2</span><span class="hljs-punctuation">,</span> <span class="hljs-number">2015</span>'<span class="hljs-punctuation">,</span> 'November <span class="hljs-number">7</span><span class="hljs-punctuation">,</span> <span class="hljs-number">2011</span>'<span class="hljs-punctuation">,</span> 'June <span class="hljs-number">5</span><span class="hljs-punctuation">,</span> <span class="hljs-number">2013</span>'<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br> 'usefulCount'<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">36</span><span class="hljs-punctuation">,</span> <span class="hljs-number">13</span><span class="hljs-punctuation">,</span> <span class="hljs-number">128</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">}</span><br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<ul>
<li>Dataç‰¹ç‚¹ï¼š<ul>
<li><strong>Unnamed: 0</strong>è¿™åˆ—çœ‹èµ·æ¥å¾ˆåƒæ¯ä¸ªæ‚£è€…çš„åŒ¿å IDã€‚</li>
<li><strong>condition</strong> è¿™åˆ—åŒ…å«æœ‰æè¿°å¥åº·çŠ¶å†µçš„æ ‡ç­¾ã€‚</li>
<li>è¯„è®ºé•¿çŸ­ä¸ä¸€ï¼Œæ··åˆæœ‰ Python è¡Œåˆ†éš”ç¬¦ (<strong>\r\n</strong>) ä»¥åŠ HTML å­—ç¬¦ä»£ç ï¼Œå¦‚**â€™**ã€‚</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li>ä¸ºäº†éªŒè¯<strong>Unnamed: 0</strong> åˆ—å­˜å‚¨çš„æ˜¯æ‚£è€… IDçš„çŒœæƒ³ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ <strong>Dataset.unique()</strong> å‡½æ•°æ¥éªŒè¯åŒ¿åID çš„æ•°é‡æ˜¯å¦ä¸æ‹†åˆ†åæ¯éƒ¨åˆ†ä¸­çš„è¡Œæ•°åŒ¹é…ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> drug_dataset.keys():<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(drug_dataset[split]) == <span class="hljs-built_in">len</span>(drug_dataset[split].unique(<span class="hljs-string">"Unnamed: 0"</span>))<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ **DatasetDict.rename_column()**å‡½æ•°ä¸€æ¬¡æ€§é‡å‘½åDatasetDictä¸­å…±æœ‰çš„åˆ—ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">drug_dataset = drug_dataset.rename_column(<br>    original_column_name=<span class="hljs-string">"Unnamed: 0"</span>, new_column_name=<span class="hljs-string">"patient_id"</span><br>)<br>drug_dataset<br></code></pre></td></tr></tbody></table></figure>

<figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs json">DatasetDict(<span class="hljs-punctuation">{</span><br>    train<span class="hljs-punctuation">:</span> Dataset(<span class="hljs-punctuation">{</span><br>        features<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>'patient_id'<span class="hljs-punctuation">,</span> 'drugName'<span class="hljs-punctuation">,</span> 'condition'<span class="hljs-punctuation">,</span> 'review'<span class="hljs-punctuation">,</span> 'rating'<span class="hljs-punctuation">,</span> 'date'<span class="hljs-punctuation">,</span> 'usefulCount'<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        num_rows<span class="hljs-punctuation">:</span> <span class="hljs-number">161297</span><br>    <span class="hljs-punctuation">}</span>)<br>    test<span class="hljs-punctuation">:</span> Dataset(<span class="hljs-punctuation">{</span><br>        features<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>'patient_id'<span class="hljs-punctuation">,</span> 'drugName'<span class="hljs-punctuation">,</span> 'condition'<span class="hljs-punctuation">,</span> 'review'<span class="hljs-punctuation">,</span> 'rating'<span class="hljs-punctuation">,</span> 'date'<span class="hljs-punctuation">,</span> 'usefulCount'<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        num_rows<span class="hljs-punctuation">:</span> <span class="hljs-number">53766</span><br>    <span class="hljs-punctuation">}</span>)<br><span class="hljs-punctuation">}</span>)<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>ä½¿ç”¨ **Dataset.map()**æ ‡å‡†åŒ–æ‰€æœ‰ <strong>condition</strong> æ ‡ç­¾</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lowercase_condition</span>(<span class="hljs-params">example</span>):<br>    <span class="hljs-keyword">return</span> {<span class="hljs-string">"condition"</span>: example[<span class="hljs-string">"condition"</span>].lower()}<br>  <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_nones</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x[<span class="hljs-string">"condition"</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span><br>  <br>drug_dataset = drug_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">"condition"</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>)<br>drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(lowercase_condition)<br><span class="hljs-comment"># Check that lowercasing worked</span><br>drug_dataset[<span class="hljs-string">"train"</span>][<span class="hljs-string">"condition"</span>][:<span class="hljs-number">3</span>]<br></code></pre></td></tr></tbody></table></figure>



<h3 id="Creating-new-columns"><a href="#Creating-new-columns" class="headerlink" title="Creating new columns"></a>Creating new columns</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_review_length</span>(<span class="hljs-params">example</span>):<br>    <span class="hljs-keyword">return</span> {<span class="hljs-string">"review_length"</span>: <span class="hljs-built_in">len</span>(example[<span class="hljs-string">"review"</span>].split())}<br><br>drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(compute_review_length)<br><span class="hljs-comment"># Inspect the first training example</span><br>drug_dataset[<span class="hljs-string">"train"</span>][<span class="hljs-number">0</span>]<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>ç„¶åè¿›è¡Œæ’åº</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">drug_dataset[<span class="hljs-string">"train"</span>].sort(<span class="hljs-string">"review_length"</span>)[:<span class="hljs-number">3</span>]<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>å‘æ•°æ®é›†æ·»åŠ æ–°åˆ—çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨å‡½æ•°Dataset.add_column() ã€‚è¿™å…è®¸æ‚¨è¾“å…¥Python åˆ—è¡¨æˆ– NumPyï¼Œåœ¨ä¸é€‚åˆä½¿ç”¨Dataset.map()æƒ…å†µä¸‹å¯ä»¥å¾ˆæ–¹ä¾¿ã€‚</p>
</blockquote>
<ul>
<li>ä¸€äº›è¯„è®ºåªåŒ…å«ä¸€ä¸ªè¯ï¼Œè™½ç„¶è¿™å¯¹äºæƒ…æ„Ÿåˆ†ææ¥è¯´å¯èƒ½æ²¡é—®é¢˜ï¼Œä½†å¦‚æœæˆ‘ä»¬æƒ³è¦é¢„æµ‹ç—…æƒ…ï¼Œè¿™äº›è¯„è®ºå¯èƒ½å¹¶ä¸é€‚åˆã€‚æˆ‘ä»¬ä½¿ç”¨ <strong>Dataset.filter()</strong> åŠŸèƒ½æ¥åˆ é™¤åŒ…å«å°‘äº 30 ä¸ªå•è¯çš„è¯„è®ºã€‚ä¸æˆ‘ä»¬å¯¹ <strong>condition</strong> åˆ—çš„å¤„ç†ç›¸ä¼¼ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é€‰å–è¯„è®ºçš„é•¿åº¦é«˜äºæ­¤é˜ˆå€¼æ¥è¿‡æ»¤æ‰éå¸¸çŸ­çš„è¯„è®ºï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">drug_dataset = drug_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">"review_length"</span>] &gt; <span class="hljs-number">30</span>)<br><span class="hljs-built_in">print</span>(drug_dataset.num_rows)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>è¿™å·²ç»ä»æˆ‘ä»¬çš„åŸå§‹è®­ç»ƒå’Œæµ‹è¯•é›†ä¸­åˆ é™¤äº†å¤§çº¦ 15% çš„è¯„è®ºã€‚</p>
</blockquote>
<ul>
<li>è¯„è®ºä¸­å­˜åœ¨ HTML å­—ç¬¦ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Python çš„<strong>html</strong>æ¨¡å—å–æ¶ˆè¿™äº›å­—ç¬¦çš„è½¬ä¹‰</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> html<br><br>text = <span class="hljs-string">"I&amp;#039;m a transformer called BERT"</span><br>html.unescape(text)<br><br>drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">"review"</span>: html.unescape(x[<span class="hljs-string">"review"</span>])})<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p> <strong>Dataset.map()</strong> æ–¹æ³•å¯¹äºå¤„ç†æ•°æ®éå¸¸æœ‰ç”¨</p>
</blockquote>
<h3 id="Map-methodâ€™s-superpowers"><a href="#Map-methodâ€™s-superpowers" class="headerlink" title="Map() methodâ€™s superpowers"></a>Map() methodâ€™s superpowers</h3><ul>
<li>Dataset.map() æ–¹æ³•æœ‰ä¸€ä¸ª batched å‚æ•°ï¼Œå¦‚æœè®¾ç½®ä¸º True , map å‡½æ•°å°†ä¼šåˆ†æ‰¹æ‰§è¡Œæ‰€éœ€è¦è¿›è¡Œçš„æ“ä½œï¼ˆæ‰¹é‡å¤§å°æ˜¯å¯é…ç½®çš„ï¼Œä½†é»˜è®¤ä¸º 1,000ï¼‰ã€‚ å½“æ‚¨åœ¨ä½¿ç”¨ Dataset.map()å‡½æ•°æ—¶æŒ‡å®š batched=Trueã€‚è¯¥å‡½æ•°ä¼šæ¥æ”¶ä¸€ä¸ªåŒ…å«æ•°æ®é›†å­—æ®µçš„å­—å…¸ï¼Œæ¯ä¸ªå€¼éƒ½æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œè€Œä¸ä»…ä»…æ˜¯å•ä¸ªå€¼ã€‚Dataset.map() çš„è¿”å›å€¼åº”è¯¥æ˜¯ç›¸åŒçš„ï¼šä¸€ä¸ªåŒ…å«æˆ‘ä»¬æƒ³è¦æ›´æ–°æˆ–æ·»åŠ åˆ°æ•°æ®é›†ä¸­çš„å­—æ®µçš„å­—å…¸ï¼Œå­—å…¸çš„é”®æ˜¯è¦æ·»åŠ çš„å­—æ®µï¼Œå­—å…¸çš„å€¼æ˜¯ç»“æœçš„åˆ—è¡¨ã€‚</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">new_drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(<br>    <span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">"review"</span>: [html.unescape(o) <span class="hljs-keyword">for</span> o <span class="hljs-keyword">in</span> x[<span class="hljs-string">"review"</span>]]}, batched=<span class="hljs-literal">True</span><br>)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>åˆ—è¡¨æ¨å¯¼å¼é€šå¸¸æ¯”åœ¨åŒä¸€ä»£ç ä¸­ç”¨ <strong>for</strong> å¾ªç¯æ‰§è¡Œç›¸åŒçš„ä»£ç æ›´å¿«ï¼Œå¹¶ä¸”æˆ‘ä»¬è¿˜é€šè¿‡åŒæ—¶è®¿é—®å¤šä¸ªå…ƒç´ è€Œä¸æ˜¯ä¸€ä¸ªä¸€ä¸ªæ¥å¤„ç†æ¥æé«˜å¤„ç†çš„é€Ÿåº¦ã€‚ä½¿ç”¨ <strong>Dataset.map()</strong> å’Œ <strong>batched=True</strong> æ˜¯åŠ é€Ÿçš„å…³é”®ã€‚</p>
</blockquote>
<ul>
<li>â€œå¿«é€Ÿâ€æ ‡è®°å™¨</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"bert-base-cased"</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">"review"</span>], truncation=<span class="hljs-literal">True</span>)<br><br>tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li><strong>Dataset.map()</strong> ä¹Ÿæœ‰ä¸€äº›è‡ªå·±çš„å¹¶è¡ŒåŒ–èƒ½åŠ›ã€‚ç”±äºå®ƒä»¬ä¸å— Rust çš„æ”¯æŒï¼Œå› æ­¤æ…¢é€Ÿåˆ†è¯å™¨çš„é€Ÿåº¦èµ¶ä¸ä¸Šå¿«é€Ÿåˆ†è¯å™¨ï¼Œä½†å®ƒä»¬ä»ç„¶ä¼šæ›´å¿«ä¸€äº›ï¼ˆå°¤å…¶æ˜¯å½“æ‚¨ä½¿ç”¨æ²¡æœ‰å¿«é€Ÿç‰ˆæœ¬çš„åˆ†è¯å™¨æ—¶ï¼‰ã€‚è¦å¯ç”¨å¤šå¤„ç†ï¼Œè¯·åœ¨**Dataset.map()**æ—¶ä½¿ç”¨ <strong>num_proc</strong> å‚æ•°å¹¶æŒ‡å®šè¦åœ¨è°ƒç”¨ä¸­ä½¿ç”¨çš„è¿›ç¨‹æ•° ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">slow_tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"bert-base-cased"</span>, use_fast=<span class="hljs-literal">False</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">slow_tokenize_function</span>(<span class="hljs-params">examples</span>):<br>    <span class="hljs-keyword">return</span> slow_tokenizer(examples[<span class="hljs-string">"review"</span>], truncation=<span class="hljs-literal">True</span>)<br><br>tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(slow_tokenize_function, batched=<span class="hljs-literal">True</span>, num_proc=<span class="hljs-number">8</span>)<br></code></pre></td></tr></tbody></table></figure>



<h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1><ul>
<li>å…¶ä»–å†…å®¹å…¶å®å·²ç»ä¸æ˜¯é‡ç‚¹äº†ï¼ˆåŒ…æ‹¬ä¸Šé¢çš„Datasetsï¼Œæœ€ä¸»è¦çš„éƒ¨åˆ†ï¼Œæ˜¯å‰é¢å‡ èŠ‚ï¼Œç”±ä¸åŒçš„å±‚æ‹¼å‡ºæ¥å…·ä½“çš„å¤„ç†é€»è¾‘å’Œpipelineï¼‰ã€‚</li>
</ul>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/zh-CN/chapter1/1">HuggingFace NLP Course Reference</a></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/AI/" class="category-chain-item">AI</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E8%87%AA%E5%AD%A6/">#è‡ªå­¦</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>HuggingFace-NLP-Course</div>
      <div>https://alexanderliu-creator.github.io/2024/08/03/huggingface-nlp-course/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>ä½œè€…</div>
          <div>Alexander Liu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>å‘å¸ƒäº</div>
          <div>2024å¹´8æœˆ3æ—¥</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>è®¸å¯åè®®</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - ç½²å">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/08/16/recommendation-system/" title="Recommendation System">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Recommendation System</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/02/21/suan-fa-gang-mian-shi-hui-zong-1/" title="ç®—æ³•å²—é¢è¯•æ±‡æ€»-1">
                        <span class="hidden-mobile">ç®—æ³•å²—é¢è¯•æ±‡æ€»-1</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;ç›®å½•</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.events.registerRefreshCallback(function() {
      if ('mermaid' in window) {
        mermaid.init();
      }
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        æ€»è®¿é—®é‡ 
        <span id="busuanzi_value_site_pv"></span>
         æ¬¡
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        æ€»è®¿å®¢æ•° 
        <span id="busuanzi_value_site_uv"></span>
         äºº
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">åšå®¢åœ¨å…è®¸ JavaScript è¿è¡Œçš„ç¯å¢ƒä¸‹æµè§ˆæ•ˆæœæ›´ä½³</div>
  </noscript>
</body>
</html>
