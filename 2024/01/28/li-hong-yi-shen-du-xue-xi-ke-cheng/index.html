

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/tuzi.png">
  <link rel="icon" href="/img/tuzi.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Alexander Liu">
  <meta name="keywords" content="分布式系统,后端研发,数据协同">
  
    <meta name="description" content="李沐老师的课程看完了！再来看看李宏毅老师的课程！温故而知新！多学习！">
<meta property="og:type" content="article">
<meta property="og:title" content="李宏毅深度学习课程">
<meta property="og:url" content="https://alexanderliu-creator.github.io/2024/01/28/li-hong-yi-shen-du-xue-xi-ke-cheng/index.html">
<meta property="og:site_name" content="兔の博客">
<meta property="og:description" content="李沐老师的课程看完了！再来看看李宏毅老师的课程！温故而知新！多学习！">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202401281948983.jpg">
<meta property="article:published_time" content="2024-01-28T11:45:14.000Z">
<meta property="article:modified_time" content="2024-02-11T12:47:48.765Z">
<meta property="article:author" content="Alexander Liu">
<meta property="article:tag" content="研0自学">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202401281948983.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>李宏毅深度学习课程 - 兔の博客</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"alexanderliu-creator.github.io","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":1},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="兔の博客" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>兔的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/background_post.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="李宏毅深度学习课程"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Alexander Liu
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-01-28 19:45" pubdate>
          2024年1月28日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          7.7k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          64 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">李宏毅深度学习课程</h1>
            
              <p class="note note-info">
                
                  
                    本文最后更新于：12 小时前
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <p>李沐老师的课程看完了！再来看看李宏毅老师的课程！温故而知新！多学习！</p>
<span id="more"></span>

<h1 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h1><ul>
<li><p>Machine Learning 约等于 Looking for Function</p>
</li>
<li><p>cases: Audio2txt, img2txt, ….</p>
</li>
<li><p>Different types of IO</p>
<ul>
<li>Input: vector, matrix, sequence(speech, text)</li>
<li>Output: scalar(regression), choice(classification), text</li>
</ul>
</li>
<li><p>有很多种方法去教机器学！</p>
<ul>
<li>Classification -&gt; Supervised Learning（监督学习）</li>
<li>但是监督学习需要的人工太多了，Self-supervised Learning（自监督学习）, unlabeled images —Pre-train—&gt; Develop general propose knowledge, Fine-tune可以在下游任务上表现出好的结果！！！Pre-trained Model又被称为Foundation Model.</li>
<li>Generative Adversarial Network(GAN) -&gt; 不需要手动标注太多！只需要找到x集合和y集合，不用标注(unpaired)，机器就能够自动学习。</li>
<li>还有Unsupervised，无监督。也是类似的，不用找材料的对应关系，只要有足量的x和y，机器就能够学的很好。</li>
<li>Reinforcement Learning(RL)，你不知道具体是怎么样的，但是你知道“是好是坏”，这就是RL，你能够给予一些反馈给机器，而不是具体的x -&gt; y的关系。</li>
</ul>
</li>
<li><p>ML不只是追求正确率，还关注：</p>
<ul>
<li>Anomaly Detection: 机器在分类问题上，回答“我不知道”的能力。</li>
<li>Explainable AI: 可解释性</li>
<li>Model Attack: 模型攻击</li>
<li>Domain Adaptation: 测试资料和训练资料分布很不一样，模型准确率暴跌</li>
<li>Network Compression: 模型太大，压缩一把</li>
<li>Life-long Learning: all-in-one ML，学习所有的东西！</li>
<li>Meta Learning: Learn to Learn, Few-shot learning 和 meta-learning强相关. 机器自己会写算法？？？教会机器如何去学习，就可以做到few shots，很多人甚至会画上等号，few-shot就要用到meta-learning的技术。</li>
</ul>
</li>
</ul>
<h1 id="Introduction-of-Machine-x2F-Deep-Learning"><a href="#Introduction-of-Machine-x2F-Deep-Learning" class="headerlink" title="Introduction of Machine/Deep Learning"></a>Introduction of Machine/Deep Learning</h1><h2 id="ML"><a href="#ML" class="headerlink" title="ML"></a>ML</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul>
<li><p>ML: Find a function</p>
</li>
<li><p>Different types of functions</p>
<ul>
<li>Regression: The function outputs a scalar</li>
<li>Classification: Give options(classes), the function outputs the correct one.</li>
<li>Structure Learning -&gt; create something with structure(image, document)</li>
</ul>
<p>……</p>
</li>
<li><p>How to find the function?</p>
<ol>
<li>Function with Unknown Parameters, e.g. $y = wx + b$</li>
<li>Define <strong>Loss</strong> From Training Data. (Loss is a function of parameters).<ul>
<li>Loss is a function of parameters, $L(b, w)$</li>
<li>Loss: how good a set of values is.</li>
<li>MAE, MSE, Cross-Entropy, …</li>
</ul>
</li>
<li>Optimization -&gt; decrease loss<ul>
<li>Gradient Descent, …</li>
<li>hyperparameters: learning rate, …</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="Sigmoid-amp-Epoch"><a href="#Sigmoid-amp-Epoch" class="headerlink" title="Sigmoid &amp; Epoch"></a>Sigmoid &amp; Epoch</h3><ul>
<li><p>Linear Models are too simple… we need more sophisticated modes. Linear models have server limitation. <strong>Model Bias.</strong> We need a more flexible model!</p>
<ul>
<li>Approximate continuous curve by a piecewise linear curve</li>
<li>Sigmoid Function</li>
<li>New Model: More Features, consisting of sigmoid functions to approximate real function.</li>
</ul>
</li>
<li><p>Some hyperparameters</p>
<ul>
<li>Batch: All the training data are too much, we don’t use all the data to do gradient descent, that costs too much. We divide data into batches, and use each “Batch” to do the gradient descent. 1 Update = update parameters once = 1 batch training.</li>
<li>1 Epoch = see all the batches once.</li>
<li>e.g. Q: 10,000 examples(N = 10,000), Batch size is 10(B = 10), how many updates in 1 epoch? -&gt; A: 1000 updates</li>
</ul>
</li>
<li><p>Why Sigmoid? ReLU -&gt; ReLU(Rectified Linear Unit) is “hard sigmoid”, and others. They’re called activated functions.</p>
</li>
<li><p>Neuron -&gt; Neural Network, 可以一层有多个Neuron，也可以多层嵌套，组成复杂的神经网络结构，拟合复杂的函数和情况。</p>
</li>
<li><p>一些思考：Why we want “Deep” instead of “Fat” network? Fat也可以拟合很复杂的Functions啊！</p>
</li>
<li><p>Better on training data, worse on unseen data -&gt; <strong>Overfitting</strong></p>
</li>
</ul>
<h3 id="DL-Concept"><a href="#DL-Concept" class="headerlink" title="DL Concept"></a>DL Concept</h3><ul>
<li>Deep = Many Hidden Layers</li>
<li>Just a new name, deep neural network too.</li>
</ul>
<h2 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1J94y1f7u5?p=4&amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd">Pytorch lession 1</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1J94y1f7u5/?p=5&amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd">Pytorch lession 2</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1J94y1f7u5/?p=6&amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd">Pytorch lession 3 - Pytorch Tutorial Colab</a></li>
</ul>
<h2 id="DL"><a href="#DL" class="headerlink" title="DL"></a>DL</h2><ul>
<li>Ups and downs of Deep Learning<ul>
<li>1958: Perceptron(linear model)</li>
<li>1969: Perceptron has limitation</li>
<li>1980s: Multi-layer perceptron -&gt; Do not have significant difference from DNN today</li>
<li>1986: Backpropagation</li>
<li>1989: 1 hidder layer is “good enough”, why deep?</li>
<li>2006: RBM(Restricted Boltzmann Machine) initialization(breakthrough)</li>
<li>2009: GPU</li>
<li>2011: Better and better</li>
</ul>
</li>
<li>Three Steps for deep learning: <ol>
<li>Neural Network -&gt; Given network structure, we define a function set. Define a good network structure is really important. Use Gradient Descent to find a good function.</li>
<li>Goodness of function -&gt; Loss function</li>
<li>Pick the best function -&gt; Minimize total loss(Gradient Descent)</li>
</ol>
</li>
<li>Deep = Many hidden layers, How many layers? How many neurons for each layer? <strong>Trial and Error + Intuition</strong>.</li>
<li>DL的出现转换了问题，如何抽取features -&gt; 如何定义一个好的neural network.</li>
<li>越多的参数，可以覆盖的function set越大，找到越好的function的可能性也就越大，效果越好也就是在预料之中啊。Why deeper is better, why not fat?</li>
</ul>
<h2 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1J94y1f7u5/?p=8&amp;spm_id_from=pageDriver&amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd">Backpropagation vedio</a></p>
<ul>
<li>Chain Rule is core of back propagation</li>
<li>建议全部看看哈，这里的计算讲的非常清楚昂！！！<ul>
<li>Backpropagation需要Forward pass和Backward pass两步，综合起来才能够完成。<ul>
<li>Forward pass: 从前往后，每一个的神经元的输入，就是当前神经元对于上一个神经元的Forward pass</li>
<li>Backward pass: 从后往前，和上面类似，反推。</li>
</ul>
</li>
<li>这么看来，就是前往后，后往前，计算量其实是一样的。通过前往后 + 后往前，就能够算的出来某一层的偏微分，就能够更新了哈！</li>
</ul>
</li>
</ul>
<h1 id="Regression-Prediction-Problem"><a href="#Regression-Prediction-Problem" class="headerlink" title="Regression Prediction Problem"></a>Regression Prediction Problem</h1><h2 id="Pokemon-Regression-Task"><a href="#Pokemon-Regression-Task" class="headerlink" title="Pokemon Regression Task"></a>Pokemon Regression Task</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1J94y1f7u5?p=9&amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd">Pokemon Demo</a></p>
<ul>
<li><p>Loss function: Input is a function, output is a value telling how bad the function is. $L(f) = L(w,b)$</p>
</li>
<li><p>More complex model doen’t always lead to better performance on testing data -&gt; <strong>Overfitting</strong> -&gt; <strong>Select suitable model</strong></p>
</li>
<li><p>缓解overfitting的技巧</p>
<ul>
<li>删掉一些没用的features，防止过拟合。</li>
<li>损失函数加上一个正则项，Regularization</li>
</ul>
</li>
<li><p>Regularization，正则项的系数$\lambda$是我们手动调整的。让$w$尽可能的小，越小越平滑！模型越平滑，对于输入越不敏感，输入的噪声也对于函数的影响小，模型拟合效果就越好！We prefer smooth function, but don’t be too smooth. 做正则化的过程中，也不需要考虑$b$，因为它对于模型的平滑程度是没有影响的。</p>
</li>
</ul>
<h1 id="Classification-Probabilistic-Generative-Model"><a href="#Classification-Probabilistic-Generative-Model" class="headerlink" title="Classification: Probabilistic Generative Model"></a>Classification: Probabilistic Generative Model</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1J94y1f7u5?p=10&amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd">Plz see the lession vedio</a>，涉及到了好多概率论相关的知识，贝叶斯，高斯分布，极大似然估计等，很有意思！但是要有概率论的部分基础哈，还要有线性代数和微积分的昂！x -&gt; Function -&gt; Class n</p>
</blockquote>
<ul>
<li><p>贝叶斯本质上就是一个Generative Model哇！</p>
</li>
<li><p>Linear Regression可以用在Classification的问题上吗？可以，但是不好！ -&gt; Penalize to the examples that are “too correct”，会惩罚那些离分界线远的点，但是那些点正确性强！导致预测的分解会有偏移昂！</p>
</li>
<li><p>Linear Regression不太适用于分类问题哈</p>
</li>
</ul>
<h1 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h1><blockquote>
<p>Probabilistic Generative Model -&gt; Logistic Regression</p>
</blockquote>
<ul>
<li><p>MSE没有交叉熵好的理由：使用MSE算出来的梯度，离目标很近，微分是0，离目标很远，微分也是0，几乎学不动orz。很难找到结果，但是Cross-Entropy，距离目标越远，剃度越大，就很容易能够找到很好的结果昂！</p>
</li>
<li><p>Dicriminative vs Generative</p>
<ul>
<li>Logistic Regression: Dicriminative</li>
<li>Gauss Probability: Generative(当二分类两个变量共享covariance matrix时候，这两者是一致的)</li>
</ul>
<blockquote>
<ul>
<li><p>本质表达的是同一个model，同样的function set，去寻找$w$和$b$。因为假设不一样，所以找出来的结果也会不一样，但是都make sense。The same model(function set), but different function is selected by the same training data. Discriminative的效果，看起来比Generative Model要好一些昂！！！</p>
</li>
<li><p>数据少的时候，Generative Model的效果可能就会更好（脑补），它做的一些假设（例如Naive Bayes），就适用于数据量少的情况（或者数据里有噪音的时候）。但是Logistic是看数据说话，数据少的时候，就不太好，数据量大的时候，Logistic就work。</p>
</li>
</ul>
</blockquote>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/139122386">Logistic Regression</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/72513104">Linear Regression</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/20852004">「协方差」与「相关系数」</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/39840928/answer/2222150696">AUC</a></p>
</li>
</ul>
<h1 id="Multi-class-Classification"><a href="#Multi-class-Classification" class="headerlink" title="Multi-class Classification"></a>Multi-class Classification</h1><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/105722023">Softmax函数与交叉熵</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41888257/article/details/109157970">Softmax是线性模型</a></li>
<li>Limitation of Logistic Regression: <ul>
<li>Logistic Regression本质上是一个线性分类器，两个class之间的boundary就是一条直线，对于一些特殊的分类情况做不到哈。</li>
<li>如果你非要想用怎么办？Feature Transformation，按照处理后的feature，把不同的类尽量放在空间中不同的部分，使其使用Logistic Regression可以很好的“线性分类”。Not always easy to find a good transformation to use logistic regression.</li>
</ul>
</li>
<li>怎么办？把很多Logistic Regression Cascade起来，然后自己去学！找一个好的Transformation！</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202402091041515.png" srcset="/img/loading.gif" lazyload alt="image-20240209104124234"></p>
<blockquote>
<p>叠加逻辑回归层，使得x特征不断进行Transformation，使其明显易分类</p>
</blockquote>
<h1 id="Machine-Learning-Strategy-General-Guide"><a href="#Machine-Learning-Strategy-General-Guide" class="headerlink" title="Machine Learning Strategy - General Guide"></a>Machine Learning Strategy - General Guide</h1><ul>
<li><p>Framework of ML: Input -&gt; Function -&gt; Output</p>
<ol>
<li>Function with unknown</li>
<li>Define loss from training data</li>
<li>Optimization</li>
</ol>
</li>
<li><p>loss on training data</p>
<ul>
<li>large（训练资料没有学好）<ul>
<li>model bias -&gt; 模型太简单，function set里面就没有包含好的function，那没办法找到好的function哇。Redesign your model to make it more flexible.</li>
<li>optimization -&gt; Gradient Descent有许多问题，例如被限制在local minima，没办法在一个包含较好结果的function set上，找到一个好的function。</li>
<li>怎么判断是哪种呢？可以通过比较不同模型，来比较function set够不够大捏！**Gaining the insights from comparison.**（例如56-layer和20-layer的模型对比效果）<ul>
<li>Start from shallower networks(or other models), which are easier to optimize.  If deeper networks do not obtain smaller loss on training data,then there is optimization issue.</li>
<li>Solution:More powerful optimization technology (next lecture)</li>
</ul>
</li>
</ul>
</li>
<li>small<ul>
<li>loss on testing data<ul>
<li>small -&gt; done</li>
<li>large<ul>
<li>overfitting -&gt; more training data/data augmentation/make your model simpler</li>
<li>mismatch: 和overfitting不一样，测试资料和训练资料不一样昂！</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Overfitting: Small loss on training data,large loss on testing<br>data. Why? -&gt; “Freestyle”</p>
<ul>
<li>More training data</li>
<li>Data Augmentation(agument要有道理，你拿一只猫猫照片反过来喂给model是不是就有点抽象？？？)</li>
<li>Less “Freestyle” -&gt; 更简单的模型或者是更多的限制，function set就有限啦！<ul>
<li>Less parameters, sharing parameters</li>
<li>Less features</li>
<li>Early stopping</li>
<li>Regularization</li>
<li>Dropout</li>
</ul>
</li>
<li>如果模型限制太多，例如一个二次模型，给了一个一次函数，死活都拟合不好哇。Back to model bias……</li>
</ul>
</li>
<li><p>Bias-Complexity Trade-off -&gt; 你应该如何找一个比较合适的model呢？</p>
<ul>
<li>去Kaggle上，对着public testing set刷分数，看看哪个模型好。但是这个是不make sense的，低效，并且有次数限制，而且！也不一定是准确的，public上好，private也不一定好哇。</li>
<li>Training Set -&gt; Training Set(90%) + Validation Set(10%)，根据你自己本地的Validation Set的结果，去挑选好的模型，然后再上传到Kaggle上康康捏！</li>
<li>Using the results of public testing data to select your model. You are making public set better than private set. 所以从这个角度来看，我们完全在看Trainging Data，而不是Testing data的结果（不管是Public还是Private）。这样能够消除，我们“偏袒于” public tesing training set.</li>
</ul>
</li>
<li><p>这里的结构其实是：</p>
<ul>
<li>Trainging Data<ul>
<li>Training set</li>
<li>Validation set</li>
</ul>
</li>
<li>Testing Data<ul>
<li>Public testing set</li>
<li>Private testing set</li>
</ul>
</li>
</ul>
</li>
<li><p>如果我的Validation Set选的不好怎么办呢？ -&gt; N-fold Cross Validation. </p>
<ul>
<li>把Training Data切分为n份，把一份儿当作Validation Set，其他当作Training Set。</li>
<li>这种操作，重复n次。每次把第n份当作Validation set，其他都当作Training set.</li>
<li>把所有的模型，对于n组不同的Training Set和Validation Set，<strong>分别</strong>跑n次，然后算个Avg或者别的指标也好，看看哪个model的效果最好。然后再交上去，用到testing set上！</li>
</ul>
</li>
<li><p>Mismatch: Your training and testing data have different distributions.</p>
</li>
</ul>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1J94y1f7u5/?vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd">【2022】最新 李宏毅大佬的深度学习与机器学习</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/ninehills/blog/issues/97">NLP学习路线</a></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/AI/" class="category-chain-item">AI</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/">#研0自学</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>李宏毅深度学习课程</div>
      <div>https://alexanderliu-creator.github.io/2024/01/28/li-hong-yi-shen-du-xue-xi-ke-cheng/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Alexander Liu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年1月28日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/01/25/stable-diffusion-and-comfyui-tutorial/" title="Stable Diffusion and ComfyUI Tutorial">
                        <span class="hidden-mobile">Stable Diffusion and ComfyUI Tutorial</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.events.registerRefreshCallback(function() {
      if ('mermaid' in window) {
        mermaid.init();
      }
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
