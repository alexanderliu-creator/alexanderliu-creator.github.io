

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/tuzi.png">
  <link rel="icon" href="/img/tuzi.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Alexander Liu">
  <meta name="keywords" content="分布式系统,后端研发,数据协同">
  
    <meta name="description" content="针对于有顺序的数据类型，我们需要设计特定模型。我们不仅仅可以接收一个序列作为输入，而是还可能期望继续猜测这个序列的后续。如果说卷积神经网络可以有效地处理空间信息， 那么本章的循环神经网络（recurrent neural network，RNN）则可以更好地处理序列信息。 循环神经网络通过引入状态变量存储过去的信息和当前的输入，从而可以确定当前的输出。 循环神经网络 (RNN) 是深度学习模型，通">
<meta property="og:type" content="article">
<meta property="og:title" content="D2L-9-Recurrent Neural Networks">
<meta property="og:url" content="http://example.com/2023/08/07/d2l-9-recurrent-neural-networks/index.html">
<meta property="og:site_name" content="兔の博客">
<meta property="og:description" content="针对于有顺序的数据类型，我们需要设计特定模型。我们不仅仅可以接收一个序列作为输入，而是还可能期望继续猜测这个序列的后续。如果说卷积神经网络可以有效地处理空间信息， 那么本章的循环神经网络（recurrent neural network，RNN）则可以更好地处理序列信息。 循环神经网络通过引入状态变量存储过去的信息和当前的输入，从而可以确定当前的输出。 循环神经网络 (RNN) 是深度学习模型，通">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202307231956594.jpg">
<meta property="article:published_time" content="2023-08-07T11:47:21.000Z">
<meta property="article:modified_time" content="2023-08-07T14:13:53.774Z">
<meta property="article:author" content="Alexander Liu">
<meta property="article:tag" content="研0自学">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202307231956594.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>D2L-9-Recurrent Neural Networks - 兔の博客</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":1},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="兔の博客" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>兔的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/background_post.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="D2L-9-Recurrent Neural Networks"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Alexander Liu
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-08-07 19:47" pubdate>
          2023年8月7日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          14k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          113 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">D2L-9-Recurrent Neural Networks</h1>
            
              <p class="note note-info">
                
                  
                    本文最后更新于：4 天前
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <p>针对于有顺序的数据类型，我们需要设计特定模型。我们不仅仅可以接收一个序列作为输入，而是还可能期望继续猜测这个序列的后续。如果说卷积神经网络可以有效地处理空间信息， 那么本章的<em>循环神经网络</em>（recurrent neural network，RNN）则可以更好地处理序列信息。 循环神经网络通过引入状态变量存储过去的信息和当前的输入，从而可以确定当前的输出。</p>
<p><em>循环神经网络 (RNN) 是深度学习模型，通过循环</em>连接捕获序列的动态，循环连接可以被视为节点网络中的循环。乍一看这似乎违反直觉。毕竟，正是神经网络的前馈性质使得计算顺序变得明确。然而，循环边缘以精确的方式定义，以确保不会出现此类歧义。循环神经网络 跨时间步长（或序列步长）<em>展开</em>，每个步骤应用<em>相同的基础参数。**标准连接同步</em>应用以<em>在同一时间步长</em>将每一层的激活传播到后续层，循环连接是 <em>动态的</em>，跨相邻时间步传递信息。</p>
<span id="more"></span>





<p><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202308071957945.svg" srcset="/img/loading.gif" lazyload alt="../_images/unfolded-rnn.svg"></p>
<h1 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h1><ul>
<li>数据呈现时间性，季节性等，会随着时间而改变！</li>
<li>预测明天的股价要比过去的股价更困难，尽管两者都只是估计一个数字。 毕竟，先见之明比事后诸葛亮难得多。 在统计学中，前者（对超出已知观测范围进行预测）称为<em>外推法</em>（extrapolation）， 而后者（在现有观测值之间进行估计）称为<em>内插法</em>（interpolation）。前者比后者困难的多得多！！！</li>
</ul>
<h2 id="统计工具"><a href="#统计工具" class="headerlink" title="统计工具"></a>统计工具</h2><p><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202308072001662.png" srcset="/img/loading.gif" lazyload alt="../_images/ftse100.png"></p>
<ul>
<li>用$x_t$表示价格，即在<em>时间步</em>（time step）$t \in \mathbb{Z}^+$时，观察到的价格$x_t$。 请注意，$t$对于本文中的序列通常是离散的，并在整数或其子集上变化。 假设一个交易员想在$t$日的股市中表现良好，于是通过以下途径预测$x_t$：</li>
</ul>
<p>$$<br>x_t \sim P(x_t \mid x_{t-1}, \ldots, x_1).<br>$$</p>
<h3 id="自回归模型"><a href="#自回归模型" class="headerlink" title="自回归模型"></a>自回归模型</h3><ul>
<li><p>输入数据的数量， 输入$x_{t-1}, \ldots, x_1$本身因$t$而异。 也就是说，输入数据的数量这个数字将会随着我们遇到的数据量的增加而增加， 因此需要一个近似方法来使这个计算变得容易处理。 本章后面的大部分内容将围绕着如何有效估计$P(x_t \mid x_{t-1}, \ldots, x_1)$展开。 简单地说，它归结为以下两种策略。</p>
<ul>
<li><p>第一种策略，假设在现实情况下相当长的序列$x_{t-1}, \ldots, x_1$可能是不必要的， 因此我们只需要满足某个长度为$\tau$的时间跨度， 即使用观测序列$x_{t-1}, \ldots, x_{t-\tau}$。 当下获得的最直接的好处就是参数的数量总是不变的， 至少在$t &gt; \tau$时如此，这就使我们能够训练一个上面提及的深度网络。 这种模型被称为<em>自回归模型</em>（autoregressive models）， 因为它们是对自己执行回归。</p>
</li>
<li><p>第二种策略，保留一些对过去观测的总结$h_t$， 并且同时更新预测$\hat{x}<em>t$和总结$h_t$。 这就产生了基于$\hat{x}<em>t = P(x_t \mid h</em>{t})$估计$x_t$， 以及公式$h_t = g(h</em>{t-1}, x_{t-1})$更新的模型。 由于$h_t$从未被观测到，这类模型也被称为 <em>隐变量自回归模型</em>（latent autoregressive models）。</p>
<p><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202308072011626.svg" srcset="/img/loading.gif" lazyload alt="../_images/sequence-model.svg"></p>
</li>
</ul>
</li>
<li><p>如何生成训练数据？ 一个经典方法是使用历史观测来预测下一个未来观测。 显然，我们并不指望时间会停滞不前。 然而，一个常见的假设是虽然特定值$x_t$可能会改变， 但是序列本身的动力学不会改变。 这样的假设是合理的，因为新的动力学一定受新的数据影响， 而我们不可能用目前所掌握的数据来预测新的动力学。 统计学家称不变的动力学为<em>静止的</em>（stationary）。 因此，整个序列的估计值都将通过以下的方式获得：</p>
</li>
</ul>
<p>$$<br>P(x_1, \ldots, x_T) = \prod_{t=1}^T P(x_t \mid x_{t-1}, \ldots, x_1).<br>$$</p>
<blockquote>
<p>注意，如果我们处理的是离散的对象（如单词）， 而不是连续的数字，则上述的考虑仍然有效。 唯一的差别是，对于离散的对象， 我们需要使用分类器而不是回归模型来估计$P(x_t \mid x_{t-1}, \ldots, x_1)$。</p>
</blockquote>
<h3 id="马尔可夫模型"><a href="#马尔可夫模型" class="headerlink" title="马尔可夫模型"></a>马尔可夫模型</h3><ul>
<li>在自回归模型的近似法中， 我们使用$x_{t-1}, \ldots, x_{t-\tau}$而不是$x_{t-1}, \ldots, x_1$来估计$x_t$。 只要这种是近似精确的，我们就说序列满足<em>马尔可夫条件</em>（Markov condition）。 特别是，如果$\tau = 1$，得到一个 <em>一阶马尔可夫模型</em>（first-order Markov model）， $P(x)$由下式给出：</li>
</ul>
<p>$$<br>P(x_1, \ldots, x_T) = \prod_{t=1}^T P(x_t \mid x_{t-1}) \text{ 当 } P(x_1 \mid x_0) = P(x_1).<br>$$</p>
<ul>
<li>假设$x_t$仅是离散值时，这样的模型特别棒， 因为在这种情况下，使用动态规划可以沿着马尔可夫链精确地计算结果。 例如，我们可以高效地计算$P(x_{t+1} \mid x_{t-1})$：</li>
</ul>
<p>$$<br>\begin{split}\begin{aligned}<br>P(x_{t+1} \mid x_{t-1})<br>&amp;= \frac{\sum_{x_t} P(x_{t+1}, x_t, x_{t-1})}{P(x_{t-1})}\<br>&amp;= \frac{\sum_{x_t} P(x_{t+1} \mid x_t, x_{t-1}) P(x_t, x_{t-1})}{P(x_{t-1})}\<br>&amp;= \sum_{x_t} P(x_{t+1} \mid x_t) P(x_t \mid x_{t-1})<br>\end{aligned}\end{split}<br>$$</p>
<blockquote>
<p>离散的情况下，只需要对可能出现的情况进行罗列，对每种出现情况的概率进行求和罢了。参考最后的马尔可夫链昂！</p>
</blockquote>
<h3 id="因果关系"><a href="#因果关系" class="headerlink" title="因果关系"></a>因果关系</h3><ul>
<li>$P(x_1, \ldots, x_T)$基于条件概率公式，总是可以写出：</li>
</ul>
<p>$$<br>P(x_1, \ldots, x_T) = \prod_{t=T}^1 P(x_t \mid x_{t+1}, \ldots, x_T).<br>$$</p>
<blockquote>
<p>如果基于一个马尔可夫模型， 我们还可以得到一个反向的条件概率分布。 然而，在许多情况下，数据存在一个自然的方向，即在时间上是前进的。 很明显，未来的事件不能影响过去。 </p>
</blockquote>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><ul>
<li>首先，我们生成一些数据：使用正弦函数和一些可加性噪声来生成序列数据。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>T = <span class="hljs-number">1000</span>  <span class="hljs-comment"># 总共产生1000个点</span><br>time = torch.arange(<span class="hljs-number">1</span>, T + <span class="hljs-number">1</span>, dtype=torch.float32)<br>x = torch.sin(<span class="hljs-number">0.01</span> * time) + torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.2</span>, (T,))<br>d2l.plot(time, [x], <span class="hljs-string">'time'</span>, <span class="hljs-string">'x'</span>, xlim=[<span class="hljs-number">1</span>, <span class="hljs-number">1000</span>], figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>))<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>我们使用一个相当简单的架构训练模型： 一个拥有两个全连接层的多层感知机，ReLU激活函数和平方损失。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 初始化网络权重的函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.xavier_uniform_(m.weight)<br><br><span class="hljs-comment"># 一个简单的多层感知机</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_net</span>():<br>    net = nn.Sequential(nn.Linear(<span class="hljs-number">4</span>, <span class="hljs-number">10</span>),<br>                        nn.ReLU(),<br>                        nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">1</span>))<br>    net.apply(init_weights)<br>    <span class="hljs-keyword">return</span> net<br><br><span class="hljs-comment"># 平方损失。注意：MSELoss计算平方误差时不带系数1/2</span><br>loss = nn.MSELoss(reduction=<span class="hljs-string">'none'</span>)<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>训练：</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">net, train_iter, loss, epochs, lr</span>):<br>    trainer = torch.optim.Adam(net.parameters(), lr)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>            trainer.zero_grad()<br>            l = loss(net(X), y)<br>            l.<span class="hljs-built_in">sum</span>().backward()<br>            trainer.step()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f'epoch <span class="hljs-subst">{epoch + <span class="hljs-number">1</span>}</span>, '</span><br>              <span class="hljs-string">f'loss: <span class="hljs-subst">{d2l.evaluate_loss(net, train_iter, loss):f}</span>'</span>)<br><br>net = get_net()<br>train(net, train_iter, loss, <span class="hljs-number">5</span>, <span class="hljs-number">0.01</span>)<br><br><span class="hljs-comment"># result</span><br>epoch <span class="hljs-number">1</span>, loss: <span class="hljs-number">0.063133</span><br>epoch <span class="hljs-number">2</span>, loss: <span class="hljs-number">0.053832</span><br>epoch <span class="hljs-number">3</span>, loss: <span class="hljs-number">0.051174</span><br>epoch <span class="hljs-number">4</span>, loss: <span class="hljs-number">0.050547</span><br>epoch <span class="hljs-number">5</span>, loss: <span class="hljs-number">0.047369</span><br></code></pre></td></tr></tbody></table></figure>



<h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><ul>
<li>由于训练损失很小，因此我们期望模型能有很好的工作效果。 让我们看看这在实践中意味着什么。 首先是检查模型预测下一个时间步的能力， 也就是<em>单步预测</em>（one-step-ahead prediction）。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">onestep_preds = net(features)<br>d2l.plot([time, time[tau:]],<br>         [x.detach().numpy(), onestep_preds.detach().numpy()], <span class="hljs-string">'time'</span>,<br>         <span class="hljs-string">'x'</span>, legend=[<span class="hljs-string">'data'</span>, <span class="hljs-string">'1-step preds'</span>], xlim=[<span class="hljs-number">1</span>, <span class="hljs-number">1000</span>],<br>         figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>))<br></code></pre></td></tr></tbody></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202308072040653.svg" srcset="/img/loading.gif" lazyload alt="../_images/output_sequence_ce248f_66_0.svg"></p>
<blockquote>
<p>单步预测效果不错。 即使这些预测的时间步超过了600+4（n_train + tau）， 其结果看起来仍然是可信的。 </p>
</blockquote>
<ul>
<li>对于直到$x_t$的观测序列，其在时间步$t+k$处的预测输出$\hat{x}_{t+k}$ 称为$k$步预测（k-step-ahead-prediction）。换句话说，我们必须使用我们自己的预测（而不是原始数据）来进行多步预测。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">multistep_preds = torch.zeros(T)<br>multistep_preds[: n_train + tau] = x[: n_train + tau]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_train + tau, T):<br>    multistep_preds[i] = net(<br>        multistep_preds[i - tau:i].reshape((<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)))<br><br>d2l.plot([time, time[tau:], time[n_train + tau:]],<br>         [x.detach().numpy(), onestep_preds.detach().numpy(),<br>          multistep_preds[n_train + tau:].detach().numpy()], <span class="hljs-string">'time'</span>,<br>         <span class="hljs-string">'x'</span>, legend=[<span class="hljs-string">'data'</span>, <span class="hljs-string">'1-step preds'</span>, <span class="hljs-string">'multistep preds'</span>],<br>         xlim=[<span class="hljs-number">1</span>, <span class="hljs-number">1000</span>], figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>))<br></code></pre></td></tr></tbody></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202308072044949.svg" srcset="/img/loading.gif" lazyload alt="../_images/output_sequence_ce248f_81_0.svg"></p>
<blockquote>
<p>绿线的预测显然并不理想。经过几个预测步骤之后，预测的结果很快就会衰减到一个常数。 事实是由于错误的累积，预测误差会接着影响下一次的预测，依此类推。 误差可能会相当快地偏离真实的观测结果。</p>
</blockquote>
<ul>
<li>基于$k = 1, 4, 16, 64$，通过对整个序列预测的计算， 让我们更仔细地看一下$k$步预测的困难。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">max_steps = <span class="hljs-number">64</span><br><br>features = torch.zeros((T - tau - max_steps + <span class="hljs-number">1</span>, tau + max_steps))<br><span class="hljs-comment"># 列i（i&lt;tau）是来自x的观测，其时间步从（i）到（i+T-tau-max_steps+1）</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(tau):<br>    features[:, i] = x[i: i + T - tau - max_steps + <span class="hljs-number">1</span>]<br><br><span class="hljs-comment"># 列i（i&gt;=tau）是来自（i-tau+1）步的预测，其时间步从（i）到（i+T-tau-max_steps+1）</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(tau, tau + max_steps):<br>    features[:, i] = net(features[:, i - tau:i]).reshape(-<span class="hljs-number">1</span>)<br><br>steps = (<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">16</span>, <span class="hljs-number">64</span>)<br>d2l.plot([time[tau + i - <span class="hljs-number">1</span>: T - max_steps + i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> steps],<br>         [features[:, tau + i - <span class="hljs-number">1</span>].detach().numpy() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> steps], <span class="hljs-string">'time'</span>, <span class="hljs-string">'x'</span>,<br>         legend=[<span class="hljs-string">f'<span class="hljs-subst">{i}</span>-step preds'</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> steps], xlim=[<span class="hljs-number">5</span>, <span class="hljs-number">1000</span>],<br>         figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>))<br></code></pre></td></tr></tbody></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202308072047297.svg" srcset="/img/loading.gif" lazyload alt="../_images/output_sequence_ce248f_96_0.svg"></p>
<blockquote>
<p>以上例子清楚地说明了当我们试图预测更远的未来时，预测的质量是如何变化的。 虽然“4步预测”看起来仍然不错，但超过这个跨度的任何预测几乎都是无用的。</p>
</blockquote>
<h1 id="文本预处理"><a href="#文本预处理" class="headerlink" title="文本预处理"></a>文本预处理</h1><ul>
<li>一篇文章可以被简单地看作一串单词序列，甚至是一串字符序列。</li>
</ul>
<h2 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br>d2l.DATA_HUB[<span class="hljs-string">'time_machine'</span>] = (d2l.DATA_URL + <span class="hljs-string">'timemachine.txt'</span>,<br>                                <span class="hljs-string">'090b5e7e70c295757f55df93cb0a180b9691891a'</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_time_machine</span>():  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">"""将时间机器数据集加载到文本行的列表中"""</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(d2l.download(<span class="hljs-string">'time_machine'</span>), <span class="hljs-string">'r'</span>) <span class="hljs-keyword">as</span> f:<br>        lines = f.readlines()<br>    <span class="hljs-keyword">return</span> [re.sub(<span class="hljs-string">'[^A-Za-z]+'</span>, <span class="hljs-string">' '</span>, line).strip().lower() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br><br>lines = read_time_machine()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f'# 文本总行数: <span class="hljs-subst">{<span class="hljs-built_in">len</span>(lines)}</span>'</span>)<br><span class="hljs-built_in">print</span>(lines[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(lines[<span class="hljs-number">10</span>])<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>下面的函数将数据集读取到由多条文本行组成的列表中，其中每条文本行都是一个字符串。 为简单起见，我们在这里忽略了标点符号和字母大写。</p>
</blockquote>
<h2 id="词元化"><a href="#词元化" class="headerlink" title="词元化"></a>词元化</h2><ul>
<li>下面的<code>tokenize</code>函数将文本行列表（<code>lines</code>）作为输入， 列表中的每个元素是一个文本序列（如一条文本行）。 每个文本序列又被拆分成一个词元列表，<em>词元</em>（token）是文本的基本单位。 最后，返回一个由词元列表组成的列表，其中的每个词元都是一个字符串（string）。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">lines, token=<span class="hljs-string">'word'</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">"""将文本行拆分为单词或字符词元"""</span><br>    <span class="hljs-keyword">if</span> token == <span class="hljs-string">'word'</span>:<br>        <span class="hljs-keyword">return</span> [line.split() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">elif</span> token == <span class="hljs-string">'char'</span>:<br>        <span class="hljs-keyword">return</span> [<span class="hljs-built_in">list</span>(line) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">'错误：未知词元类型：'</span> + token)<br><br>tokens = tokenize(lines)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">11</span>):<br>    <span class="hljs-built_in">print</span>(tokens[i])<br></code></pre></td></tr></tbody></table></figure>





<h2 id="词表"><a href="#词表" class="headerlink" title="词表"></a>词表</h2><ul>
<li>我们构建一个字典，通常也叫做<em>词表</em>（vocabulary）， 用来将字符串类型的词元映射到从0开始的数字索引中。 我们先将训练集中的所有文档合并在一起，对它们的唯一词元进行统计， 得到的统计结果称之为<em>语料</em>（corpus）。 然后根据每个唯一词元的出现频率，为其分配一个数字索引。 很少出现的词元通常被移除，这可以降低复杂性。 另外，语料库中不存在或已删除的任何词元都将映射到一个特定的未知词元“<unk>”。 我们可以选择增加一个列表，用于保存那些被保留的词元， 例如：填充词元（“<pad>”）； 序列开始词元（“<bos>”）； 序列结束词元（“<eos>”）。</eos></bos></pad></unk></li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Vocab</span>:  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">"""文本词表"""</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, tokens=<span class="hljs-literal">None</span>, min_freq=<span class="hljs-number">0</span>, reserved_tokens=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-keyword">if</span> tokens <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            tokens = []<br>        <span class="hljs-keyword">if</span> reserved_tokens <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            reserved_tokens = []<br>        <span class="hljs-comment"># 按出现频率排序</span><br>        counter = count_corpus(tokens)<br>        self._token_freqs = <span class="hljs-built_in">sorted</span>(counter.items(), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>],<br>                                   reverse=<span class="hljs-literal">True</span>)<br>        <span class="hljs-comment"># 未知词元的索引为0</span><br>        self.idx_to_token = [<span class="hljs-string">'&lt;unk&gt;'</span>] + reserved_tokens<br>        self.token_to_idx = {token: idx<br>                             <span class="hljs-keyword">for</span> idx, token <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.idx_to_token)}<br>        <span class="hljs-keyword">for</span> token, freq <span class="hljs-keyword">in</span> self._token_freqs:<br>            <span class="hljs-keyword">if</span> freq &lt; min_freq:<br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">if</span> token <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self.token_to_idx:<br>                self.idx_to_token.append(token)<br>                self.token_to_idx[token] = <span class="hljs-built_in">len</span>(self.idx_to_token) - <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.idx_to_token)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, tokens</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(tokens, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            <span class="hljs-keyword">return</span> self.token_to_idx.get(tokens, self.unk)<br>        <span class="hljs-keyword">return</span> [self.__getitem__(token) <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">to_tokens</span>(<span class="hljs-params">self, indices</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(indices, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            <span class="hljs-keyword">return</span> self.idx_to_token[indices]<br>        <span class="hljs-keyword">return</span> [self.idx_to_token[index] <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> indices]<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">unk</span>(<span class="hljs-params">self</span>):  <span class="hljs-comment"># 未知词元的索引为0</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">token_freqs</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self._token_freqs<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">count_corpus</span>(<span class="hljs-params">tokens</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">"""统计词元的频率"""</span><br>    <span class="hljs-comment"># 这里的tokens是1D列表或2D列表</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(tokens) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">isinstance</span>(tokens[<span class="hljs-number">0</span>], <span class="hljs-built_in">list</span>):<br>        <span class="hljs-comment"># 将词元列表展平成一个列表</span><br>        tokens = [token <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>    <span class="hljs-keyword">return</span> collections.Counter(tokens)<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>使用时光机器数据集作为语料库来构建词表</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">vocab = Vocab(tokens)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(vocab.token_to_idx.items())[:<span class="hljs-number">10</span>])<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>我们可以将每一条文本行转换成一个数字索引列表。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> [<span class="hljs-number">0</span>, <span class="hljs-number">10</span>]:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">'文本:'</span>, tokens[i])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">'索引:'</span>, vocab[tokens[i]])<br></code></pre></td></tr></tbody></table></figure>



<h2 id="整合所有功能"><a href="#整合所有功能" class="headerlink" title="整合所有功能"></a>整合所有功能</h2><ul>
<li>我们将所有功能打包到<code>load_corpus_time_machine</code>函数中， 该函数返回<code>corpus</code>（词元索引列表）和<code>vocab</code>（时光机器语料库的词表）。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_corpus_time_machine</span>(<span class="hljs-params">max_tokens=-<span class="hljs-number">1</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">"""返回时光机器数据集的词元索引列表和词表"""</span><br>    lines = read_time_machine()<br>    tokens = tokenize(lines, <span class="hljs-string">'char'</span>)<br>    vocab = Vocab(tokens)<br>    <span class="hljs-comment"># 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，</span><br>    <span class="hljs-comment"># 所以将所有文本行展平到一个列表中</span><br>    corpus = [vocab[token] <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>    <span class="hljs-keyword">if</span> max_tokens &gt; <span class="hljs-number">0</span>:<br>        corpus = corpus[:max_tokens]<br>    <span class="hljs-keyword">return</span> corpus, vocab<br><br>corpus, vocab = load_corpus_time_machine()<br><span class="hljs-built_in">len</span>(corpus), <span class="hljs-built_in">len</span>(vocab)<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<ol>
<li>为了简化后面章节中的训练，我们使用字符（而不是单词）实现文本词元化；</li>
<li>时光机器数据集中的每个文本行不一定是一个句子或一个段落，还可能是一个单词，因此返回的<code>corpus</code>仅处理为单个列表，而不是使用多词元列表构成的一个列表。</li>
</ol>
</blockquote>
<h1 id="语言模型和数据集"><a href="#语言模型和数据集" class="headerlink" title="语言模型和数据集"></a>语言模型和数据集</h1><ul>
<li>将文本数据映射为词元， 以及将这些词元可以视为一系列离散的观测，例如单词或字符。 假设长度为$T$的文本序列中的词元依次为$x_1, x_2, \ldots, x_T$。 于是，$x_t(1 \leq t \leq T)$可以被认为是文本序列在时间步$t$处的观测或标签。 在给定这样的文本序列时，<em>语言模型</em>（language model）的目标是估计序列的联合概率</li>
</ul>
<p>$$<br>P(x_1, x_2, \ldots, x_T).<br>$$</p>
<ul>
<li>例如：只需要一次抽取一个词元$x_t \sim P(x_t \mid x_{t-1}, \ldots, x_1)$，一个理想的语言模型就能够基于模型本身生成自然文本。</li>
</ul>
<h2 id="学习语言模型"><a href="#学习语言模型" class="headerlink" title="学习语言模型"></a>学习语言模型</h2><ul>
<li>基本概率规则开始：</li>
</ul>
<p>$$<br>P(x_1, x_2, \ldots, x_T) = \prod_{t=1}^T P(x_t  \mid  x_1, \ldots, x_{t-1}). \<br>Example: \ P(\text{deep}, \text{learning}, \text{is}, \text{fun}) =  P(\text{deep}) P(\text{learning}  \mid  \text{deep}) P(\text{is}  \mid  \text{deep}, \text{learning}) P(\text{fun}  \mid  \text{deep}, \text{learning}, \text{is}).<br>$$</p>
<blockquote>
<p>我们需要计算单词的概率， 以及给定前面几个单词后出现某个单词的条件概率。 这些概率本质上就是语言模型的参数。</p>
</blockquote>
<ul>
<li>一种（稍稍不太精确的）方法是统计单词“deep”在数据集中的出现次数， 然后将其除以整个语料库中的单词总数。 这种方法效果不错，特别是对于频繁出现的单词。 接下来，我们可以尝试估计</li>
</ul>
<p>$$<br>\hat{P}(\text{learning} \mid \text{deep}) = \frac{n(\text{deep, learning})}{n(\text{deep})},<br>$$</p>
<ul>
<li>$n(x)$和$n(x, x’)$分别是单个单词和连续单词对的出现次数。由于连续单词对“deep learning”的出现频率要低得多， 所以估计这类单词正确的概率要困难得多。 特别是对于一些不常见的单词组合，要想找到足够的出现次数来获得准确的估计可能都不容易。 而对于三个或者更多的单词组合，情况会变得更糟。 许多合理的三个单词组合可能是存在的，但是在数据集中却找不到。 如果数据集很小，或者单词非常罕见，那么这类单词出现一次的机会可能都找不到。</li>
<li>一种常见的策略是执行某种形式的<em>拉普拉斯平滑</em>（Laplace smoothing）， 具体方法是在所有计数中添加一个小常量。 用n表示训练集中的单词总数，用m表示唯一单词的数量。 此解决方案有助于处理单元素问题，例如通过：</li>
</ul>
<p>$$<br>\begin{split}\begin{aligned}<br>    \hat{P}(x) &amp; = \frac{n(x) + \epsilon_1/m}{n + \epsilon_1}, \<br>    \hat{P}(x’ \mid x) &amp; = \frac{n(x, x’) + \epsilon_2 \hat{P}(x’)}{n(x) + \epsilon_2}, \<br>    \hat{P}(x’’ \mid x,x’) &amp; = \frac{n(x, x’,x’’) + \epsilon_3 \hat{P}(x’’)}{n(x, x’) + \epsilon_3}.<br>\end{aligned}\end{split}<br>$$</p>
<ul>
<li>$\epsilon_1,\epsilon_2,\epsilon_3$是超参数。 当$\epsilon$为0的时候，不应用平滑。无穷大的时候，$\hat{P}(x)$接近均匀概率分布1/m。这样的模型很容易变得无效，原因如下： 首先，我们需要存储所有的计数； 其次，这完全忽略了单词的意思。 例如，“猫”（cat）和“猫科动物”（feline）可能出现在相关的上下文中， 但是想根据上下文调整这类模型其实是相当困难的。 最后，长单词序列大部分是没出现过的， 因此一个模型如果只是简单地统计先前“看到”的单词序列频率， 那么模型面对这种问题肯定是表现不佳的。</li>
</ul>
<h2 id="马尔可夫模型与n元语法"><a href="#马尔可夫模型与n元语法" class="headerlink" title="马尔可夫模型与n元语法"></a>马尔可夫模型与n元语法</h2><ul>
<li>序列上的分布满足一阶马尔可夫性质。 阶数越高，对应的依赖关系就越长。 这种性质推导出了许多可以应用于序列建模的近似公式：</li>
</ul>
<p>$$<br>\begin{split}\begin{aligned}<br>P(x_1, x_2, x_3, x_4) &amp;=  P(x_1) P(x_2) P(x_3) P(x_4),\<br>P(x_1, x_2, x_3, x_4) &amp;=  P(x_1) P(x_2  \mid  x_1) P(x_3  \mid  x_2) P(x_4  \mid  x_3),\<br>P(x_1, x_2, x_3, x_4) &amp;=  P(x_1) P(x_2  \mid  x_1) P(x_3  \mid  x_1, x_2) P(x_4  \mid  x_2, x_3).<br>\end{aligned}\end{split}<br>$$</p>
<blockquote>
<p>涉及一个、两个和三个变量的概率公式分别被称为 <em>一元语法</em>（unigram）、<em>二元语法</em>（bigram）和<em>三元语法</em>（trigram）模型。</p>
</blockquote>
<h2 id="自然语言统计"><a href="#自然语言统计" class="headerlink" title="自然语言统计"></a>自然语言统计</h2><ul>
<li>查看出现频率最高的十个词：</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>tokens = d2l.tokenize(d2l.read_time_machine())<br><span class="hljs-comment"># 因为每个文本行不一定是一个句子或一个段落，因此我们把所有文本行拼接到一起</span><br>corpus = [token <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>vocab = d2l.Vocab(corpus)<br>vocab.token_freqs[:<span class="hljs-number">10</span>]<br></code></pre></td></tr></tbody></table></figure>

<ul>
<li>最流行的词看起来很无聊， 这些词通常被称为<em>停用词</em>（stop words），因此可以被过滤掉。 尽管如此，它们本身仍然是有意义的，我们仍然会在模型中使用它们。 此外，还有个明显的问题是词频衰减的速度相当地快。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">freqs = [freq <span class="hljs-keyword">for</span> token, freq <span class="hljs-keyword">in</span> vocab.token_freqs]<br>d2l.plot(freqs, xlabel=<span class="hljs-string">'token: x'</span>, ylabel=<span class="hljs-string">'frequency: n(x)'</span>,<br>         xscale=<span class="hljs-string">'log'</span>, yscale=<span class="hljs-string">'log'</span>)<br></code></pre></td></tr></tbody></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202308072134274.svg" srcset="/img/loading.gif" lazyload alt="../_images/output_language-models-and-dataset_789d14_21_0.svg"></p>
<blockquote>
<p>词频以一种明确的方式迅速衰减。 将前几个单词作为例外消除后，剩余的所有单词大致遵循双对数坐标图上的一条直线。 这意味着单词的频率满足<em>齐普夫定律</em>（Zipf’s law）， 即第$i$个最常用单词的频率$n_i$为：</p>
</blockquote>
<p>$$<br>n_i \propto \frac{1}{i^\alpha},<br>$$</p>
<blockquote>
<p>等价于</p>
</blockquote>
<p>$$<br>\log n_i = -\alpha \log i + c,<br>$$</p>
<ul>
<li>$\alpha$是刻画分布的指数，$c$是常数。 这告诉我们想要通过计数统计和平滑来建模单词是不可行的， 因为这样建模的结果会大大高估尾部单词的频率，也就是所谓的不常用单词。 那么其他的词元组合，比如二元语法、三元语法等等，又会如何呢？ 我们来看看二元语法的频率是否与一元语法的频率表现出相同的行为方式。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">bigram_tokens = [pair <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(corpus[:-<span class="hljs-number">1</span>], corpus[<span class="hljs-number">1</span>:])]<br>bigram_vocab = d2l.Vocab(bigram_tokens)<br>bigram_vocab.token_freqs[:<span class="hljs-number">10</span>]<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>在十个最频繁的词对中，有九个是由两个停用词组成的， 只有一个与“the time”有关。 我们再进一步看看三元语法的频率是否表现出相同的行为方式。</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">trigram_tokens = [triple <span class="hljs-keyword">for</span> triple <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<br>    corpus[:-<span class="hljs-number">2</span>], corpus[<span class="hljs-number">1</span>:-<span class="hljs-number">1</span>], corpus[<span class="hljs-number">2</span>:])]<br>trigram_vocab = d2l.Vocab(trigram_tokens)<br>trigram_vocab.token_freqs[:<span class="hljs-number">10</span>]<br></code></pre></td></tr></tbody></table></figure>

<blockquote>
<p>我们直观地对比三种模型中的词元频率：一元语法、二元语法和三元语法。</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">bigram_freqs = [freq <span class="hljs-keyword">for</span> token, freq <span class="hljs-keyword">in</span> bigram_vocab.token_freqs]<br>trigram_freqs = [freq <span class="hljs-keyword">for</span> token, freq <span class="hljs-keyword">in</span> trigram_vocab.token_freqs]<br>d2l.plot([freqs, bigram_freqs, trigram_freqs], xlabel=<span class="hljs-string">'token: x'</span>,<br>         ylabel=<span class="hljs-string">'frequency: n(x)'</span>, xscale=<span class="hljs-string">'log'</span>, yscale=<span class="hljs-string">'log'</span>,<br>         legend=[<span class="hljs-string">'unigram'</span>, <span class="hljs-string">'bigram'</span>, <span class="hljs-string">'trigram'</span>])<br></code></pre></td></tr></tbody></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202308072141219.png" srcset="/img/loading.gif" lazyload alt="image-20230807214144040"></p>
<ul>
<li>这张图非常令人振奋！原因有很多：<ol>
<li>除了一元语法词，单词序列似乎也遵循齐普夫定律， 尽管公式 <a target="_blank" rel="noopener" href="https://zh.d2l.ai/chapter_recurrent-neural-networks/language-models-and-dataset.html#equation-eq-zipf-law">(8.3.7)</a>中的指数$\alpha$更小 （指数的大小受序列长度的影响）；</li>
<li>词表中n元组的数量并没有那么大，这说明语言中存在相当多的结构， 这些结构给了我们应用模型的希望；</li>
<li>很多n元组很少出现，这使得拉普拉斯平滑非常不适合语言建模。 作为代替，我们将使用基于深度学习的模型。</li>
</ol>
</li>
</ul>
<h2 id="读取长序列数据"><a href="#读取长序列数据" class="headerlink" title="读取长序列数据"></a>读取长序列数据</h2><ul>
<li>当序列变得太长而不能被模型一次性全部处理时， 我们可能希望拆分这样的序列方便模型读取。我们看一下总体策略。 假设我们将使用神经网络来训练语言模型， 模型中的网络一次处理具有预定义长度 （例如n个时间步）的一个小批量序列。 现在的问题是如何随机生成一个小批量数据的特征和标签以供读取。</li>
<li>由于文本序列可以是任意长的， 例如整本《时光机器》（<em>The Time Machine</em>）， 于是任意长的序列可以被我们划分为具有相同时间步数的子序列。 当训练我们的神经网络时，这样的小批量子序列将被输入到模型中。 假设网络一次只处理具有n个时间步的子序列。每个时间步的词元对应于一个字符，如果大小为5，我们可以选择任意偏移量来指示初始位置，所以我们有相当大的自由度。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/alexanderliu-creator/blog_img/img/202308072152942.svg" srcset="/img/loading.gif" lazyload alt="../_images/timemachine-5gram.svg"></p>
<ul>
<li>如果我们只选择一个偏移量， 那么用于训练网络的、所有可能的子序列的覆盖范围将是有限的。 因此，我们可以从随机偏移量开始划分序列， 以同时获得<em>覆盖性</em>（coverage）和<em>随机性</em>（randomness）。 下面，我们将描述如何实现<em>随机采样</em>（random sampling）和 <em>顺序分区</em>（sequential partitioning）策略。</li>
</ul>
<h3 id="随机采样"><a href="#随机采样" class="headerlink" title="随机采样"></a>随机采样</h3><ul>
<li>在随机采样中，每个样本都是在原始的长序列上任意捕获的子序列。 在迭代过程中，来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻。 对于语言建模，目标是基于到目前为止我们看到的词元来预测下一个词元， 因此标签是移位了一个词元的原始序列。</li>
<li>下面的代码每次可以从数据中随机生成一个小批量。 在这里，参数<code>batch_size</code>指定了每个小批量中子序列样本的数目， 参数<code>num_steps</code>是每个子序列中预定义的时间步数。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_random</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">"""使用随机抽样生成一个小批量子序列"""</span><br>    <span class="hljs-comment"># 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1</span><br>    corpus = corpus[random.randint(<span class="hljs-number">0</span>, num_steps - <span class="hljs-number">1</span>):]<br>    <span class="hljs-comment"># 减去1，是因为我们需要考虑标签</span><br>    num_subseqs = (<span class="hljs-built_in">len</span>(corpus) - <span class="hljs-number">1</span>) // num_steps<br>    <span class="hljs-comment"># 长度为num_steps的子序列的起始索引</span><br>    initial_indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_subseqs * num_steps, num_steps))<br>    <span class="hljs-comment"># 在随机抽样的迭代过程中，</span><br>    <span class="hljs-comment"># 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻</span><br>    random.shuffle(initial_indices)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">data</span>(<span class="hljs-params">pos</span>):<br>        <span class="hljs-comment"># 返回从pos位置开始的长度为num_steps的序列</span><br>        <span class="hljs-keyword">return</span> corpus[pos: pos + num_steps]<br><br>    num_batches = num_subseqs // batch_size<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, batch_size * num_batches, batch_size):<br>        <span class="hljs-comment"># 在这里，initial_indices包含子序列的随机起始索引</span><br>        initial_indices_per_batch = initial_indices[i: i + batch_size]<br>        X = [data(j) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> initial_indices_per_batch]<br>        Y = [data(j + <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> initial_indices_per_batch]<br>        <span class="hljs-keyword">yield</span> torch.tensor(X), torch.tensor(Y)<br></code></pre></td></tr></tbody></table></figure>











<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/643560888">LLM面试题</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/109217883">马尔可夫链</a></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/AI/" class="category-chain-item">AI</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E7%A0%940%E8%87%AA%E5%AD%A6/">#研0自学</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>D2L-9-Recurrent Neural Networks</div>
      <div>http://example.com/2023/08/07/d2l-9-recurrent-neural-networks/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Alexander Liu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年8月7日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/08/07/d2l-8-computer-vision/" title="D2L-8-Computer Vision">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">D2L-8-Computer Vision</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/08/06/d2l-7-modern-convolutional-neural-networks/" title="D2L-7-Modern Convolutional Neural Networks">
                        <span class="hidden-mobile">D2L-7-Modern Convolutional Neural Networks</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.events.registerRefreshCallback(function() {
      if ('mermaid' in window) {
        mermaid.init();
      }
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
